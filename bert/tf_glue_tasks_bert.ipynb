{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_glue_tasks_bert.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMzVQ3YzorugtnpNgobPRuZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6xjncqQbllB6"},"source":["# Solving GLUE tasks using BERT"]},{"cell_type":"markdown","metadata":{"id":"yLEV7ljanHT-"},"source":["## What is the GLUE benchmark?\n","\n","The General Language Undertanding Evaluation benchmark (GLUE) is collection of datasets used for training, evaluating and analyzing NLP models. The collection consists of nine difficult and diverse tasks datasets.\n","\n","Dataset | Description | Data sample | Metric(s)  \n","--- | --- | --- | ---\n","CoLA | **Corpus of Linguistic Acceptability**<br>Is the sentence grammatically correct? | \"This building is than that one.\" <br> **= Ungrammatical** | Matthews\n","SST-2 | **Stanford Sentiment Treebank**<br>The task is to predict the sentiment of a given sentence. | \"The movie is funny, smart, and most of all alive.\"<br>**=.93056(very positive)** | Accuracy\n","MRPC | Microsoft Research Paraphrase Corpus<br>Determine whether a pair of sentences are semantically equivalent | a) \"Yesterday, Taiwan reported 35 new infections, briging the total number of cases to 418.\"<br>b) \"The island reported another 35 probable cases yesterday, taking its total to 418.\"<br>**A Paraphrase** | Accuracy/F1"]},{"cell_type":"code","metadata":{"id":"GXnp-FuYnGyJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1kuPVuIlY5l"},"source":[""],"execution_count":null,"outputs":[]}]}