{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_attention.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP99UTORHknC8NgK42Qpb4h"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dvvs__CnaoA6"},"source":["<img src=\"https://github.com/martin-fabbri/colab-notebooks/raw/master/bert/images/attention-zoom-in.png\" width=1000px alt=\"Big Picture\"/>"]},{"cell_type":"markdown","metadata":{"id":"J_CP6riQlY4V"},"source":[""]},{"cell_type":"code","metadata":{"id":"GLJzaFoaHup7","executionInfo":{"status":"ok","timestamp":1610350039584,"user_tz":480,"elapsed":331,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["import io\r\n","import os\r\n","import re\r\n","import time\r\n","import unicodedata\r\n","\r\n","import matplotlib.pyplot as plt\r\n","import matplotlib.ticker as ticker\r\n","import numpy as np\r\n","import tensorflow as tf\r\n","\r\n","from tensorflow.keras.layers import Embedding, GRU, Layer, Dense\r\n","from sklearn.model_selection import train_test_split"],"execution_count":108,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LxA03ICpIGSQ"},"source":["## 1. Inputs"]},{"cell_type":"code","metadata":{"id":"zrlOwYH6akcE","executionInfo":{"status":"ok","timestamp":1610180491585,"user_tz":480,"elapsed":2399,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["x = [\r\n","    [1.0, 0.0, 1.0, 0.0],  # input 1\r\n","    [0.0, 2.0, 0.0, 2.0],  # input 2\r\n","    [1.0, 1.0, 1.0, 1.0],  # input 3\r\n","]\r\n","\r\n","x = tf.constant(x)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_gByknkII_C"},"source":["## 2. Initialize Queries, Keys, and Values Weights"]},{"cell_type":"code","metadata":{"id":"f6tmKgkAH4lH","executionInfo":{"status":"ok","timestamp":1610180491586,"user_tz":480,"elapsed":2390,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["w_key = [\r\n","  [0.0, 0.0, 1.0],\r\n","  [1.0, 1.0, 0.0],\r\n","  [0.0, 1.0, 0.0],\r\n","  [1.0, 1.0, 0.0]\r\n","]\r\n","w_query = [\r\n","  [1.0, 0.0, 1.0],\r\n","  [1.0, 0.0, 0.0],\r\n","  [0.0, 0.0, 1.0],\r\n","  [0.0, 1.0, 1.0]\r\n","]\r\n","w_value = [\r\n","  [0.0, 2.0, 0.0],\r\n","  [0.0, 3.0, 0.0],\r\n","  [1.0, 0.0, 3.0],\r\n","  [1.0, 1.0, 0.0]\r\n","]\r\n","w_key = tf.constant(w_key)\r\n","w_query = tf.constant(w_query)\r\n","w_value = tf.constant(w_value)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a75T5sNjH5I-","executionInfo":{"status":"ok","timestamp":1610180491588,"user_tz":480,"elapsed":2380,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"98457ea9-fd58-4180-8907-2501bb5c2e32"},"source":["keys = tf.linalg.matmul(x, w_key)\r\n","keys"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n","array([[0., 1., 1.],\n","       [4., 4., 0.],\n","       [2., 3., 1.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s38iPdOJJVpr","executionInfo":{"status":"ok","timestamp":1610180491589,"user_tz":480,"elapsed":2367,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"cf7fb1dc-a2a6-4806-dc9b-d7e80bb602d9"},"source":["queries = tf.linalg.matmul(x, w_query)\r\n","queries"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n","array([[1., 0., 2.],\n","       [2., 2., 2.],\n","       [2., 1., 3.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQfeAWTuJu9z","executionInfo":{"status":"ok","timestamp":1610180491939,"user_tz":480,"elapsed":2707,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"a20c6c06-a7e5-4ca4-ee86-cbf350e16f1a"},"source":["values = tf.linalg.matmul(x, w_value)\r\n","values"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n","array([[1., 2., 3.],\n","       [2., 8., 0.],\n","       [2., 6., 3.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"1oBR9SwZLVZd"},"source":["<img src=\"https://github.com/martin-fabbri/colab-notebooks/raw/master/bert/images/attention-nn.png\" alt=\"self-attention block\" width=800px>"]},{"cell_type":"markdown","metadata":{"id":"4NG1-3I3KDAd"},"source":["## 2. Calculate attention scores"]},{"cell_type":"markdown","metadata":{"id":"0xItyEXlLtXQ"},"source":["<img src=\"https://github.com/martin-fabbri/colab-notebooks/raw/master/bert/images/multi-head-attention.png\" alt=\"multihead-attention\" width=\"700px\">"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lzm9xkvZJ6hm","executionInfo":{"status":"ok","timestamp":1610181180671,"user_tz":480,"elapsed":385,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"fa0d7837-c6b8-445d-e854-146a30591fa1"},"source":["attention_scores = tf.matmul(queries, keys, transpose_b=True)\r\n","attention_scores"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n","array([[ 2.,  4.,  4.],\n","       [ 4., 16., 12.],\n","       [ 4., 12., 10.]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"36jww2K9MXUD"},"source":["### 3. Softmax"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qJtLBNaK1eC","executionInfo":{"status":"ok","timestamp":1610181196815,"user_tz":480,"elapsed":406,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"bd987006-a09c-4487-9c3d-a1929c0fc0dc"},"source":["attention_scores_softmax = tf.nn.softmax(attention_scores)\r\n","attention_scores_softmax"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n","array([[6.3378938e-02, 4.6831051e-01, 4.6831051e-01],\n","       [6.0336647e-06, 9.8200780e-01, 1.7986100e-02],\n","       [2.9538720e-04, 8.8053685e-01, 1.1916770e-01]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"byub9VSsPZaV"},"source":["## 4. Multiply scores with values"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6TGCiPkqMryj","executionInfo":{"status":"ok","timestamp":1610181268935,"user_tz":480,"elapsed":372,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"a28ad0a9-1de2-4682-c2c4-ebbf01f8baf9"},"source":["weighted_values = values[:, None] * tf.transpose(attention_scores_softmax)[:,:,None]\r\n","weighted_values"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3, 3), dtype=float32, numpy=\n","array([[[6.3378938e-02, 1.2675788e-01, 1.9013682e-01],\n","        [6.0336647e-06, 1.2067329e-05, 1.8100995e-05],\n","        [2.9538720e-04, 5.9077441e-04, 8.8616158e-04]],\n","\n","       [[9.3662101e-01, 3.7464840e+00, 0.0000000e+00],\n","        [1.9640156e+00, 7.8560624e+00, 0.0000000e+00],\n","        [1.7610737e+00, 7.0442948e+00, 0.0000000e+00]],\n","\n","       [[9.3662101e-01, 2.8098631e+00, 1.4049315e+00],\n","        [3.5972200e-02, 1.0791660e-01, 5.3958301e-02],\n","        [2.3833540e-01, 7.1500623e-01, 3.5750312e-01]]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oNa37XS5QjQJ","executionInfo":{"status":"ok","timestamp":1610181341016,"user_tz":480,"elapsed":310,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"6e1c1929-839d-4bf1-e611-4cfa07980aaf"},"source":["outputs = tf.reduce_sum(weighted_values, axis=0)\r\n","outputs"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n","array([[1.936621 , 6.683105 , 1.5950683],\n","       [1.9999939, 7.963991 , 0.0539764],\n","       [1.9997045, 7.759892 , 0.3583893]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"RSTuWLQI_JxW"},"source":["## Seq2Seq Attention"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"t5M10bX2SUyS","executionInfo":{"status":"ok","timestamp":1610328558221,"user_tz":480,"elapsed":338,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"f538f57a-16c9-4875-c26c-78c7cd8f18a8"},"source":["dataset_url = \"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\r\n","\r\n","path_to_zip = tf.keras.utils.get_file(\r\n","    'spa-end.zip', origin=dataset_url, extract=True\r\n",")\r\n","\r\n","path_to_file = os.path.join(os.path.dirname(path_to_zip), \"spa-eng/spa.txt\")\r\n","path_to_file"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/root/.keras/datasets/spa-eng/spa.txt'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"MiSUKMgm_57p","executionInfo":{"status":"ok","timestamp":1610330715317,"user_tz":480,"elapsed":296,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["# Uncase sentence and removes accents from sentence\r\n","def unicode_to_ascii(s):\r\n","    return \"\".join(\r\n","        c\r\n","        for c in unicodedata.normalize(\"NFD\", s)\r\n","        if unicodedata.category(c) != \"Mn\"\r\n","    )"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ckDXR-ILDmkT","executionInfo":{"status":"ok","timestamp":1610329932264,"user_tz":480,"elapsed":316,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"e2f2bd94-386b-4cf2-f953-78d383ba25bb"},"source":["unicode_to_ascii(\"¿Dónde está la farmacia?\")"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'¿Donde esta la farmacia?'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"VEvxX4QeJMBO","executionInfo":{"status":"ok","timestamp":1610330421457,"user_tz":480,"elapsed":360,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["def preprocess_sentence(w):\r\n","    w = unicode_to_ascii(w.lower().strip())\r\n","\r\n","    # creating a space between a word and the punctuation following it\r\n","    # eg: \"he is a boy.\" => \"he is a boy .\"\r\n","    w = re.sub(r\"([?.!,¿])\", r\" \\1\", w)\r\n","    w = re.sub('[\" \"]+1', \" \", w)\r\n","\r\n","    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\r\n","    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\r\n","    w = w.strip()\r\n","\r\n","    # adding a start and an end token to the sentence\r\n","    w = f\"<start>{w}<end>\"\r\n","    return w"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4oQMRkcMJkZs","executionInfo":{"status":"ok","timestamp":1610330646395,"user_tz":480,"elapsed":352,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"d73696cb-43a3-4a2e-a415-24b3ee8ece31"},"source":["en_sentence = u\"Where is the drug store?\"\r\n","sp_sentence = u\"¿Dónde está la farmacia?\"\r\n","print(preprocess_sentence(en_sentence))\r\n","print(preprocess_sentence(sp_sentence))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["<start>where is the drug store ?<end>\n","<start>¿donde esta la farmacia ?<end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58YRQvtnLdc6","executionInfo":{"status":"ok","timestamp":1610330718980,"user_tz":480,"elapsed":376,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"c0634baf-a6d6-42eb-b2d5-d8ce1e791e29"},"source":["en_sentence = u\"I am going home.\"\r\n","sp_sentence = u\"Me voy a la casa.\"\r\n","print(preprocess_sentence(en_sentence))\r\n","print(preprocess_sentence(sp_sentence))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["<start>i am going home .<end>\n","<start>me voy a la casa .<end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3csooFt2LdQN","executionInfo":{"status":"ok","timestamp":1610336188012,"user_tz":480,"elapsed":473,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"16ae5c2c-595d-41aa-c383-bf82916e7cbb"},"source":["# cleans the sentences and returns word pairs in the format [en, sp]\r\n","NUM_EXAMPLES = 3000\r\n","\r\n","lines = io.open(path_to_file, encoding=\"UTF-8\").read().strip().split(\"\\n\")\r\n","word_pairs = [\r\n","    [preprocess_sentence(w) for w in l.split(\"\\t\")]\r\n","    for l in lines[:NUM_EXAMPLES]\r\n","]\r\n","en, sp = zip(*word_pairs)\r\n","print(en[0])\r\n","print(sp[0])"],"execution_count":74,"outputs":[{"output_type":"stream","text":["<start>go .<end>\n","<start>ve .<end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s1ZqavQvYPpJ","executionInfo":{"status":"ok","timestamp":1610336493446,"user_tz":480,"elapsed":286,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["def tokenize(lang):\r\n","    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\")\r\n","    lang_tokenizer.fit_on_texts(lang)\r\n","    tensor = lang_tokenizer.texts_to_sequences(lang)\r\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(\r\n","        tensor, padding=\"post\"\r\n","    )\r\n","    return tensor, lang_tokenizer"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzqPkMXYaWmb","executionInfo":{"status":"ok","timestamp":1610336494923,"user_tz":480,"elapsed":331,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["input_tensor, sp_lang_tokenizer = tokenize(sp)\r\n","target_tensor, en_lang_tokenizer = tokenize(en)\r\n","max_length_target, max_lenght_input = (\r\n","    target_tensor.shape[1],\r\n","    input_tensor.shape[1],\r\n",")"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-IsV5Uyacfl","executionInfo":{"status":"ok","timestamp":1610336502895,"user_tz":480,"elapsed":349,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"605bdb38-b180-46bf-b9ed-7b28d2059d49"},"source":["(\r\n","    input_tensor_train,\r\n","    input_tensor_val,\r\n","    target_tensor_train,\r\n","    target_tensor_val,\r\n",") = train_test_split(input_tensor, target_tensor, test_size=0.2)\r\n","# Show length\r\n","print(f\"Input train length       {len(input_tensor_train):,}\")\r\n","print(f\"Target train length      {len(target_tensor_train):,}\")\r\n","print(f\"Input validation length  {len(input_tensor_val)}\")\r\n","print(f\"Target validation length {len(target_tensor_val)}\")"],"execution_count":84,"outputs":[{"output_type":"stream","text":["Input train length       2,400\n","Target train length      2,400\n","Input validation length  600\n","Target validation length 600\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m0k-EJLTdNfQ","executionInfo":{"status":"ok","timestamp":1610336505534,"user_tz":480,"elapsed":394,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["def convert(lang, tensor):\r\n","  for t in tensor:\r\n","    if t != 0:\r\n","      print(f\"{t} ---->{lang.index_word[t]}\")"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ZCH8aTkfxbZ","executionInfo":{"status":"ok","timestamp":1610336506668,"user_tz":480,"elapsed":296,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"f4db6c52-123d-436c-a5f0-e5335eab3438"},"source":["print (\"Input Language; index to word mapping\")\r\n","convert(sp_lang_tokenizer, input_tensor_train[0])\r\n","print ()\r\n","print (\"Target Language; index to word mapping\")\r\n","convert(en_lang_tokenizer, target_tensor_train[0])"],"execution_count":86,"outputs":[{"output_type":"stream","text":["Input Language; index to word mapping\n","61 ----><start>ven\n","1949 ---->enseguida\n","1 ---->.<end>\n","\n","Target Language; index to word mapping\n","21 ----><start>come\n","102 ---->at\n","932 ---->once\n","1 ---->.<end>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EIinyvkHia5C"},"source":["### Create a tf.data Dataset"]},{"cell_type":"code","metadata":{"id":"8-GpzQQ9hdMj","executionInfo":{"status":"ok","timestamp":1610336767427,"user_tz":480,"elapsed":300,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["BUFFER_SIZE = len(input_tensor_train)\r\n","BATCH_SIZE = 64\r\n","STEPS_PER_EPOCH = BUFFER_SIZE // BATCH_SIZE\r\n","EMBEDDING_DIM = 256\r\n","UNITS = 1024\r\n","VOCAB_INPUT_SIZE = len(sp_lang_tokenizer.word_counts) + 1\r\n","VOCAB_TARGET_SIZE = len(en_lang_tokenizer.word_counts) + 1"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rcPCYDKjQwf","executionInfo":{"status":"ok","timestamp":1610336885376,"user_tz":480,"elapsed":230,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"fc340378-80a3-472e-ff1d-a9a13ed21ecf"},"source":["dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\r\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\r\n","dataset.cardinality()"],"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=int64, numpy=37>"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C4TDxPDhjnSL","executionInfo":{"status":"ok","timestamp":1610336965937,"user_tz":480,"elapsed":220,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"13f34d47-5d18-4dc8-b1fd-b2f31a30b9b5"},"source":["input_batch, target_batch = next(iter(dataset))\r\n","input_batch.shape, target_batch.shape"],"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 8]), TensorShape([64, 6]))"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"XqtTVqDskyEF","executionInfo":{"status":"ok","timestamp":1610347639403,"user_tz":480,"elapsed":295,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["class Encoder(tf.keras.Model):\r\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\r\n","        super(Encoder, self).__init__()\r\n","        self.batch_sz = batch_sz\r\n","        self.enc_units = enc_units # number of units in output space\r\n","        self.embedding = Embedding(vocab_size, embedding_dim)\r\n","        self.gru = GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer=\"glorot_uniform\")\r\n","\r\n","    def call(self, x, hidden):\r\n","        x = self.embedding(x)\r\n","        output, state = self.gru(x, initial_state=hidden)\r\n","        return output, state\r\n","\r\n","    def initialize_hidden_state(self):\r\n","        return tf.zeros((self.batch_sz, self.enc_units))"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G6DCjutOHTgG","executionInfo":{"status":"ok","timestamp":1610348125113,"user_tz":480,"elapsed":702,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"eec5e817-c92e-4233-d46d-518ab2789f44"},"source":["encoder = Encoder(VOCAB_INPUT_SIZE, EMBEDDING_DIM, UNITS, BATCH_SIZE)\r\n","\r\n","sample_hidden = encoder.initialize_hidden_state()\r\n","sample_output, sample_hidden = encoder(input_batch, sample_hidden)\r\n","print(\"VOCAB_INPUT_SIZE \", VOCAB_INPUT_SIZE)\r\n","print(\"EMBEDDING_DIM    \", EMBEDDING_DIM)\r\n","print(\"UNIT             \", UNITS)\r\n","print(\"BATCH SIZR       \", BATCH_SIZE)\r\n","print(\"Encoder output shape: (batch size, seq len, units)\", sample_output.shape)\r\n","print(\"Encoder Hidden state shape: (batch size, units)\", sample_hidden.shape)"],"execution_count":105,"outputs":[{"output_type":"stream","text":["VOCAB_INPUT_SIZE  2177\n","EMBEDDING_DIM     256\n","UNIT              1024\n","BATCH SIZR        64\n","Encoder output shape: (batch size, seq len, units) (64, 8, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ombMFIhcmHiO"},"source":["## Bahdanau attention\r\n","\r\n","We will implement Bahdanau attention where:\r\n","\r\n","* FC = Fully connected (dense) layer\r\n","* EO = Encoder output\r\n","* H = hidden state\r\n","* X = input to the decoder\r\n","\r\n","And the pseudo-code:\r\n","\r\n","* `score = FC(tanh(FC(EO) + FC(H)))`\r\n","* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, hidden_size)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\r\n","* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\r\n","* `embedding output` = The input to the decoder X is passed through an embedding layer.\r\n","* `merged vector = concat(embedding output, context vector)`\r\n","* This merged vector is then given to the GRU\r\n","\r\n","The shapes of all the vectors at each step have been specified in the comments in the code:"]},{"cell_type":"code","metadata":{"id":"mnwdpiNgJr9z","executionInfo":{"status":"ok","timestamp":1610350655054,"user_tz":480,"elapsed":472,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["#@markdown <img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\r\n","#@markdown <img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\r\n","class BahdanauAttention(Layer):\r\n","    def __init__(self, units):\r\n","        super(BahdanauAttention, self).__init__()\r\n","        self.W1 = Dense(units)\r\n","        self.W2 = Dense(units)\r\n","        self.V = Dense(1)\r\n","\r\n","    def call(self, query, values):\r\n","        # query hidden state shape == (batch_size, hidden size)\r\n","        # query_with_time_axis shape == (batch_size, 1, hidden size)\r\n","        # values shape == (batch_size, max_len, hidden size)\r\n","        # we are doing this to broadcast addition along the time axis to \r\n","        # calculate the score\r\n","        query_with_time_axis = tf.expand_dims(query, 1)\r\n","\r\n","        # score shape == (batch_size, max_length, 1)\r\n","        # we get 1 at the last axis because we are applying score to self.V\r\n","        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\r\n","        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\r\n","\r\n","        # attention_weights shape == (batch_size, max_length, 1)\r\n","        attention_weights = tf.nn.softmax(score, axis=1)\r\n","\r\n","        # context_vector shape after sum == (batch_size, hidden_size)\r\n","        context_vector = attention_weights * values\r\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\r\n","\r\n","        return context_vector, attention_weights\r\n"],"execution_count":109,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osU0ZK0tYQIe","executionInfo":{"status":"ok","timestamp":1610350666678,"user_tz":480,"elapsed":529,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"a4f449eb-f8e7-4366-ca93-163f6a180a16"},"source":["attention_layer = BahdanauAttention(10)\r\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\r\n","\r\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\r\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"execution_count":110,"outputs":[{"output_type":"stream","text":["Attention result shape: (batch size, units) (64, 1024)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 8, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bqT04VJnYY-s","executionInfo":{"status":"ok","timestamp":1610350713730,"user_tz":480,"elapsed":331,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["class Decoder(tf.keras.Model):\r\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\r\n","    super(Decoder, self).__init__()\r\n","    self.batch_sz = batch_sz\r\n","    self.dec_units = dec_units\r\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\r\n","    self.gru = tf.keras.layers.GRU(self.dec_units,\r\n","                                   return_sequences=True,\r\n","                                   return_state=True,\r\n","                                   recurrent_initializer='glorot_uniform')\r\n","    self.fc = tf.keras.layers.Dense(vocab_size)\r\n","\r\n","    # used for attention\r\n","    self.attention = BahdanauAttention(self.dec_units)\r\n","\r\n","  def call(self, x, hidden, enc_output):\r\n","    # enc_output shape == (batch_size, max_length, hidden_size)\r\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\r\n","\r\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\r\n","    x = self.embedding(x)\r\n","\r\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\r\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\r\n","\r\n","    # passing the concatenated vector to the GRU\r\n","    output, state = self.gru(x)\r\n","\r\n","    # output shape == (batch_size * 1, hidden_size)\r\n","    output = tf.reshape(output, (-1, output.shape[2]))\r\n","\r\n","    # output shape == (batch_size, vocab)\r\n","    x = self.fc(output)\r\n","\r\n","    return x, state, attention_weights"],"execution_count":113,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQtjQAUEYbpq","executionInfo":{"status":"ok","timestamp":1610350746504,"user_tz":480,"elapsed":426,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"402614c4-e9ef-4c75-9c87-3526a828b27c"},"source":["decoder = Decoder(VOCAB_TARGET_SIZE, EMBEDDING_DIM, UNITS, BATCH_SIZE)\r\n","\r\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\r\n","                                      sample_hidden, sample_output)\r\n","\r\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"execution_count":115,"outputs":[{"output_type":"stream","text":["Decoder output shape: (batch_size, vocab size) (64, 1036)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LQOCUkO0YlmO","executionInfo":{"status":"ok","timestamp":1610350765030,"user_tz":480,"elapsed":252,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["optimizer = tf.keras.optimizers.Adam()\r\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n","    from_logits=True, reduction='none')\r\n","\r\n","def loss_function(real, pred):\r\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\r\n","  loss_ = loss_object(real, pred)\r\n","\r\n","  mask = tf.cast(mask, dtype=loss_.dtype)\r\n","  loss_ *= mask\r\n","\r\n","  return tf.reduce_mean(loss_)"],"execution_count":116,"outputs":[]},{"cell_type":"code","metadata":{"id":"EhI5yCObYsJi","executionInfo":{"status":"ok","timestamp":1610350774944,"user_tz":480,"elapsed":304,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["checkpoint_dir = './training_checkpoints'\r\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\r\n","                                 encoder=encoder,\r\n","                                 decoder=decoder)"],"execution_count":117,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkOWoifgYu9W","executionInfo":{"status":"ok","timestamp":1610350934357,"user_tz":480,"elapsed":535,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["@tf.function\r\n","def train_step(inp, targ, enc_hidden):\r\n","  loss = 0\r\n","\r\n","  with tf.GradientTape() as tape:\r\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\r\n","\r\n","    dec_hidden = enc_hidden\r\n","\r\n","    dec_input = tf.expand_dims([en_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\r\n","\r\n","    # Teacher forcing - feeding the target as the next input\r\n","    for t in range(1, targ.shape[1]):\r\n","      # passing enc_output to the decoder\r\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\r\n","\r\n","      loss += loss_function(targ[:, t], predictions)\r\n","\r\n","      # using teacher forcing\r\n","      dec_input = tf.expand_dims(targ[:, t], 1)\r\n","\r\n","  batch_loss = (loss / int(targ.shape[1]))\r\n","\r\n","  variables = encoder.trainable_variables + decoder.trainable_variables\r\n","\r\n","  gradients = tape.gradient(loss, variables)\r\n","\r\n","  optimizer.apply_gradients(zip(gradients, variables))\r\n","\r\n","  return batch_loss"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"id":"hmcm3_s7YwVh","executionInfo":{"status":"error","timestamp":1610350937046,"user_tz":480,"elapsed":650,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"19010d58-9555-482c-d25a-50f67fc2ba5b"},"source":["EPOCHS = 10\r\n","\r\n","for epoch in range(EPOCHS):\r\n","  start = time.time()\r\n","\r\n","  enc_hidden = encoder.initialize_hidden_state()\r\n","  total_loss = 0\r\n","\r\n","  for (batch, (inp, targ)) in enumerate(dataset.take(STEPS_PER_EPOCH)):\r\n","    batch_loss = train_step(inp, targ, enc_hidden)\r\n","    total_loss += batch_loss\r\n","\r\n","    if batch % 100 == 0:\r\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\r\n","                                                   batch,\r\n","                                                   batch_loss.numpy()))\r\n","  # saving (checkpoint) the model every 2 epochs\r\n","  if (epoch + 1) % 2 == 0:\r\n","    checkpoint.save(file_prefix = checkpoint_prefix)\r\n","\r\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\r\n","                                      total_loss / steps_per_epoch))\r\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":124,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-124-09903f55127d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: in user code:\n\n    <ipython-input-123-d20897873df4>:10 train_step  *\n        dec_input = tf.expand_dims([en_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n\n    KeyError: '<start>'\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bExowuVmY0UO","executionInfo":{"status":"ok","timestamp":1610351116713,"user_tz":480,"elapsed":336,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"d7ac8296-3e89-4e9d-bc49-f953c953c340"},"source":["en_lang_tokenizer.word_index"],"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'.<end>': 1,\n"," '<start>i': 2,\n"," '?<end>': 3,\n"," 's': 4,\n"," 'm': 5,\n"," '!<end>': 6,\n"," '<start>tom': 7,\n"," 'it': 8,\n"," 'you': 9,\n"," 'tom': 10,\n"," '<start>we': 11,\n"," '<start>he': 12,\n"," '<start>it': 13,\n"," 'is': 14,\n"," 'me': 15,\n"," 'a': 16,\n"," 't': 17,\n"," '<start>you': 18,\n"," 're': 19,\n"," 'this': 20,\n"," '<start>come': 21,\n"," 'll': 22,\n"," 'go': 23,\n"," 'in': 24,\n"," 'up': 25,\n"," '<start>go': 26,\n"," '<start>let': 27,\n"," '<start>is': 28,\n"," '<start>don': 29,\n"," 'on': 30,\n"," 'him': 31,\n"," '<start>who': 32,\n"," 'here': 33,\n"," 'am': 34,\n"," '<start>are': 35,\n"," 'can': 36,\n"," '<start>that': 37,\n"," '<start>be': 38,\n"," '<start>they': 39,\n"," 'that': 40,\n"," 'like': 41,\n"," '<start>get': 42,\n"," 'was': 43,\n"," 'love': 44,\n"," 'out': 45,\n"," '<start>keep': 46,\n"," '<start>look': 47,\n"," 'us': 48,\n"," '<start>do': 49,\n"," '<start>stop': 50,\n"," 'home': 51,\n"," 'i': 52,\n"," '<start>how': 53,\n"," '<start>what': 54,\n"," 'know': 55,\n"," 'saw': 56,\n"," 'need': 57,\n"," '<start>take': 58,\n"," 'not': 59,\n"," '<start>she': 60,\n"," 'help': 61,\n"," 'away': 62,\n"," '<start>have': 63,\n"," 'see': 64,\n"," '<start>can': 65,\n"," 'want': 66,\n"," '<start>no': 67,\n"," 'to': 68,\n"," 'do': 69,\n"," 'lost': 70,\n"," 'come': 71,\n"," 'them': 72,\n"," 'down': 73,\n"," '<start>this': 74,\n"," 'ok': 75,\n"," 'back': 76,\n"," 'so': 77,\n"," 'one': 78,\n"," '<start>stay': 79,\n"," '<start>here': 80,\n"," 'again': 81,\n"," 'have': 82,\n"," '<start>help': 83,\n"," 'won': 84,\n"," 'fat': 85,\n"," 'old': 86,\n"," 'he': 87,\n"," 'over': 88,\n"," 'good': 89,\n"," 'hate': 90,\n"," 'loved': 91,\n"," 'work': 92,\n"," '<start>try': 93,\n"," ',': 94,\n"," 'still': 95,\n"," 'got': 96,\n"," 'new': 97,\n"," 'are': 98,\n"," 'broke': 99,\n"," 'mine': 100,\n"," '<start>please': 101,\n"," 'at': 102,\n"," 'may': 103,\n"," 'sick': 104,\n"," 'for': 105,\n"," 'wait': 106,\n"," 'right': 107,\n"," 'way': 108,\n"," 'fun': 109,\n"," '<start>leave': 110,\n"," '<start>watch': 111,\n"," 'made': 112,\n"," '<start>wait': 113,\n"," 'try': 114,\n"," '<start>ask': 115,\n"," 'we': 116,\n"," 'sing': 117,\n"," 'alone': 118,\n"," 'happy': 119,\n"," 'time': 120,\n"," 'her': 121,\n"," 'be': 122,\n"," 'with': 123,\n"," 'now': 124,\n"," 'nice': 125,\n"," 'came': 126,\n"," 'ate': 127,\n"," 'free': 128,\n"," 'hurt': 129,\n"," 'rich': 130,\n"," 'busy': 131,\n"," 'walk': 132,\n"," 'tired': 133,\n"," 'bad': 134,\n"," '<start>did': 135,\n"," '<start>call': 136,\n"," 'did': 137,\n"," 'get': 138,\n"," 'full': 139,\n"," 'mean': 140,\n"," 'warm': 141,\n"," '<start>follow': 142,\n"," '<start>forget': 143,\n"," 'gave': 144,\n"," 'eat': 145,\n"," '<start>say': 146,\n"," 'hot': 147,\n"," '<start>check': 148,\n"," '<start>give': 149,\n"," 'feel': 150,\n"," 'dog': 151,\n"," 'the': 152,\n"," 'ran': 153,\n"," 'no': 154,\n"," 'quit': 155,\n"," 'cool': 156,\n"," 'hit': 157,\n"," 'shy': 158,\n"," '<start>find': 159,\n"," 'failed': 160,\n"," 'bald': 161,\n"," 'fine': 162,\n"," 'sad': 163,\n"," 'died': 164,\n"," 'miss': 165,\n"," 'stop': 166,\n"," 'there': 167,\n"," 'mad': 168,\n"," 'move': 169,\n"," 'said': 170,\n"," 'moving': 171,\n"," 'my': 172,\n"," 'don': 173,\n"," '<start>send': 174,\n"," '<start>hi': 175,\n"," '<start>hold': 176,\n"," 'moved': 177,\n"," 'tried': 178,\n"," 'care': 179,\n"," 'ahead': 180,\n"," 'okay': 181,\n"," '<start>sit': 182,\n"," '<start>stand': 183,\n"," 'knew': 184,\n"," 'cry': 185,\n"," 'awake': 186,\n"," 'first': 187,\n"," 'yours': 188,\n"," 'cold': 189,\n"," 'talk': 190,\n"," 'lying': 191,\n"," 'read': 192,\n"," 'felt': 193,\n"," 'dead': 194,\n"," '<start>was': 195,\n"," '<start>nobody': 196,\n"," '<start>now': 197,\n"," 'left': 198,\n"," 'kind': 199,\n"," '<start>wake': 200,\n"," 'run': 201,\n"," 'guys': 202,\n"," 'talked': 203,\n"," 'pay': 204,\n"," 'weak': 205,\n"," 'his': 206,\n"," 'some': 207,\n"," '<start>answer': 208,\n"," 'ask': 209,\n"," 'fainted': 210,\n"," 'cook': 211,\n"," 'drunk': 212,\n"," '<start>sign': 213,\n"," '<start>all': 214,\n"," 'wrong': 215,\n"," '<start>bring': 216,\n"," 'stay': 217,\n"," 'found': 218,\n"," 'must': 219,\n"," 'hungry': 220,\n"," 'single': 221,\n"," 'big': 222,\n"," 'cheese': 223,\n"," 'these': 224,\n"," 'had': 225,\n"," 'has': 226,\n"," 'snow': 227,\n"," 'married': 228,\n"," 'all': 229,\n"," 'car': 230,\n"," 'cheated': 231,\n"," 'book': 232,\n"," 'another': 233,\n"," 'fell': 234,\n"," '<start>why': 235,\n"," 'calm': 236,\n"," '<start>hang': 237,\n"," '<start>am': 238,\n"," 'off': 239,\n"," 'quiet': 240,\n"," 'real': 241,\n"," '<start>grab': 242,\n"," 'agreed': 243,\n"," 'phoned': 244,\n"," 'smiled': 245,\n"," 'done': 246,\n"," 'late': 247,\n"," 've': 248,\n"," 'works': 249,\n"," '<start>after': 250,\n"," '<start>catch': 251,\n"," '<start>feel': 252,\n"," 'ready': 253,\n"," 'live': 254,\n"," 'angry': 255,\n"," '<start>ignore': 256,\n"," 'true': 257,\n"," '<start>put': 258,\n"," '<start>seize': 259,\n"," 'stood': 260,\n"," 'early': 261,\n"," 'look': 262,\n"," 'swim': 263,\n"," 'remember': 264,\n"," '<start>smell': 265,\n"," '<start>finish': 266,\n"," 'will': 267,\n"," 'going': 268,\n"," 'an': 269,\n"," 'sure': 270,\n"," 'confident': 271,\n"," 'drink': 272,\n"," 'let': 273,\n"," '<start>examine': 274,\n"," 'annoying': 275,\n"," 'very': 276,\n"," '<start>fire': 277,\n"," '<start>listen': 278,\n"," 'agree': 279,\n"," 'too': 280,\n"," '<start>show': 281,\n"," 'man': 282,\n"," '<start>drive': 283,\n"," 'job': 284,\n"," 'cute': 285,\n"," '<start>hurry': 286,\n"," 'forgot': 287,\n"," 'waited': 288,\n"," 'easy': 289,\n"," 'poor': 290,\n"," 'safe': 291,\n"," '<start>speak': 292,\n"," '<start>warn': 293,\n"," '<start>write': 294,\n"," 'fire': 295,\n"," '<start>calm': 296,\n"," 'inside': 297,\n"," 'fast': 298,\n"," 'laughed': 299,\n"," 'sorry': 300,\n"," '<start>loosen': 301,\n"," '<start>move': 302,\n"," '<start>nice': 303,\n"," '<start>read': 304,\n"," 'walks': 305,\n"," 'start': 306,\n"," 'anyone': 307,\n"," 'around': 308,\n"," 'serious': 309,\n"," 'wine': 310,\n"," 'slowly': 311,\n"," 'life': 312,\n"," 'faith': 313,\n"," 'tall': 314,\n"," 'sat': 315,\n"," 'buy': 316,\n"," 'better': 317,\n"," 'sleepy': 318,\n"," 'trying': 319,\n"," 'alive': 320,\n"," 'great': 321,\n"," 'notes': 322,\n"," '<start>start': 323,\n"," '<start>talk': 324,\n"," 'called': 325,\n"," 'walked': 326,\n"," 'deaf': 327,\n"," 'well': 328,\n"," '<start>where': 329,\n"," 'missed': 330,\n"," '<start>as': 331,\n"," 'prepared': 332,\n"," '<start>count': 333,\n"," 'say': 334,\n"," 'smoke': 335,\n"," 'find': 336,\n"," 'likes': 337,\n"," 'curious': 338,\n"," 'dogs': 339,\n"," 'milk': 340,\n"," 'mess': 341,\n"," '<start>does': 342,\n"," 'half': 343,\n"," 'school': 344,\n"," 'pen': 345,\n"," 'confused': 346,\n"," '<start>got': 347,\n"," 'lied': 348,\n"," '<start>goodbye': 349,\n"," 'wet': 350,\n"," '<start>open': 351,\n"," '<start>see': 352,\n"," 'brief': 353,\n"," '<start>good': 354,\n"," 'tries': 355,\n"," '<start>humor': 356,\n"," 'by': 357,\n"," 'stayed': 358,\n"," 'use': 359,\n"," 'lazy': 360,\n"," 'next': 361,\n"," 'helps': 362,\n"," '<start>kiss': 363,\n"," '<start>aim': 364,\n"," '<start>birds': 365,\n"," '<start>fantastic': 366,\n"," 'shaved': 367,\n"," 'crazy': 368,\n"," 'stinks': 369,\n"," 'worked': 370,\n"," 'hers': 371,\n"," 'shot': 372,\n"," '<start>step': 373,\n"," '<start>thank': 374,\n"," 'cared': 375,\n"," 'cares': 376,\n"," 'cried': 377,\n"," 'voted': 378,\n"," 'along': 379,\n"," 'boring': 380,\n"," 'lovely': 381,\n"," 'hear': 382,\n"," 'tea': 383,\n"," 'd': 384,\n"," 'french': 385,\n"," 'liar': 386,\n"," 'ill': 387,\n"," 'town': 388,\n"," 'problem': 389,\n"," 'sit': 390,\n"," 'please': 391,\n"," 'close': 392,\n"," 'aside': 393,\n"," '<start>taste': 394,\n"," 'cheat': 395,\n"," 'bit': 396,\n"," 'gasped': 397,\n"," 'helped': 398,\n"," 'winked': 399,\n"," 'yelled': 400,\n"," 'die': 401,\n"," '<start>turn': 402,\n"," 'win': 403,\n"," '<start>anyone': 404,\n"," 'specific': 405,\n"," 'begin': 406,\n"," 'shoot': 407,\n"," 'meet': 408,\n"," 'sleep': 409,\n"," '<start>has': 410,\n"," 'hated': 411,\n"," 'nasty': 412,\n"," 'young': 413,\n"," 'jerk': 414,\n"," 'stupid': 415,\n"," 'she': 416,\n"," 'share': 417,\n"," 'dumb': 418,\n"," 'rock': 419,\n"," 'needed': 420,\n"," 'trust': 421,\n"," 'went': 422,\n"," 'woman': 423,\n"," 'broken': 424,\n"," 'chilly': 425,\n"," '<start>make': 426,\n"," 'timing': 427,\n"," 'cheered': 428,\n"," 'crashed': 429,\n"," 'why': 430,\n"," 'pity': 431,\n"," '<start>will': 432,\n"," 'nuts': 433,\n"," 'objective': 434,\n"," '<start>describe': 435,\n"," 'cat': 436,\n"," 'face': 437,\n"," 'cut': 438,\n"," 'myself': 439,\n"," 'didn': 440,\n"," 'carded': 441,\n"," 'doctor': 442,\n"," 'freezing': 443,\n"," 'restless': 444,\n"," '<start>run': 445,\n"," '<start>jump': 446,\n"," '<start>attack': 447,\n"," '<start>hug': 448,\n"," '<start>really': 449,\n"," '<start>thanks': 450,\n"," 'fair': 451,\n"," 'bowed': 452,\n"," '<start>join': 453,\n"," '<start>shut': 454,\n"," '<start>so': 455,\n"," 'long': 456,\n"," '<start>tell': 457,\n"," '<start>welcome': 458,\n"," '<start>back': 459,\n"," 'brave': 460,\n"," '<start>cheer': 461,\n"," '<start>cool': 462,\n"," 'deep': 463,\n"," 'resign': 464,\n"," 'tidy': 465,\n"," 'hurts': 466,\n"," 'odd': 467,\n"," 'runs': 468,\n"," '<start>terrific': 469,\n"," 'swam': 470,\n"," 'wept': 471,\n"," '<start>trust': 472,\n"," 'hard': 473,\n"," '.': 474,\n"," 'fly': 475,\n"," 'lie': 476,\n"," 'bed': 477,\n"," 'dj': 478,\n"," 'beg': 479,\n"," 'ski': 480,\n"," 'dying': 481,\n"," 'burned': 482,\n"," 'tv': 483,\n"," 'ours': 484,\n"," '<start>lie': 485,\n"," 'above': 486,\n"," 'tight': 487,\n"," '<start>slow': 488,\n"," 'dozed': 489,\n"," 'knows': 490,\n"," 'drive': 491,\n"," 'higher': 492,\n"," 'aboard': 493,\n"," 'careful': 494,\n"," 'patient': 495,\n"," 'quick': 496,\n"," 'men': 497,\n"," 'jump': 498,\n"," '<start>eat': 499,\n"," 'burns': 500,\n"," '<start>forgive': 501,\n"," 'hung': 502,\n"," 'smart': 503,\n"," '<start>hey': 504,\n"," 'relax': 505,\n"," 'bored': 506,\n"," 'envy': 507,\n"," 'art': 508,\n"," 'liked': 509,\n"," 'ice': 510,\n"," 'promised': 511,\n"," 'resigned': 512,\n"," 'yes': 513,\n"," 'screamed': 514,\n"," 'survived': 515,\n"," 'think': 516,\n"," 'told': 517,\n"," 'wrote': 518,\n"," 'hero': 519,\n"," 'eating': 520,\n"," 'faster': 521,\n"," 'normal': 522,\n"," 'skinny': 523,\n"," 'twelve': 524,\n"," 'green': 525,\n"," 'night': 526,\n"," 'windy': 527,\n"," '<start>just': 528,\n"," 'chat': 529,\n"," 'kidding': 530,\n"," 'alert': 531,\n"," 'boy': 532,\n"," '<start>time': 533,\n"," 'danced': 534,\n"," 'drinks': 535,\n"," 'fought': 536,\n"," 'obeyed': 537,\n"," 'prayed': 538,\n"," 'even': 539,\n"," 'gives': 540,\n"," 'punctual': 541,\n"," 'sensible': 542,\n"," 'thorough': 543,\n"," 'tolerant': 544,\n"," 'closer': 545,\n"," '<start>cook': 546,\n"," 'later': 547,\n"," 'fight': 548,\n"," 'leave': 549,\n"," 'shout': 550,\n"," 'smile': 551,\n"," 'speak': 552,\n"," 'worry': 553,\n"," '<start>flip': 554,\n"," 'coin': 555,\n"," 'seat': 556,\n"," 'strange': 557,\n"," 'joking': 558,\n"," 'bought': 559,\n"," 'lot': 560,\n"," 'bread': 561,\n"," 'fruit': 562,\n"," 'sand': 563,\n"," 'heard': 564,\n"," 'fish': 565,\n"," 'kids': 566,\n"," 'math': 567,\n"," 'often': 568,\n"," 'smell': 569,\n"," 'gas': 570,\n"," 'dizzy': 571,\n"," 'fired': 572,\n"," 'naive': 573,\n"," 'loser': 574,\n"," 'baffled': 575,\n"," 'excited': 576,\n"," 'jittery': 577,\n"," 'starved': 578,\n"," 'working': 579,\n"," 'happened': 580,\n"," 'monday': 581,\n"," 'harp': 582,\n"," 'party': 583,\n"," 'list': 584,\n"," '<start>memorize': 585,\n"," '<start>money': 586,\n"," 'talks': 587,\n"," 'means': 588,\n"," 'crying': 589,\n"," 'card': 590,\n"," '<start>there': 591,\n"," 'hugged': 592,\n"," '<start>think': 593,\n"," 'changed': 594,\n"," 'escaped': 595,\n"," 'prepaid': 596,\n"," 'refused': 597,\n"," 'relaxed': 598,\n"," 'dope': 599,\n"," 'pain': 600,\n"," 'keep': 601,\n"," '<start>anybody': 602,\n"," '<start>bear': 603,\n"," 'and': 604,\n"," 'anytime': 605,\n"," 'call': 606,\n"," 'sign': 607,\n"," 'they': 608,\n"," 'snore': 609,\n"," '<start>happy': 610,\n"," 'easter': 611,\n"," 'donut': 612,\n"," 'courage': 613,\n"," 'cranky': 614,\n"," 'admire': 615,\n"," 'apples': 616,\n"," 'drank': 617,\n"," 'woozy': 618,\n"," 'framed': 619,\n"," 'opera': 620,\n"," 'sushi': 621,\n"," 'money': 622,\n"," 'books': 623,\n"," 'paint': 624,\n"," 'water': 625,\n"," 'understand': 626,\n"," 'lonely': 627,\n"," 'lose': 628,\n"," 'adult': 629,\n"," 'rebel': 630,\n"," 'pregnant': 631,\n"," 'starving': 632,\n"," 'thinking': 633,\n"," '<start>hello': 634,\n"," '<start>oh': 635,\n"," '<start>relax': 636,\n"," '<start>smile': 637,\n"," '<start>hop': 638,\n"," '<start>awesome': 639,\n"," '<start>beat': 640,\n"," '<start>drop': 641,\n"," 'slow': 642,\n"," '<start>hit': 643,\n"," 'slept': 644,\n"," 'fit': 645,\n"," '<start>me': 646,\n"," '<start>perfect': 647,\n"," '<start>skip': 648,\n"," '<start>wash': 649,\n"," '<start>cuff': 650,\n"," '<start>fix': 651,\n"," 'spoke': 652,\n"," 'refuse': 653,\n"," 'thin': 654,\n"," 'wise': 655,\n"," 'red': 656,\n"," '<start>marry': 657,\n"," '<start>may': 658,\n"," '<start>save': 659,\n"," 'put': 660,\n"," 'lies': 661,\n"," 'paid': 662,\n"," '<start>too': 663,\n"," '<start>use': 664,\n"," '<start>bless': 665,\n"," 'soon': 666,\n"," '<start>dogs': 667,\n"," 'bark': 668,\n"," 'awful': 669,\n"," 'weird': 670,\n"," 'cringed': 671,\n"," 'hope': 672,\n"," 'tripped': 673,\n"," 'pro': 674,\n"," 'blind': 675,\n"," 'obese': 676,\n"," 'far': 677,\n"," 'rained': 678,\n"," 'snowed': 679,\n"," 'dark': 680,\n"," '<start>of': 681,\n"," 'course': 682,\n"," '<start>pardon': 683,\n"," 'hello': 684,\n"," '<start>search': 685,\n"," '<start>seriously': 686,\n"," '<start>then': 687,\n"," 'what': 688,\n"," 'drove': 689,\n"," 'knits': 690,\n"," 'rocks': 691,\n"," 'swims': 692,\n"," 'swore': 693,\n"," 'waved': 694,\n"," 'content': 695,\n"," 'food': 696,\n"," '<start>carry': 697,\n"," '<start>choose': 698,\n"," '<start>cut': 699,\n"," 'yell': 700,\n"," '<start>god': 701,\n"," 'exists': 702,\n"," 'coughed': 703,\n"," 'cruel': 704,\n"," 'tragic': 705,\n"," 'admit': 706,\n"," 'human': 707,\n"," 'chuckled': 708,\n"," 'disagree': 709,\n"," 'doubt': 710,\n"," 'meat': 711,\n"," 'threw': 712,\n"," 'twin': 713,\n"," 'bushed': 714,\n"," 'buying': 715,\n"," 'clumsy': 716,\n"," 'coming': 717,\n"," 'greedy': 718,\n"," 'hiding': 719,\n"," 'immune': 720,\n"," 'scared': 721,\n"," 'eaten': 722,\n"," 'happens': 723,\n"," 'empty': 724,\n"," 'magic': 725,\n"," 'cd': 726,\n"," 'white': 727,\n"," '<start>jesus': 728,\n"," 'kiss': 729,\n"," 'play': 730,\n"," 'vote': 731,\n"," '<start>lift': 732,\n"," '<start>love': 733,\n"," 'lasts': 734,\n"," '<start>mama': 735,\n"," 'comment': 736,\n"," '<start>quiet': 737,\n"," '<start>replace': 738,\n"," '<start>sing': 739,\n"," 'sharp': 740,\n"," '<start>study': 741,\n"," 'bus': 742,\n"," 'flies': 743,\n"," 'agrees': 744,\n"," 'burped': 745,\n"," 'cheats': 746,\n"," 'dances': 747,\n"," 'drives': 748,\n"," 'goofed': 749,\n"," 'jumped': 750,\n"," 'looked': 751,\n"," 'moaned': 752,\n"," 'nodded': 753,\n"," 'paused': 754,\n"," 'sighed': 755,\n"," 'snores': 756,\n"," 'yawned': 757,\n"," 'glad': 758,\n"," 'gone': 759,\n"," 'ugly': 760,\n"," 'cds': 761,\n"," 'fail': 762,\n"," 'day': 763,\n"," '<start>wood': 764,\n"," 'decide': 765,\n"," 'anybody': 766,\n"," 'creative': 767,\n"," 'discreet': 768,\n"," 'merciful': 769,\n"," 'vigilant': 770,\n"," 'watchful': 771,\n"," '<start>beer': 772,\n"," '<start>comfort': 773,\n"," '<start>contact': 774,\n"," 'as': 775,\n"," 'bowl': 776,\n"," 'argue': 777,\n"," 'laugh': 778,\n"," 'dressed': 779,\n"," 'straight': 780,\n"," 'grew': 781,\n"," 'guts': 782,\n"," 'eight': 783,\n"," 'faking': 784,\n"," 'strong': 785,\n"," 'monk': 786,\n"," 'dozing': 787,\n"," 'taller': 788,\n"," 'apologize': 789,\n"," 'asked': 790,\n"," 'blame': 791,\n"," 'confessed': 792,\n"," 'cats': 793,\n"," 'rats': 794,\n"," 'news': 795,\n"," 'hired': 796,\n"," 'both': 797,\n"," 'jazz': 798,\n"," 'rice': 799,\n"," 'beer': 800,\n"," 'golf': 801,\n"," 'soup': 802,\n"," 'hide': 803,\n"," 'never': 804,\n"," 'overslept': 805,\n"," 'taxes': 806,\n"," 'lips': 807,\n"," 'ufo': 808,\n"," 'sell': 809,\n"," 'cars': 810,\n"," 'should': 811,\n"," 'thank': 812,\n"," 'more': 813,\n"," 'lucky': 814,\n"," 'naked': 815,\n"," 'change': 816,\n"," 'baker': 817,\n"," 'cooking': 818,\n"," 'dancing': 819,\n"," 'engaged': 820,\n"," 'fasting': 821,\n"," 'finicky': 822,\n"," 'healthy': 823,\n"," 'jail': 824,\n"," 'leaving': 825,\n"," 'nervous': 826,\n"," 'neutral': 827,\n"," 'psyched': 828,\n"," 'reading': 829,\n"," 'resting': 830,\n"," 'selfish': 831,\n"," 'sloshed': 832,\n"," 'through': 833,\n"," 'trapped': 834,\n"," 'unlucky': 835,\n"," 'waiting': 836,\n"," 'worried': 837,\n"," 'cost': 838,\n"," 'rain': 839,\n"," 'saved': 840,\n"," 'yen': 841,\n"," 'doll': 842,\n"," 'joke': 843,\n"," 'rule': 844,\n"," 'song': 845,\n"," 'vice': 846,\n"," 'cloudy': 847,\n"," 'futile': 848,\n"," 'secret': 849,\n"," 'dance': 850,\n"," 'hurry': 851,\n"," '<start>life': 852,\n"," 'wish': 853,\n"," '<start>many': 854,\n"," 'thanks': 855,\n"," 'hold': 856,\n"," 'shut': 857,\n"," '<start>ok': 858,\n"," '<start>one': 859,\n"," 'blue': 860,\n"," '<start>release': 861,\n"," '<start>remember': 862,\n"," '<start>return': 863,\n"," 'goodbye': 864,\n"," 'nothing': 865,\n"," '<start>shall': 866,\n"," 'woke': 867,\n"," 'fox': 868,\n"," '<start>should': 869,\n"," 'how': 870,\n"," '<start>sleep': 871,\n"," '!': 872,\n"," 'thief': 873,\n"," 'rest': 874,\n"," 'action': 875,\n"," '<start>tea': 876,\n"," 'huge': 877,\n"," '<start>the': 878,\n"," 'kissed': 879,\n"," 'arrived': 880,\n"," 'blushed': 881,\n"," 'clapped': 882,\n"," 'decided': 883,\n"," 'drowned': 884,\n"," 'exhaled': 885,\n"," 'giggled': 886,\n"," 'gloated': 887,\n"," 'grinned': 888,\n"," 'groaned': 889,\n"," 'grunted': 890,\n"," 'ocd': 891,\n"," 'inhaled': 892,\n"," 'evil': 893,\n"," 'kneeled': 894,\n"," 'listens': 895,\n"," 'shouted': 896,\n"," 'slipped': 897,\n"," 'sneezed': 898,\n"," 'teaches': 899,\n"," 'flaky': 900,\n"," 'funny': 901,\n"," 'upset': 902,\n"," '<start>walk': 903,\n"," 'eggs': 904,\n"," 'act': 905,\n"," 'clean': 906,\n"," 'twins': 907,\n"," 'heel': 908,\n"," 'loss': 909,\n"," 'team': 910,\n"," 'ego': 911,\n"," 'drew': 912,\n"," '<start>whose': 913,\n"," '<start>yes': 914,\n"," '<start>abandon': 915,\n"," 'ship': 916,\n"," '<start>act': 917,\n"," 'your': 918,\n"," 'age': 919,\n"," 'invited': 920,\n"," '<start>anything': 921,\n"," 'mary': 922,\n"," 'attentive': 923,\n"," 'merciless': 924,\n"," 'realistic': 925,\n"," '<start>beef': 926,\n"," '<start>boil': 927,\n"," 'egg': 928,\n"," 'backup': 929,\n"," 'hat': 930,\n"," 'fbi': 931,\n"," 'once': 932,\n"," 'forward': 933,\n"," 'outside': 934,\n"," 'quickly': 935,\n"," 'show': 936,\n"," 'ramble': 937,\n"," 'scream': 938,\n"," 'safely': 939,\n"," '<start>fight': 940,\n"," 'or': 941,\n"," 'upstairs': 942,\n"," '<start>ghosts': 943,\n"," 'exist': 944,\n"," 'morning': 945,\n"," 'snack': 946,\n"," 'avoids': 947,\n"," 'denied': 948,\n"," 'driven': 949,\n"," 'kicked': 950,\n"," 'loves': 951,\n"," 'seems': 952,\n"," 'bigot': 953,\n"," 'ninja': 954,\n"," 'dieting': 955,\n"," 'jealous': 956,\n"," 'arrogant': 957,\n"," 'horrible': 958,\n"," 'romantic': 959,\n"," 'chinese': 960,\n"," 'injured': 961,\n"," 'praying': 962,\n"," 'apologized': 963,\n"," 'caviar': 964,\n"," 'lip': 965,\n"," 'fix': 966,\n"," 'could': 967,\n"," 'detest': 968,\n"," 'mind': 969,\n"," 'faint': 970,\n"," 'mugged': 971,\n"," 'doubts': 972,\n"," 'liars': 973,\n"," 'rules': 974,\n"," 'key': 975,\n"," 'music': 976,\n"," 'just': 977,\n"," 'china': 978,\n"," 'beans': 979,\n"," 'candy': 980,\n"," 'chess': 981,\n"," 'honey': 982,\n"," 'pizza': 983,\n"," 'women': 984,\n"," 'games': 985,\n"," 'trips': 986,\n"," 'bet': 987,\n"," 'misled': 988,\n"," 'cab': 989,\n"," 'hug': 990,\n"," 'nap': 991,\n"," 'space': 992,\n"," 'lion': 993,\n"," 'star': 994,\n"," 'sympathize': 995,\n"," 'warned': 996,\n"," 'afraid': 997,\n"," 'twice': 998,\n"," 'wonder': 999,\n"," 'risk': 1000,\n"," ...}"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"id":"h_1kku-MaAAU"},"source":[""],"execution_count":null,"outputs":[]}]}