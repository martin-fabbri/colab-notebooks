{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_from_scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxzGcgznaJ8uAuW0lM5rUL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/rnn/rnn_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzjc2dlH2GsQ"
      },
      "source": [
        "# Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUVIbX8I4_gR"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from numpy.random import randint\n",
        "from collections import OrderedDict\n",
        "from torch.utils import data\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uzAyRHP2U7H"
      },
      "source": [
        "## Representing text as tokens\n",
        "\n",
        "Let's define our dataset samples $x \\in \\mathrm{R}^d$, where $d$ is the feature space dimension.\n",
        "\n",
        "With time sequences our data can be represented as $x \\in \\mathrm{R}^{t \\, \\times \\, d}$, where $t$ is the sequence length. \n",
        "This emphasises sequence dependence and that the samples along the sequence are not independent and identically distributed (i.i.d.).\n",
        "We will model functions as $\\mathrm{R}^{t \\, \\times \\, d} \\rightarrow \\mathrm{R}^c$, where $c$ is the amount of classes in the output.\n",
        "\n",
        "There are several ways to represent sequences. With text, the challenge is how to represent a word as a feature vector in $d$ dimensions, as we are required to represent text with decimal numbers in order to apply neural networks to it.\n",
        "\n",
        "Initially, we will use a simple one-hot encoding but for categorical variables that can take on many values (e.g. words in the English language)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-DRDHhQ3zs7"
      },
      "source": [
        "### One-hot encoding over vocabulary\n",
        "\n",
        "One way to represent a fixed amount of words is by making a one-hot encoded vector, which consists of 0s in all cells with the exception of a single 1 in a cell used uniquely to identify each word.\n",
        "\n",
        "| vocabulary    | one-hot encoded vector   |\n",
        "| ------------- |--------------------------|\n",
        "| Paris         | $= [1, 0, 0, \\ldots, 0]$ |\n",
        "| Rome          | $= [0, 1, 0, \\ldots, 0]$ |\n",
        "| Copenhagen    | $= [0, 0, 1, \\ldots, 0]$ |\n",
        "\n",
        "Representing a large vocabulary with one-hot encodings often becomes inefficient because of the size of each sparse vector.\n",
        "To overcome this challenge it is common practice to truncate the vocabulary to contain the $k$ most used words and represent the rest with a special symbol, $\\mathtt{UNK}$, to define unknown/unimportant words.\n",
        "This often causes entities such as names to be represented with $\\mathtt{UNK}$ because they are rare.\n",
        "\n",
        "Consider the following text\n",
        "> I love the corny jokes in Spielberg's new movie.\n",
        "\n",
        "where an example result would be similar to\n",
        "> I love the corny jokes in $\\mathtt{UNK}$'s new movie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ag97wDL4Ubv"
      },
      "source": [
        "### Generating a dataset\n",
        "\n",
        "We generate sequences of the form:\n",
        "\n",
        "`a b EOS`,\n",
        "\n",
        "`a a b b EOS`,\n",
        "\n",
        "`a a a a a b b b b b EOS`\n",
        "\n",
        "where `EOS` is a special character denoting the end of a sequence. The task is to predict the next token $t_n$, i.e. `a`, `b`, `EOS` or the unknown token `UNK` given a sequence of tokens $\\{ t_{1}, t_{2}, \\dots , t_{n-1}\\}$, and we are to process sequences in a sequential manner. As such, the network will need to learn that e.g. 5 `b`s and an `EOS` token will be preceded by 5 `a`s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVm_7FMdRtWL"
      },
      "source": [
        "CHARS = ['a', 'b']\n",
        "UNKNOWN = 'U'\n",
        "EOS = 'E'\n",
        "VOCAB = [UNKNOWN, EOS] + CHARS\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "NUM_SENTENCES = 2**8\n",
        "P_TRAIN = int(NUM_SENTENCES * 0.8)\n",
        "P_VAL = int(NUM_SENTENCES * 0.1)\n",
        "P_TEST = int(NUM_SENTENCES * 0.1)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSNcnPbA2AEj"
      },
      "source": [
        "def generate_dataset(num_sequences):\n",
        "  \"\"\"\n",
        "  Generated a number of sequences as out dataset.\n",
        "  \"\"\"\n",
        "  generate_random_token = lambda num_tokens: (\n",
        "      ''.join([c * num_tokens for c in CHARS]) + EOS\n",
        "  )\n",
        "  return [generate_random_token(randint(1, 12)) for _ in range(num_sequences)]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLtzsitq7Ekw",
        "outputId": "8bd61409-6d05-4e66-c0ae-4cbdad1f71c1"
      },
      "source": [
        "sequences = generate_dataset(NUM_SENTENCES)\n",
        "sequences[:5]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aaaaabbbbbE',\n",
              " 'aaaaabbbbbE',\n",
              " 'aaaaaaaaaaabbbbbbbbbbbE',\n",
              " 'aaaaaaabbbbbbbE',\n",
              " 'aaaaaaaaabbbbbbbbbE']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGpn9GHR9IHR"
      },
      "source": [
        "## Representing tokens as indices\n",
        "\n",
        "To build a one-hot encoding, we need to assign each possible word in our vocabulary an index. We do that by creating two dictionaries: one that allows us to go from a given word to its corresponding index in our vocabulary, and one for the reverse direction. Let's call them `word_to_idx` and `idx_to_word`. The keyword `vocab_size` specifies the maximum size of our vocabulary. If we try to access a word that does not exist in our vocabulary, it is automatically replaced by the `UNK` token or its corresponding index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-ArjKF4BZJ8"
      },
      "source": [
        "word_to_idx = OrderedDict((word, index) for index, word in enumerate(VOCAB)) \n",
        "idx_to_word = OrderedDict((index, word) for index, word in enumerate(VOCAB))\n",
        "vocab_size = len(VOCAB)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuiEBnlwXe-U"
      },
      "source": [
        "## Partitioning the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VafQndpbXW46"
      },
      "source": [
        "class Dataset(data.Dataset):\n",
        "  def __init__(self, inputs, targets):\n",
        "    self.inputs = inputs\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X = self.inputs[index]\n",
        "    y = self.targets[index]\n",
        "    return X, y"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGhRyIYrXW2G",
        "outputId": "b57a72aa-5546-4389-a7cf-5cf318a8d7fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = [sequences[i][:-1] for i in range(len(sequences))]\n",
        "targets = [sequences[i][1:] for i in range(len(sequences))]\n",
        "train_set = Dataset(inputs[:P_TRAIN], targets[:P_TRAIN])\n",
        "val_set = Dataset(inputs[P_TRAIN:P_TRAIN + P_VAL], targets[P_TRAIN:P_TRAIN + P_VAL])\n",
        "test_set = Dataset(inputs[-P_TEST:], targets[-P_TEST:])\n",
        "\n",
        "print(f'We have {len(train_set)} samples in the training set.')\n",
        "print(f'We have {len(val_set)} samples in the validation set.')\n",
        "print(f'We have {len(test_set)} samples in the test set.')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 204 samples in the training set.\n",
            "We have 25 samples in the validation set.\n",
            "We have 25 samples in the test set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plzXFcMvXWze",
        "outputId": "42634a63-a542-4c19-f3af-5e295923a535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "inputs[1]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aaaaabbbbb'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTrF5TmXekFa",
        "outputId": "76aa1668-6b6a-4779-ce9c-174e34ca90f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_set.targets[1]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aaaabbbbbE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Ukog4IfO7d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}