{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq-to-seq-keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPTRZ1eh3AZDjBWVA+vKg9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/rnn/seq_to_seq_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9ZxIisYLDxo"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQT0ooynK1F5"
      },
      "source": [
        "## LSTM quick recap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGEQ_UklLFR9"
      },
      "source": [
        "Creating a layer of LSTM memory units allows you to specify the `number of memory units` within the layer.\n",
        "\n",
        "```python\n",
        "lstm = tf.keras.layers.LTSM(30) # number of memory units=30\n",
        "```\n",
        "\n",
        "Each unit or cell within the layer has an `internal cell state` ($c$), and output a `hidden state` ($h$) \n",
        "\n",
        "```python\n",
        "inputs = Input(shape=(3, 1)\n",
        "lstm, state_h, state_c = tf.keras.layers.LTSM(1, return_state=True)(inputs)\n",
        "```\n",
        "\n",
        "Each LSTM cell will output one hidden state $h$ for each input.\n",
        "\n",
        "```python\n",
        "h = tf.keras.layers.LTSM(X)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD2GyT7cTUgH"
      },
      "source": [
        "# input time steps\n",
        "t1 = 0.1\n",
        "t2 = 0.2\n",
        "t3 = 0.3\n",
        "time_steps = [t1, t2, t3]\n",
        "one_memory_unit = 1"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc2NMUHRLFYN",
        "outputId": "5ecda9a6-934b-456f-995d-780d2ad02802"
      },
      "source": [
        "# define the model\n",
        "inputs1 = layers.Input(shape=(3, 1))\n",
        "lstm1 = layers.LSTM(one_memory_unit)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "\n",
        "# define input data -> inputs should include the \n",
        "# batch reference (batch, time steps->sequence length, ?)\n",
        "data = np.array(time_steps).reshape((1, 3, 1))\n",
        "\n",
        "# make a prediction -> should output a single scalar hidden state\n",
        "model.predict(data)[0][0]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7fc85f16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09254665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qmAyjbDRq_X"
      },
      "source": [
        "It's possible to access the `hidden state output` $\\ldots[\\hat{y}_{t-1}],[\\hat{y}_{t}],[\\hat{y}_{t+1}]\\ldots$ for each input time step. \n",
        "\n",
        "```python\n",
        "LSTM(1, return_sequences=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQEO7ucPLKOY",
        "outputId": "fb6ad618-3751-409d-a808-ca2bf4bcab3b"
      },
      "source": [
        "# define the model\n",
        "inputs1 = layers.Input(shape=(3, 1))\n",
        "lstm1 = layers.LSTM(one_memory_unit, return_sequences=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "\n",
        "# define input data -> inputs should include the \n",
        "# batch reference (batch, time steps->sequence length, ?)\n",
        "data = np.array(time_steps).reshape((1, 3, 1))\n",
        "\n",
        "# make a prediction -> should output y^ for each time step\n",
        "model.predict(data)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7fc7c23f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.01487367],\n",
              "        [0.04095905],\n",
              "        [0.07560855]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwr87gFDV7JT"
      },
      "source": [
        "Each LSTM call retains an `internal state` that `is not output`, called `cell state` ($c$).\n",
        "\n",
        "Keras provides the return_state argument to the LSTM layer that will provide access to the `hidden` state ($state_h$) and the `cell` state ($state_c$).\n",
        "\n",
        "```python\n",
        "lstm1, state_h, state_c = LSTM(1, return_state=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPWLhVXhLLon",
        "outputId": "9183824f-6a57-4249-e302-db3846e9c8b1"
      },
      "source": [
        "# define the model\n",
        "inputs1 = layers.Input(shape=(3, 1))\n",
        "lstm1, state_h, state_c = layers.LSTM(one_memory_unit, return_state=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "\n",
        "# define input data -> inputs should include the \n",
        "# batch reference (batch, time steps->sequence length, ?)\n",
        "data = np.array(time_steps).reshape((1, 3, 1))\n",
        "\n",
        "# make a prediction -> should output y^ for each time step\n",
        "model.predict(data)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7fc9c409d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01654461]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZpKWQGv1YkF"
      },
      "source": [
        "Hidden state fro the last time step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1M-PfKsXw-p",
        "outputId": "e6001365-20d8-49e1-c071-6bf0ebd3553e"
      },
      "source": [
        "state_h[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'strided_slice_11:0' shape=(1,) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXOHzh301cYp"
      },
      "source": [
        "Cell state for the last step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxEAaFXs0a_f",
        "outputId": "f9c03b0a-17b4-44a1-c7de-2c40cdb4f22f"
      },
      "source": [
        "state_c[0]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'strided_slice_12:0' shape=(1,) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXERevWR2ePP"
      },
      "source": [
        "## TimeDistributed Layer\n",
        "\n",
        "> This wrapper allows to apply a layer to every temporal slice of an input. `TimeDistributedDense` applies a same Dense (fully-connected) operation to every timestep of a 3D tensor.<br><br>\n",
        ">Consider a batch of 32 video samples, where each sample is a 128x128 RGB image with channels_last data format, across 10 timesteps. The batch input shape is (32, 10, 128, 128, 3).<br><br>\n",
        ">You can then use TimeDistributed to apply the same Conv2D layer to each of the 10 timesteps, independently:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm3u31aH01mV",
        "outputId": "e660a492-11ee-4a88-e2c2-2105e73e5e64"
      },
      "source": [
        "inputs = layers.Input(shape=(10, 128, 128, 3))\n",
        "conv_2d_layer = layers.Conv2D(64, (3, 3))\n",
        "outputs = layers.TimeDistributed(conv_2d_layer)(inputs)\n",
        "outputs.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 10, 126, 126, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM8kpZi94nz_",
        "outputId": "6c30dc3c-49ab-4c8c-d3ec-b22c935d30c3"
      },
      "source": [
        "length = 5\n",
        "seq = array([i / length for i in range(length)])\n",
        "seq"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0. , 0.2, 0.4, 0.6, 0.8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_79BH_XW9J-7"
      },
      "source": [
        "## One-to-One LSTM for Senquence Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqOu9oQi8wVW",
        "outputId": "06b5b8d1-733e-4db0-8cb6-5c9e067b6b0e"
      },
      "source": [
        "X = seq.reshape(5, 1, 1)\n",
        "X"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0. ]],\n",
              "\n",
              "       [[0.2]],\n",
              "\n",
              "       [[0.4]],\n",
              "\n",
              "       [[0.6]],\n",
              "\n",
              "       [[0.8]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPPmEl7x-afg",
        "outputId": "9fb23b1e-3457-46f0-809b-3131dda39a89"
      },
      "source": [
        "y = seq.reshape(5, 1)\n",
        "y"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. ],\n",
              "       [0.2],\n",
              "       [0.4],\n",
              "       [0.6],\n",
              "       [0.8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB127pF4-uhu"
      },
      "source": [
        "We will define the network model as having 1 input with 1 time step. The first hidden layer will be an LSTM with 5 units. The output layer with be a fully-connected layer with 1 output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "580KHVz_-l4P"
      },
      "source": [
        "length = 5\n",
        "seq = array([i/length for i in range(length)])\n",
        "X = seq.reshape(len(seq), 1, 1)\n",
        "y = seq.reshape(len(seq), 1)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0w0tu_3_Slz",
        "outputId": "fa60934d-aec0-4a9c-bf05-12be61fef971"
      },
      "source": [
        "n_memory_units = length\n",
        "n_batch = length\n",
        "n_epoch = 1000\n",
        "\n",
        "model = Sequential([\n",
        "  layers.LSTM(n_memory_units, input_shape=(1, 1)),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer='adam'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_28 (LSTM)               (None, 5)                 140       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 146\n",
            "Trainable params: 146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ0fSARiAPpQ"
      },
      "source": [
        "history = model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=0)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEkhNQ77AkQH",
        "outputId": "0b4c1bf0-2e28-4e5a-b108-4868043727aa"
      },
      "source": [
        "result = model.predict(X, batch_size=n_batch, verbose=0)\n",
        "for value in result:\n",
        "\tprint(f'{value[0]:.1f}', end=' ')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.2 0.4 0.6 0.8 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8pak1koBTqb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}