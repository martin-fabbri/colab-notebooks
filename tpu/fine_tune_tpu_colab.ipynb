{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fine_tune_tpu_colab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMI1g+qPIgbEPqynYq3F6ov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/tpu/fine_tune_tpu_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW9r9XilRxdH"
      },
      "source": [
        "# Fine-tune Xception TPUs (Colab)&nbsp;<img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HMuKZpuSUzq"
      },
      "source": [
        "### Enabling and testing the TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0Ow71wqXRwtE",
        "outputId": "6d79ade0-e834-4047-8a1e-d0a4f7320ddf"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDIKDjlgTXe9",
        "outputId": "ecfce651-a871-41e0-918f-4ad7c624d558"
      },
      "source": [
        "#@title Enable TPU\n",
        "use_tpu = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "if use_tpu:\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tpu_spec = tpu.cluster_spec().as_dict()['worker']\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    print('Running on TPU:', tpu_spec)\n",
        "  except ValueError:\n",
        "    print('ERROR: Not connected to a TPU.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR: Not connected to a TPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkPmFXOhY6P-"
      },
      "source": [
        "\n",
        "## Input data\n",
        "\n",
        "Our input data is stored on Google Cloud Storage. To more fully use the parallelism TPUs offer us, and to avoid bottlenecking on data transfer, we've stored our input data in TFRecord files, 230 images per file.\n",
        "\n",
        "Below, we make heavy use of `tf.data.experimental.AUTOTUNE` to optimize different parts of input loading.\n",
        "\n",
        "All of these techniques are a bit overkill for our (small) dataset, but demonstrate best practices for using TPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9LbwcCRaRBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2323ea7e-9066-4c95-fe16-9f7397f53ba6"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "IMAGE_SIZE = [331, 331]\n",
        "GCS_PATTERN = 'gs://flowers-public/tfrecords-jpeg-331x331/*.tfrec'\n",
        "VALIDATION_SPLIT = 0.19\n",
        "if use_tpu:\n",
        "  BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\n",
        "else:\n",
        "  BATCH_SIZE = 16\n",
        "SHUFFLE = 2048\n",
        "EPOCHS = 12\n",
        "print('Batch Size:', BATCH_SIZE)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c48921a01e5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mGCS_PATTERN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gs://flowers-public/tfrecords-jpeg-331x331/*.tfrec'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mVALIDATION_SPLIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtpu_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_replicas_in_sync\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mSHUFFLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tpu_strategy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRs3CNv7Sj4R"
      },
      "source": [
        "filenames = tf.io.gfile.glob(GCS_PATTERN)\n",
        "split = len(filenames) - int(len(filenames) * VALIDATION_SPLIT)\n",
        "TRAIN_FNS = filenames[:split]\n",
        "VALIDATION_FNS = filenames[split:]\n",
        "print('Train len:', len(TRAIN_FNS), ' ', 'Validation len:', len(VALIDATION_FNS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10WrfZr8f0-o"
      },
      "source": [
        "tf.io.FixedLenFeature([], tf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFSpn67pWrP1"
      },
      "source": [
        "def parse_tfrecord(example):\n",
        "  features = {\n",
        "    'image': tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
        "    'class': tf.io.FixedLenFeature([], tf.int64),  # shape [] means scalar\n",
        "    'one_hot_class': tf.io.VarLenFeature(tf.float32),\n",
        "  }\n",
        "  example =tf.io.parse_single_example(example, features)\n",
        "  decoded =tf.image.decode_jpeg(example['image'], channels=3)\n",
        "  normalized = tf.cast(decoded, tf.float32) / 255.0\n",
        "  image_tensor = tf.reshape(normalized, [*IMAGE_SIZE, 3])\n",
        "  one_hot_class = tf.reshape(tf.sparse.to_dense(example['one_hot_class']), [5])\n",
        "  return image_tensor, one_hot_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7NUw7d3b1tj"
      },
      "source": [
        "def load_dataset(filenames):\n",
        "  # Read from TFRecords. For optimal performance, \n",
        "  # we interleave reads from multiple files.\n",
        "  records = tf.data.TFRecordDataset(\n",
        "      filenames, \n",
        "      num_parallel_reads=AUTO\n",
        "  )\n",
        "  return records.map(parse_tfrecord, num_parallel_calls=AUTO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SekTRPUstxl5"
      },
      "source": [
        "# create some additional training images by randomly flipping and\n",
        "# increasing/decreasing the saturation of images in the training set\n",
        "def data_augment(image, one_hot_class):\n",
        "  modified = tf.image.random_flip_left_right(image)\n",
        "  modified = tf.image.random_saturation(modified, 0, 2)\n",
        "  return modified, one_hot_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAGw2xQ9v6_0"
      },
      "source": [
        "def optimize_batch(tfds):\n",
        "  return tfds.batch(BATCH_SIZE).prefetch(AUTO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWR38a82lufw"
      },
      "source": [
        "def get_training_dataset():\n",
        "  dataset = load_dataset(TRAIN_FNS)\n",
        "  augmented = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "  return optimize_batch(augmented.repeat().shuffle(SHUFFLE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HFN4ft4l_0C"
      },
      "source": [
        "training_dataset = get_training_dataset()\n",
        "validation_dataset = optimize_batch(load_dataset(VALIDATION_FNS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gegd7UQsxQgF"
      },
      "source": [
        "Let's take a peek at the training dataset we've created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYWbcE0Rl_xM"
      },
      "source": [
        "CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "\n",
        "def display_one_flower(image, title, subplot, color):\n",
        "  plt.subplot(subplot)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image)\n",
        "  plt.title(title, fontsize=16, color=color)\n",
        "\n",
        "def display_nine_flowers(images, titles, title_colors=None):\n",
        "  subplot = 331\n",
        "  plt.figure(figsize=(13,13))\n",
        "  for i in range(9):\n",
        "    color = 'black' if title_colors is None else title_colors[i]\n",
        "    display_one_flower(images[i], titles[i], 331+i, color)\n",
        "  plt.tight_layout()\n",
        "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "  plt.show()\n",
        "\n",
        "def get_dataset_iterator(dataset, n_examples):\n",
        "  return dataset.unbatch().batch(n_examples).as_numpy_iterator()\n",
        "\n",
        "training_viz_iterator = get_dataset_iterator(training_dataset, 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ5VTHVjl_t1"
      },
      "source": [
        "# re-run this cell to show a new batch of images\n",
        "images, classes = next(training_viz_iterator)\n",
        "class_idxs = np.argmax(classes, axis=-1)\n",
        "labels = [CLASSES[idx] for idx in class_idxs]\n",
        "display_nine_flowers(images, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4qrsGK3l_q2"
      },
      "source": [
        "classes[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O22jl7B2NxH"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMIEYliq2aSI"
      },
      "source": [
        "To get maxmimum accuracy, we leverage a pretrained image recognition model (here, [Xception](http://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf)). We drop the ImageNet-specific top layers (`include_top=false`), and add a max pooling and a softmax layer to predict our 5 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYjeRQg15rK"
      },
      "source": [
        "def create_model():\n",
        "  pretrained_model = tf.keras.applications.Xception(\n",
        "      input_shape=[*IMAGE_SIZE, 3],\n",
        "      include_top=False\n",
        "  )\n",
        "  pretrained_model.trainable = True\n",
        "  model = tf.keras.Sequential([\n",
        "    pretrained_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "  ])\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTVizVNJ2uYM"
      },
      "source": [
        "if use_tpu:\n",
        "  with tpu_strategy.scope():\n",
        "    model = create_model()\n",
        "else:\n",
        "  model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0UBMfZG4Odn"
      },
      "source": [
        "### Training\n",
        "\n",
        "Calculate the number of images in each dataset. Rather than actually load the data to do so (expensive), we rely on hints in the filename. This is used to calculate the number of batches per epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqGFj99-4FHs"
      },
      "source": [
        "def count_data_items(filenames):\n",
        "  # The number of data items is written in the name of the .tfrec files, \n",
        "  # i.e. flowers00-230.tfrec = 230 data items\n",
        "  n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n",
        "        for filename in filenames]\n",
        "  return np.sum(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdBN-TA14e5t"
      },
      "source": [
        "n_train = count_data_items(TRAIN_FNS)\n",
        "n_valid = count_data_items(VALIDATION_FNS)\n",
        "train_steps = count_data_items(TRAIN_FNS) // BATCH_SIZE\n",
        "print('TRAINING IMAGES:', n_train, ', STEPS PER EPOCH:', train_steps)\n",
        "print('VALIDATION IMAGES: ', n_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km7dPcBTSDYK"
      },
      "source": [
        "#### Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLuEHm_04e2x"
      },
      "source": [
        "start_lr = 0.00001\n",
        "min_lr = 0.00001\n",
        "max_lr = 0.0001\n",
        "if use_tpu:\n",
        "  max_lr = 0.00005 * tpu_strategy.num_replicas_in_sync\n",
        "rampup_epochs = 5\n",
        "sustain_epochs = 0\n",
        "exp_decay = 0.8 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0czNORU4ez2"
      },
      "source": [
        "def lrfn(epoch):\n",
        "  if epoch < rampup_epochs:\n",
        "    return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
        "  elif epoch < rampup_epochs + sustain_epochs:\n",
        "    return max_lr\n",
        "  else:\n",
        "    return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHz_tVBzTQcE"
      },
      "source": [
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: lrfn(epoch), verbose=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFc1Wfz9Teag"
      },
      "source": [
        "rang = np.arange(EPOCHS)\n",
        "y = [lrfn(x) for x in rang]\n",
        "plt.plot(rang, y)\n",
        "print('Learning rate per epoch:')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlyK8GNcTqrU"
      },
      "source": [
        "Actually train the model. While the first epoch will be quite a bit slower as we must XLA-compile the execution graph and load the data, later epochs should complete in ~7s (training with TPUs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG7E8IwjTrC5"
      },
      "source": [
        "history = model.fit(\n",
        "    training_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    steps_per_epoch=train_steps,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[lr_callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYf9iteRUBZj"
      },
      "source": [
        "final_accuracy = history.history['val_accuracy'][-5:]\n",
        "print('FINAL ACCURACY MEAN-5: ', np.mean(final_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVUKRBfyUzOX"
      },
      "source": [
        "def display_training_curves(training, validation, title, subplot):\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['training', 'validation'])\n",
        "\n",
        "plt.subplots(figsize=(10,10))\n",
        "plt.tight_layout()\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}