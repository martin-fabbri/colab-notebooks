{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c1_w4_info_gan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgXe+i1vu2vRmDUryrEQ9P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/gan/c1_w4_info_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guwRXellw4kG"
      },
      "source": [
        "## InfoGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ0Jydudw4Ps"
      },
      "source": [
        "### Goals\r\n",
        "\r\n",
        "In this notebook, you're going to learn about InfoGAN in order to generate disentangled outputs, based on the paper, [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets](https://arxiv.org/abs/1606.03657) by Chen et. al. While there are many approaches to disentanglement, this is one of the more widely used and better known. \r\n",
        "\r\n",
        "InfoGAN can be understood like this: you want to separate your model into two parts: $z$, corresponding to truly random noise, and $c$ corresponding to the \"latent code.\" The latent code $c$ which can be thought of as a \"hidden\" condition in a conditional generator, and you'd like it to have an interpretable meaning. \r\n",
        "\r\n",
        "Now, you'll likely immediately wonder, how do they get $c$, which is just some random set of numbers, to be more interpretable than any dimension in a typical GAN? The answer is \"mutual information\": essentially, you would like each dimension of the latent code to be as obvious a function as possible of the generated images. Read on for a more thorough theoretical and practical treatment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkHwYbmYxZwH"
      },
      "source": [
        "### Formally: Variational Lower Bound\r\n",
        "The [information entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) ${H} (X)=-\\sum _{i=1}^{n}{P(x_{i})\\log P (x_{i})}$\r\n",
        "can be understood to the amount of \"information\" in the distribution $X$. For example, the information entropy of $n$ fair coins is $n$ bits. You've also seen a similar equation before: the cross-entropy loss. Moreover, mutual information $I(X;Y) = H(X) - H(X\\vert Y)$, which the authors of InfoGAN describe as (intuitively) the \"reduction of uncertainty in $X$ when $Y$ is observed.\" \r\n",
        "\r\n",
        "In InfoGAN, you'd like to maximize $I(c; G(z, c))$, the mutual information between the latent code $c$ and the generated images $G(z, c)$.  Since it's difficult to know $P(c | G(z, c))$, you add a second output to the discriminator to predict $P(c | G(z, c))$. \r\n",
        "\r\n",
        "Let $\\Delta = D_{KL}(P(\\cdot|x) \\Vert Q(\\cdot|x))$, the [Kullback-Leibler_divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between the true and approximate distribution. Then, based on Equation 4 in the paper, the mutual information has the following lower bound: \r\n",
        "$$\\begin{split}\r\n",
        "I(c; G(z, c)) & = H(c) - H(c|G(z, c)) \\\\\r\n",
        "& = {\\mathbb{E}}_{x \\sim G(z, c)} [ {\\mathbb{E}}_{c' \\sim P(c, x)} \\log P(c' | x) ] + H(c) \\textit{ (by definition of H)}\\\\\r\n",
        "& = {\\mathbb{E}}_{x \\sim G(z, c)} [\\Delta + {\\mathbb{E}}_{c' \\sim P(c, x)} \\log Q(c' | x) ] + H(c) \\textit{ (approximation error)}\\\\\r\n",
        "& \\geq {\\mathbb{E}}_{x \\sim G(z, c)} [{\\mathbb{E}}_{c' \\sim P(c, x)} \\log Q(c' | x) ] + H(c) \\textit{ (KL divergence is non-negative)}\\\\\r\n",
        "\\end{split}\r\n",
        "$$\r\n",
        "\r\n",
        "For a given latent code distribution, $H(c)$ is fixed, so the following makes a good loss:\r\n",
        "\r\n",
        "$${\\mathbb{E}}_{x \\sim G(z, c)} [{\\mathbb{E}}_{c' \\sim P(c, x)} \\log Q(c' | x) ]$$\r\n",
        "\r\n",
        "Which is the mean cross entropy loss of the approximation over the generator's images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5q_2_cywlNj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}