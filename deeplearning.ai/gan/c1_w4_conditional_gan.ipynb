{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c1_w4_conditional_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO20oYU9TD6rP0kt/sa8hNh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc71b4484ac04a6098e1ee63cfbd5931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56cc5a5adab0451784cd5da0349f9291",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd8c38a93a994d0abe6e594594cfd08e",
              "IPY_MODEL_ec67759880ca4e789ead9e19d17fb466"
            ]
          }
        },
        "56cc5a5adab0451784cd5da0349f9291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd8c38a93a994d0abe6e594594cfd08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_87e0e120b4314a1e887e0bebce5f20a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af1d6ace7878439b845eed4f9c1f4784"
          }
        },
        "ec67759880ca4e789ead9e19d17fb466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_902d3cf324524efc9274819833c15a81",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:20&lt;00:00, 12821437.81it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70d15f2253f54b8e9b03d9468456cb31"
          }
        },
        "87e0e120b4314a1e887e0bebce5f20a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af1d6ace7878439b845eed4f9c1f4784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "902d3cf324524efc9274819833c15a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70d15f2253f54b8e9b03d9468456cb31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96dba99f3b744631b623a1594af34e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0e670e018484f0384b1b30cc6fae9ef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_232a9e10e78444a99025611c9f9637a5",
              "IPY_MODEL_ea293812efd44282b13d598721bd3960"
            ]
          }
        },
        "d0e670e018484f0384b1b30cc6fae9ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "232a9e10e78444a99025611c9f9637a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0762b5ddf9c14cf6b124c7e2458f0827",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65e82e39b3c5474fab67cde8315bb555"
          }
        },
        "ea293812efd44282b13d598721bd3960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76e043462a474943a18248228465f7c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:00&lt;00:00, 273024.07it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5b18a698a5c43ccb43ed8ced0ce5993"
          }
        },
        "0762b5ddf9c14cf6b124c7e2458f0827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65e82e39b3c5474fab67cde8315bb555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76e043462a474943a18248228465f7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5b18a698a5c43ccb43ed8ced0ce5993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4349f2019e24bea95fc8225eaa1e422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8749421d8ed1498a93da746a949cbda2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aad2cb87d44c4cb392d4082095312284",
              "IPY_MODEL_8d1caf9297f34409930419ebc9e3366a"
            ]
          }
        },
        "8749421d8ed1498a93da746a949cbda2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aad2cb87d44c4cb392d4082095312284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ec5be2cfca745faa2d8681a94740ec5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bff8374a9c6845ccbc210d88931952b6"
          }
        },
        "8d1caf9297f34409930419ebc9e3366a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ede51a65789436fadcf8df95e94de74",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:19&lt;00:00, 9327702.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2287aaf48e1d4baeafe16fb9872d4203"
          }
        },
        "1ec5be2cfca745faa2d8681a94740ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bff8374a9c6845ccbc210d88931952b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ede51a65789436fadcf8df95e94de74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2287aaf48e1d4baeafe16fb9872d4203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf6cd944d3be4bc6a29fcd65b8ec63e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8882a8f598474d819e7847851a08bf6d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_37f882ccba2640b2913f612ed0212b04",
              "IPY_MODEL_06c844b27ce5423d8a3b6d5ac7c86ca6"
            ]
          }
        },
        "8882a8f598474d819e7847851a08bf6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37f882ccba2640b2913f612ed0212b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e81f9ca865bc4365a625921e38b4936c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_affb341a7f0141cdbb391ec9e2493028"
          }
        },
        "06c844b27ce5423d8a3b6d5ac7c86ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_822551adab3348e089327b5b3866b2bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85c2af1e77e34a2faaa8e8585131d632"
          }
        },
        "e81f9ca865bc4365a625921e38b4936c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "affb341a7f0141cdbb391ec9e2493028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "822551adab3348e089327b5b3866b2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85c2af1e77e34a2faaa8e8585131d632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/gan/c1_w4_conditional_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1LgBBKMTYrJ"
      },
      "source": [
        "## Build a Conditional GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuKQzxLKTYan"
      },
      "source": [
        "### Goals\r\n",
        "In this notebook, you're going to make a conditional GAN in order to generate hand-written images of digits, conditioned on the digit to be generated (the class vector). This will let you choose what digit you want to generate.\r\n",
        "\r\n",
        "You'll then do some exploration of the generated images to visualize what the noise and class vectors mean.  \r\n",
        "\r\n",
        "### Learning Objectives\r\n",
        "1.   Learn the technical difference between a conditional and unconditional GAN.\r\n",
        "2.   Understand the distinction between the class and noise vector in a conditional GAN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9_gs7H5UC-g"
      },
      "source": [
        "## Getting Started\r\n",
        "\r\n",
        "For this assignment, you will be using the MNIST dataset again, but there's nothing stopping you from applying this generator code to produce images of animals conditioned on the species or pictures of faces conditioned on facial characteristics.\r\n",
        "\r\n",
        "Note that this assignment requires no changes to the architectures of the generator or discriminator, only changes to the data passed to both. The generator will no longer take `z_dim` as an argument, but  `input_dim` instead, since you need to pass in both the noise and class vectors. In addition to good variable naming, this also means that you can use the generator and discriminator code you have previously written with different parameters.\r\n",
        "\r\n",
        "You will begin by importing the necessary libraries and building the generator and discriminator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQgm3nLRamig"
      },
      "source": [
        "#### Packages and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xT5zNoMBTK6R",
        "outputId": "4f693df9-9d10-444f-bfb3-6a501c158b07"
      },
      "source": [
        "import torch\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from torch import nn\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.datasets import MNIST\r\n",
        "from torchvision.utils import make_grid\r\n",
        "from tqdm.auto import tqdm\r\n",
        "\r\n",
        "torch.manual_seed(0)\r\n",
        "\r\n",
        "torch.__version__"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuOeov_QTVZF"
      },
      "source": [
        "def show_tensor_images(\r\n",
        "    image_tensor, num_images=25, size=(1, 28, 28), nrow=5, show=True\r\n",
        "):\r\n",
        "    \"\"\"\r\n",
        "    Function for visualizing images: Given a tensor of images, number of images,\r\n",
        "    and size per image, plots and prints the images in an uniform grid.\r\n",
        "    \"\"\"\r\n",
        "    image_tensor = (image_tensor + 1) / 2\r\n",
        "    image_unflat = image_tensor.detach().cpu()\r\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\r\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\r\n",
        "    if show:\r\n",
        "        plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9VXa_uZbdGM"
      },
      "source": [
        "### Generator and Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmycGVlpbc4r"
      },
      "source": [
        "class Generator(nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    Generator Class\r\n",
        "    Values:\r\n",
        "        input_dim: the dimension of the input vector, a scalar\r\n",
        "        im_chan: the number of channels in the images, fitted for the dataset\r\n",
        "                 used, a scalar (MNIST is black-and-white, so 1 channel is your\r\n",
        "                 default)\r\n",
        "        hidden_dim: the inner dimension, a scalar\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, input_dim=10, im_chan=1, hidden_dim=64):\r\n",
        "        super(Generator, self).__init__()\r\n",
        "        self.input_dim = input_dim\r\n",
        "        self.gen = nn.Sequential(\r\n",
        "            self.make_gen_block(input_dim, hidden_dim * 4),\r\n",
        "            self.make_gen_block(\r\n",
        "                hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1\r\n",
        "            ),\r\n",
        "            self.make_gen_block(hidden_dim * 2, hidden_dim),\r\n",
        "            self.make_gen_block(\r\n",
        "                hidden_dim, im_chan, kernel_size=4, final_layer=True\r\n",
        "            ),\r\n",
        "        )\r\n",
        "\r\n",
        "    def make_gen_block(\r\n",
        "        self,\r\n",
        "        input_channels,\r\n",
        "        output_channels,\r\n",
        "        kernel_size=3,\r\n",
        "        stride=2,\r\n",
        "        final_layer=False,\r\n",
        "    ):\r\n",
        "        \"\"\"\r\n",
        "        Function to return a sequence of operations corresponding to a generator\r\n",
        "        block of DCGAN; a transposed convolution, a batchnorm (except in the\r\n",
        "        final layer), and an activation.\r\n",
        "        Parameters:\r\n",
        "            input_channels: how many channels the input feature representation has\r\n",
        "            output_channels: how many channels the output feature representation\r\n",
        "                             should have\r\n",
        "            kernel_size: the size of each convolutional filter, equivalent to\r\n",
        "                         (kernel_size, kernel_size)\r\n",
        "            stride: the stride of the convolution\r\n",
        "            final_layer: a boolean, true if it is the final layer and false\r\n",
        "                         otherwise (affects activation and batchnorm)\r\n",
        "        \"\"\"\r\n",
        "        if not final_layer:\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.ConvTranspose2d(\r\n",
        "                    input_channels, out_channels, kernel_size, stride\r\n",
        "                ),\r\n",
        "                nn.BatchNorm2d(output_channels),\r\n",
        "                nn.ReLU(inplace=True),\r\n",
        "            )\r\n",
        "        else:\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.ConvTranspose2d(\r\n",
        "                    input_channels, out_channels, kernel_size, stride\r\n",
        "                ),\r\n",
        "                nn.Tanh(),\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, noise):\r\n",
        "        \"\"\"\r\n",
        "        Function for completing a forward pass of the generator: Given a noise\r\n",
        "        tensor, returns generated images.\r\n",
        "        Parameters:\r\n",
        "            noise: a noise tensor with dimensions (n_samples, input_dim)\r\n",
        "        \"\"\"\r\n",
        "        x = noise.view(len(noise), self.input_dim, 1, 1)\r\n",
        "        return self.gen(x)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcqJQfq0bc2a"
      },
      "source": [
        "def get_noise(n_samples, input_dim, devide=\"cpu\"):\r\n",
        "    \"\"\"\r\n",
        "    Function for creating noise vectors: Given the dimensions (n_samples,\r\n",
        "    input_dim) creates a tensor of that shape filled with random numbers from\r\n",
        "    the normal distribution.\r\n",
        "    Parameters:\r\n",
        "        n_samples: the number of samples to generate, a scalar\r\n",
        "        input_dim: the dimension of the input vector, a scalar\r\n",
        "        device: the device type\r\n",
        "    \"\"\"\r\n",
        "    return torch.randn(n_samples, input_dim, device=device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGyVXJSRbczy"
      },
      "source": [
        "class Discriminator(nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    Discriminator Class\r\n",
        "    Values:\r\n",
        "      im_chan: the number of channels in the images, fitted for the dataset\r\n",
        "      used, a scalar (MNIST is black-and-white, so 1 channel is your default)\r\n",
        "      hidden_dim: the inner dimension, a scalar\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, im_chan=1, hidden_dim=64):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "        self.disc = nn.Sequential(\r\n",
        "            self.make_disc_block(im_chan, hidden_dim),\r\n",
        "            self.make_disc_block(hidden_dim, hidden_dim * 2),\r\n",
        "            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\r\n",
        "        )\r\n",
        "\r\n",
        "    def make_disc_block(self, input_channel, output_channel):\r\n",
        "        \"\"\"\r\n",
        "        Function to return a sequence of operations corresponding to a\r\n",
        "        discriminator block of the DCGAN; a convolution, a batchnorm\r\n",
        "        (except in the final layer), and an activation\r\n",
        "        (except in the final layer).\r\n",
        "        Parameters:\r\n",
        "            input_channels: how many channels the input feature\r\n",
        "                            representation has\r\n",
        "            output_channels: how many channels the output feature representation\r\n",
        "                             should have\r\n",
        "            kernel_size: the size of each convolutional filter, equivalent to\r\n",
        "                         (kernel_size, kernel_size)\r\n",
        "            stride: the stride of the convolution\r\n",
        "            final_layer: a boolean, true if it is the final layer and false\r\n",
        "                         otherwise (affects activation and batchnorm)\r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        if not final_layer:\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.Conv2d(input_channels, out_channels, kernel_size, stride),\r\n",
        "                nn.BatchNorm2d(output_channels),\r\n",
        "                nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            )\r\n",
        "        else:\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.Conv2d(input_channels, out_channels, kernel_size, stride)\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, image):\r\n",
        "        \"\"\"\r\n",
        "        Function for completing a forward pass of the discriminator: Given an image tensor,\r\n",
        "        returns a 1-dimension tensor representing fake/real.\r\n",
        "        Parameters:\r\n",
        "            image: a flattened image tensor with dimension (im_chan)\r\n",
        "        \"\"\"\r\n",
        "        disc_pred = self.disc(image)\r\n",
        "        return disc_pred.view(len(disc_pred), -1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muYYQrgT0Qzy"
      },
      "source": [
        "## Class Input\r\n",
        "\r\n",
        "In conditional GANs, the input vector for the generator will also need to include the class information. The class is represented using a one-hot encoded vector where its length is the number of classes and each index represents a class. The vector is all 0's and a 1 on the chosen class. Given the labels of multiple images (e.g. from a batch) and number of classes, please create one-hot vectors for each label. There is a class within the PyTorch functional library that can help you.\r\n",
        "\r\n",
        "<details>\r\n",
        "\r\n",
        "<summary>\r\n",
        "<font size=\"3\" color=\"green\">\r\n",
        "<b>Optional hints for <code><font size=\"4\">get_one_hot_labels</font></code></b>\r\n",
        "</font>\r\n",
        "</summary>\r\n",
        "\r\n",
        "1.   This code can be done in one line.\r\n",
        "2.   The documentation for [F.one_hot](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.one_hot) may be helpful.\r\n",
        "\r\n",
        "</details>\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPj3dyVmbcwg"
      },
      "source": [
        "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
        "# GRADED FUNCTION: get_one_hot_labels\r\n",
        "\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "def get_one_hot_labels(labels, n_classes):\r\n",
        "    \"\"\"\r\n",
        "    Function for creating one-hot vectors for the labels, returns a tensor of shape (?, num_classes).\r\n",
        "    Parameters:\r\n",
        "        labels: tensor of labels from the dataloader, size (?)\r\n",
        "        n_classes: the total number of classes in the dataset, an integer scalar\r\n",
        "    \"\"\"\r\n",
        "    #### START CODE HERE ####\r\n",
        "    return F.one_hot(labels, n_classes)\r\n",
        "    #### END CODE HERE ####\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gfE85JYbcjY",
        "outputId": "68a4fc01-9c0b-4903-e5a1-9572e349e53d"
      },
      "source": [
        "assert (\r\n",
        "    get_one_hot_labels(\r\n",
        "        labels=torch.Tensor([[0, 2, 1]]).long(),\r\n",
        "        n_classes=3\r\n",
        "    ).tolist() == \r\n",
        "    [[\r\n",
        "      [1, 0, 0], \r\n",
        "      [0, 0, 1], \r\n",
        "      [0, 1, 0]\r\n",
        "    ]]\r\n",
        ")\r\n",
        "print(\"Success!\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WttUNiep6e_o"
      },
      "source": [
        "Next, you need to be able to concatenate the one-hot class vector to the noise vector before giving it to the generator. You will also need to do this when adding the class channels to the discriminator.\r\n",
        "\r\n",
        "To do this, you will need to write a function that combines two vectors. Remember that you need to ensure that the vectors are the same type: floats. Again, you can look to the PyTorch library for help.\r\n",
        "<details>\r\n",
        "<summary>\r\n",
        "<font size=\"3\" color=\"green\">\r\n",
        "<b>Optional hints for <code><font size=\"4\">combine_vectors</font></code></b>\r\n",
        "</font>\r\n",
        "</summary>\r\n",
        "\r\n",
        "1.   This code can also be written in one line.\r\n",
        "2.   The documentation for [torch.cat](https://pytorch.org/docs/master/generated/torch.cat.html) may be helpful.\r\n",
        "3.   Specifically, you might want to look at what the `dim` argument of `torch.cat` does.\r\n",
        "\r\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcvpDmJI6H4_"
      },
      "source": [
        "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
        "# GRADED FUNCTION: combine_vectors\r\n",
        "def combine_vectors(x, y):\r\n",
        "    '''\r\n",
        "    Function for combining two vectors with shapes (n_samples, ?) and (n_samples, ?).\r\n",
        "    Parameters:\r\n",
        "      x: (n_samples, ?) the first vector. \r\n",
        "        In this assignment, this will be the noise vector of shape (n_samples, z_dim), \r\n",
        "        but you shouldn't need to know the second dimension's size.\r\n",
        "      y: (n_samples, ?) the second vector.\r\n",
        "        Once again, in this assignment this will be the one-hot class vector \r\n",
        "        with the shape (n_samples, n_classes), but you shouldn't assume this in your code.\r\n",
        "    '''\r\n",
        "    # Note: Make sure this function outputs a float no matter what inputs it receives\r\n",
        "    #### START CODE HERE ####\r\n",
        "    combined = torch.cat((x, y), dim=1).float()\r\n",
        "    #### END CODE HERE ####\r\n",
        "    return combined"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QNxObbN_Jn2",
        "outputId": "5eebc13d-62fd-473f-b6bb-7009325c825e"
      },
      "source": [
        "combined = combine_vectors(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[5, 6], [7, 8]]));\r\n",
        "# Check exact order of elements\r\n",
        "assert torch.all(combined == torch.tensor([[1, 2, 5, 6], [3, 4, 7, 8]]))\r\n",
        "# Tests that items are of float type\r\n",
        "assert (type(combined[0][0].item()) == float)\r\n",
        "# Check shapes\r\n",
        "combined = combine_vectors(torch.randn(1, 4, 5), torch.randn(1, 8, 5));\r\n",
        "assert tuple(combined.shape) == (1, 12, 5)\r\n",
        "assert tuple(combine_vectors(torch.randn(1, 10, 12).long(), torch.randn(1, 20, 12).long()).shape) == (1, 30, 12)\r\n",
        "print(\"Success!\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymZlCtR4ALuV"
      },
      "source": [
        "## Training\r\n",
        "Now you can start to put it all together!\r\n",
        "First, you will define some new parameters:\r\n",
        "\r\n",
        "*   mnist_shape: the number of pixels in each MNIST image, which has dimensions 28 x 28 and one channel (because it's black-and-white) so 1 x 28 x 28\r\n",
        "*   n_classes: the number of classes in MNIST (10, since there are the digits from 0 to 9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skoZsBWl_9ah"
      },
      "source": [
        "mnist_shape = (1, 28, 28)\r\n",
        "n_classes = 10"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5q5WhNPAVO6"
      },
      "source": [
        "And you also include the same parameters from previous assignments:\r\n",
        "\r\n",
        "  *   criterion: the loss function\r\n",
        "  *   n_epochs: the number of times you iterate through the entire dataset when training\r\n",
        "  *   z_dim: the dimension of the noise vector\r\n",
        "  *   display_step: how often to display/visualize the images\r\n",
        "  *   batch_size: the number of images per forward/backward pass\r\n",
        "  *   lr: the learning rate\r\n",
        "  *   device: the device type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383,
          "referenced_widgets": [
            "dc71b4484ac04a6098e1ee63cfbd5931",
            "56cc5a5adab0451784cd5da0349f9291",
            "fd8c38a93a994d0abe6e594594cfd08e",
            "ec67759880ca4e789ead9e19d17fb466",
            "87e0e120b4314a1e887e0bebce5f20a1",
            "af1d6ace7878439b845eed4f9c1f4784",
            "902d3cf324524efc9274819833c15a81",
            "70d15f2253f54b8e9b03d9468456cb31",
            "96dba99f3b744631b623a1594af34e98",
            "d0e670e018484f0384b1b30cc6fae9ef",
            "232a9e10e78444a99025611c9f9637a5",
            "ea293812efd44282b13d598721bd3960",
            "0762b5ddf9c14cf6b124c7e2458f0827",
            "65e82e39b3c5474fab67cde8315bb555",
            "76e043462a474943a18248228465f7c8",
            "d5b18a698a5c43ccb43ed8ced0ce5993",
            "a4349f2019e24bea95fc8225eaa1e422",
            "8749421d8ed1498a93da746a949cbda2",
            "aad2cb87d44c4cb392d4082095312284",
            "8d1caf9297f34409930419ebc9e3366a",
            "1ec5be2cfca745faa2d8681a94740ec5",
            "bff8374a9c6845ccbc210d88931952b6",
            "8ede51a65789436fadcf8df95e94de74",
            "2287aaf48e1d4baeafe16fb9872d4203",
            "bf6cd944d3be4bc6a29fcd65b8ec63e2",
            "8882a8f598474d819e7847851a08bf6d",
            "37f882ccba2640b2913f612ed0212b04",
            "06c844b27ce5423d8a3b6d5ac7c86ca6",
            "e81f9ca865bc4365a625921e38b4936c",
            "affb341a7f0141cdbb391ec9e2493028",
            "822551adab3348e089327b5b3866b2bf",
            "85c2af1e77e34a2faaa8e8585131d632"
          ]
        },
        "id": "D1BaXKYp_9X0",
        "outputId": "e77bf2a8-8834-4dba-a7b7-33c84c888873"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\r\n",
        "n_epochs = 200\r\n",
        "Z_dim = 64\r\n",
        "display_step = 128\r\n",
        "batch_size = 128\r\n",
        "lr = 0.0002\r\n",
        "device = \"cuda\"\r\n",
        "\r\n",
        "transform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.5,), (0.5,)),                         \r\n",
        "])\r\n",
        "\r\n",
        "dataloader = DataLoader(\r\n",
        "    MNIST(\".\", download=True, transform=transform),\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=True\r\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc71b4484ac04a6098e1ee63cfbd5931",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96dba99f3b744631b623a1594af34e98",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4349f2019e24bea95fc8225eaa1e422",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf6cd944d3be4bc6a29fcd65b8ec63e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4WBdeRIGdXu"
      },
      "source": [
        "Then, you can initialize your generator, discriminator, and optimizers. To do this, you will need to update the input dimensions for both models. For the generator, you will need to calculate the size of the input vector; recall that for conditional GANs, the generator's input is the noise vector concatenated with the class vector. For the discriminator, you need to add a channel for every class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01SMpzAU_9VK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY40EteL_9Si"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xHIpjTg_9Pp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDAyEWmu_9M_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}