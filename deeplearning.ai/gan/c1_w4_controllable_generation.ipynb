{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c1_w4_controllable_generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPR0nQJycB5V1vVxwBGyrVY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/gan/c1_w4_controllable_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdhqWu-HAmAM"
      },
      "source": [
        "## Controllable Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOoZHLWHA8aj"
      },
      "source": [
        "### Goals\r\n",
        "\r\n",
        "Explore GAN contrallability approaches using gradients from a classifier. By training a classifier to recognize a relevant feature, you can use it to change the generator's input (z-vectors) to make it generate images with more or less of that feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDIZhvahCyT-"
      },
      "source": [
        "### Packages and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-KhBNSkiAhRI",
        "outputId": "69a51ef4-1560-429a-ee4b-8e1661c092e2"
      },
      "source": [
        "import torch\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from torch import nn\r\n",
        "from tqdm.auto import tqdm\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.utils import make_grid\r\n",
        "from torchvision.datasets import CelebA\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "torch.manual_seed(0)\r\n",
        "\r\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN2Va8PqDslA"
      },
      "source": [
        "def show_tensor_images(image_tensor, num_images=16, size=(3, 64, 64), nrow=3):\r\n",
        "    '''\r\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\r\n",
        "    size per image, plots and prints the images in an uniform grid.\r\n",
        "    '''\r\n",
        "    image_tensor = (image_tensor + 1) / 2\r\n",
        "    image_unflat = image_tensor.detach().cpu()\r\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\r\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGXfSvlbEfh6"
      },
      "source": [
        "### Generator and Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze_VtMKeEfFn"
      },
      "source": [
        "class Generator(nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    Generator Class\r\n",
        "    Values:\r\n",
        "        z_dim: the dimension of the noise vector, a scalar\r\n",
        "        im_chan: the number of channels in the images, fitted for the dataset\r\n",
        "                 used, a scalar (CelebA is rgb, so 3 is our default)\r\n",
        "        hidden_dim: the inner dimension, a scalar\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, z_dim=10, im_chan=3, hidden_dim=64):\r\n",
        "        super(Generator, self).__init__()\r\n",
        "        self.z_dim = z_dim\r\n",
        "        # Build the neural network\r\n",
        "        self.gen = nn.Sequential(\r\n",
        "            self.make_gen_block(z_dim, hidden_dim * 8),\r\n",
        "            self.make_gen_block(hidden_dim * 8, hidden_dim * 4),\r\n",
        "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2),\r\n",
        "            self.make_gen_block(hidden_dim * 2, hidden_dim),\r\n",
        "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, \r\n",
        "                                final_layer=True),\r\n",
        "        )\r\n",
        "\r\n",
        "    def make_gen_block(\r\n",
        "        self,\r\n",
        "        input_channels,\r\n",
        "        output_channels,\r\n",
        "        kernel_size=3,\r\n",
        "        stride=2,\r\n",
        "        final_layer=False,\r\n",
        "    ):\r\n",
        "        \"\"\"\r\n",
        "        Function to return a sequence of operations corresponding to a generator\r\n",
        "        block of DCGAN; a transposed convolution, a batchnorm (except in the \r\n",
        "        final layer), and an activation.\r\n",
        "        Parameters:\r\n",
        "            input_channels: how many channels the input feature representation \r\n",
        "                            has\r\n",
        "            output_channels: how many channels the output feature representation \r\n",
        "                             should have\r\n",
        "            kernel_size: the size of each convolutional filter, equivalent to \r\n",
        "                         (kernel_size, kernel_size)\r\n",
        "            stride: the stride of the convolution\r\n",
        "            final_layer: a boolean, true if it is the final layer and false \r\n",
        "                         otherwise (affects activation and batchnorm)\r\n",
        "        \"\"\"\r\n",
        "        if not final_layer:\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.ConvTranspose2d(\r\n",
        "                    input_channels, output_channels, kernel_size, stride\r\n",
        "                ),\r\n",
        "                nn.BatchNorm2d(output_channels),\r\n",
        "                nn.ReLU(inplace=True),\r\n",
        "            )\r\n",
        "        else:\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.ConvTranspose2d(\r\n",
        "                    input_channels, output_channels, kernel_size, stride\r\n",
        "                ),\r\n",
        "                nn.Tanh(),\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, noise):\r\n",
        "        \"\"\"\r\n",
        "        Function for completing a forward pass of the generator: Given a noise \r\n",
        "        tensor, returns generated images.\r\n",
        "        Parameters:\r\n",
        "            noise: a noise tensor with dimensions (n_samples, z_dim)\r\n",
        "        \"\"\"\r\n",
        "        x = noise.view(len(noise), self.z_dim, 1, 1)\r\n",
        "        return self.gen(x)\r\n",
        "\r\n",
        "\r\n",
        "def get_noise(n_samples, z_dim, device=\"cpu\"):\r\n",
        "    \"\"\"\r\n",
        "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\r\n",
        "    creates a tensor of that shape filled with random numbers from the normal \r\n",
        "    distribution.\r\n",
        "    Parameters:\r\n",
        "        n_samples: the number of samples in the batch, a scalar\r\n",
        "        z_dim: the dimension of the noise vector, a scalar\r\n",
        "        device: the device type\r\n",
        "    \"\"\"\r\n",
        "    return torch.randn(n_samples, z_dim, device=device)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WpVj8y2UTMK"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZULKceLJEv_v"
      },
      "source": [
        "class Classifier(nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    Classifier Class\r\n",
        "    Values:\r\n",
        "        im_chan = the number of channels tin the images, fitted for the dataset\r\n",
        "                  used, a scalar\r\n",
        "        n_classes: the total number of classes in the dataset, an intger scalar\r\n",
        "        hidden_dim: the inner dimension, a scalar\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, im_chan=3, n_classes=2, hidden_dim=64):\r\n",
        "        super(Classifier, self).__init__()\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            self.make_classifier_block(im_chan, hidden_dim),\r\n",
        "            self.make_classifier_block(hidden_dim, hidden_dim * 2),\r\n",
        "            self.make_classifier_block(hidden_dim * 2, hidden_dim * 4, stride=3),\r\n",
        "            self.make_classifier_block(\r\n",
        "                hidden_dim * 4, \r\n",
        "                n_classes, \r\n",
        "                final_layer=True)\r\n",
        "        )\r\n",
        "\r\n",
        "    def make_classifier_block(self, input_channels, output_channels, \r\n",
        "                              kernel_size=4, final_layer=False):\r\n",
        "         make_classifier_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\r\n",
        "        \"\"\"\r\n",
        "        Function to return a sequence of operations corresponding to a \r\n",
        "        classifier block; a convolution, a batchnorm (except in the final \r\n",
        "        layer), and an activation (except in the final layer).\r\n",
        "        Parameters:\r\n",
        "            input_channels: how many channels the input feature representation \r\n",
        "                            has\r\n",
        "            output_channels: how many channels the output feature representation \r\n",
        "                             should have\r\n",
        "            kernel_size: the size of each convolutional filter, equivalent to \r\n",
        "                         (kernel_size, kernel_size)\r\n",
        "            stride: the stride of the convolution\r\n",
        "            final_layer: a boolean, true if it is the final layer and false \r\n",
        "                         otherwise \r\n",
        "        \"\"\"\r\n",
        "        if final_layer:\r\n",
        "            return \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nstD5iSqEv8X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJZonzLcEv5W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACrCCbFBEv2Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdWhlRRnEvzW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1cH2fc6EvwZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t81xJSJSEvtX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMb4jHn0Evqj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By9FMBtvEvnZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}