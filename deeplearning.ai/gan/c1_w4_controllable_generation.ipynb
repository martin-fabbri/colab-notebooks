{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c1_w4_controllable_generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQotcLc4pCGAqgfK7+K/fU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/gan/c1_w4_controllable_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdhqWu-HAmAM"
      },
      "source": [
        "## Controllable Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOoZHLWHA8aj"
      },
      "source": [
        "### Goals\r\n",
        "\r\n",
        "Explore GAN contrallability approaches using gradients from a classifier. By training a classifier to recognize a relevant feature, you can use it to change the generator's input (z-vectors) to make it generate images with more or less of that feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDIZhvahCyT-"
      },
      "source": [
        "### Packages and Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb3DaIg5TP8v"
      },
      "source": [
        "Download CelebA pretrained models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDVD_hguS3Qa"
      },
      "source": [
        "!wget -q https://github.com/martin-fabbri/colab-notebooks/raw/master/deeplearning.ai/gan/pretrained/pretrained_celeba.pth\r\n",
        "!wget -q https://github.com/martin-fabbri/colab-notebooks/raw/master/deeplearning.ai/gan/pretrained/pretrained_classifier.pth"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-KhBNSkiAhRI",
        "outputId": "98a145bc-f845-4f46-8dde-753b94bb6a43"
      },
      "source": [
        "import torch\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from torch import nn\r\n",
        "from tqdm.auto import tqdm\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.utils import make_grid\r\n",
        "from torchvision.datasets import CelebA\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "torch.manual_seed(0)\r\n",
        "\r\n",
        "torch.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN2Va8PqDslA"
      },
      "source": [
        "def show_tensor_images(image_tensor, num_images=16, size=(3, 64, 64), nrow=3):\r\n",
        "    '''\r\n",
        "    Function for visualizing images: Given a tensor of images, number of images, and\r\n",
        "    size per image, plots and prints the images in an uniform grid.\r\n",
        "    '''\r\n",
        "    image_tensor = (image_tensor + 1) / 2\r\n",
        "    image_unflat = image_tensor.detach().cpu()\r\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\r\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\r\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGXfSvlbEfh6"
      },
      "source": [
        "### Generator and Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze_VtMKeEfFn"
      },
      "source": [
        "class Generator(nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    Generator Class\r\n",
        "    Values:\r\n",
        "        z_dim: the dimension of the noise vector, a scalar\r\n",
        "        im_chan: the number of channels in the images, fitted for the dataset\r\n",
        "                 used, a scalar (CelebA is rgb, so 3 is our default)\r\n",
        "        hidden_dim: the inner dimension, a scalar\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, z_dim=10, im_chan=3, hidden_dim=64):\r\n",
        "        super(Generator, self).__init__()\r\n",
        "        self.z_dim = z_dim\r\n",
        "        # Build the neural network\r\n",
        "        self.gen = nn.Sequential(\r\n",
        "            self.make_gen_block(z_dim, hidden_dim * 8),\r\n",
        "            self.make_gen_block(hidden_dim * 8, hidden_dim * 4),\r\n",
        "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2),\r\n",
        "            self.make_gen_block(hidden_dim * 2, hidden_dim),\r\n",
        "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, \r\n",
        "                                final_layer=True),\r\n",
        "        )\r\n",
        "\r\n",
        "    def make_gen_block(\r\n",
        "        self,\r\n",
        "        input_channels,\r\n",
        "        output_channels,\r\n",
        "        kernel_size=3,\r\n",
        "        stride=2,\r\n",
        "        final_layer=False,\r\n",
        "    ):\r\n",
        "        \"\"\"\r\n",
        "        Function to return a sequence of operations corresponding to a generator\r\n",
        "        block of DCGAN; a transposed convolution, a batchnorm (except in the \r\n",
        "        final layer), and an activation.\r\n",
        "        Parameters:\r\n",
        "            input_channels: how many channels the input feature representation \r\n",
        "                            has\r\n",
        "            output_channels: how many channels the output feature representation \r\n",
        "                             should have\r\n",
        "            kernel_size: the size of each convolutional filter, equivalent to \r\n",
        "                         (kernel_size, kernel_size)\r\n",
        "            stride: the stride of the convolution\r\n",
        "            final_layer: a boolean, true if it is the final layer and false \r\n",
        "                         otherwise (affects activation and batchnorm)\r\n",
        "        \"\"\"\r\n",
        "        if not final_layer:\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.ConvTranspose2d(\r\n",
        "                    input_channels, output_channels, kernel_size, stride\r\n",
        "                ),\r\n",
        "                nn.BatchNorm2d(output_channels),\r\n",
        "                nn.ReLU(inplace=True),\r\n",
        "            )\r\n",
        "        else:\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.ConvTranspose2d(\r\n",
        "                    input_channels, output_channels, kernel_size, stride\r\n",
        "                ),\r\n",
        "                nn.Tanh(),\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, noise):\r\n",
        "        \"\"\"\r\n",
        "        Function for completing a forward pass of the generator: Given a noise \r\n",
        "        tensor, returns generated images.\r\n",
        "        Parameters:\r\n",
        "            noise: a noise tensor with dimensions (n_samples, z_dim)\r\n",
        "        \"\"\"\r\n",
        "        x = noise.view(len(noise), self.z_dim, 1, 1)\r\n",
        "        return self.gen(x)\r\n",
        "\r\n",
        "\r\n",
        "def get_noise(n_samples, z_dim, device=\"cpu\"):\r\n",
        "    \"\"\"\r\n",
        "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\r\n",
        "    creates a tensor of that shape filled with random numbers from the normal \r\n",
        "    distribution.\r\n",
        "    Parameters:\r\n",
        "        n_samples: the number of samples in the batch, a scalar\r\n",
        "        z_dim: the dimension of the noise vector, a scalar\r\n",
        "        device: the device type\r\n",
        "    \"\"\"\r\n",
        "    return torch.randn(n_samples, z_dim, device=device)\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WpVj8y2UTMK"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZULKceLJEv_v"
      },
      "source": [
        "class Classifier(nn.Module):\r\n",
        "    \"\"\"\r\n",
        "    Classifier Class\r\n",
        "    Values:\r\n",
        "        im_chan = the number of channels tin the images, fitted for the dataset\r\n",
        "                  used, a scalar\r\n",
        "        n_classes: the total number of classes in the dataset, an intger scalar\r\n",
        "        hidden_dim: the inner dimension, a scalar\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, im_chan=3, n_classes=2, hidden_dim=64):\r\n",
        "        super(Classifier, self).__init__()\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            self.make_classifier_block(im_chan, hidden_dim),\r\n",
        "            self.make_classifier_block(hidden_dim, hidden_dim * 2),\r\n",
        "            self.make_classifier_block(\r\n",
        "                hidden_dim * 2, \r\n",
        "                hidden_dim * 4, \r\n",
        "                stride=3),\r\n",
        "            self.make_classifier_block(\r\n",
        "                hidden_dim * 4, \r\n",
        "                n_classes, \r\n",
        "                final_layer=True)\r\n",
        "        )\r\n",
        "\r\n",
        "    def make_classifier_block(self, input_channels, output_channels, \r\n",
        "                              kernel_size=4, stride=2, final_layer=False):\r\n",
        "        \"\"\"\r\n",
        "        Function to return a sequence of operations corresponding to a \r\n",
        "        classifier block; a convolution, a batchnorm (except in the final \r\n",
        "        layer), and an activation (except in the final layer).\r\n",
        "        Parameters:\r\n",
        "            input_channels: how many channels the input feature representation \r\n",
        "                            has\r\n",
        "            output_channels: how many channels the output feature representation \r\n",
        "                             should have\r\n",
        "            kernel_size: the size of each convolutional filter, equivalent to \r\n",
        "                         (kernel_size, kernel_size)\r\n",
        "            stride: the stride of the convolution\r\n",
        "            final_layer: a boolean, true if it is the final layer and false \r\n",
        "                         otherwise \r\n",
        "        \"\"\"\r\n",
        "        if final_layer:\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\r\n",
        "            )\r\n",
        "        else:\r\n",
        "            return nn.Sequential(\r\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\r\n",
        "                nn.BatchNorm2d(output_channels),\r\n",
        "                nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, image):\r\n",
        "        \"\"\"\r\n",
        "        Function for completing a forward pass of the classifier: Given an image\r\n",
        "        tensor, returns an n_classes-dimension tensor representing fake/real.\r\n",
        "        Parameters:\r\n",
        "            image: a flattened image tensor with im_chan channels\r\n",
        "        \"\"\"\r\n",
        "        class_pred = self.classifier(image)\r\n",
        "        return class_pred.view(len(class_pred), -1)\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca4_YS7wdIYf"
      },
      "source": [
        "### Specifying Parameters\r\n",
        "\r\n",
        "Before you begin training, we need to specify a few parameters:\r\n",
        "\r\n",
        "- z_dim: the dimension of the noise vector\r\n",
        "- batch_size: the number of images per forward/backward pass\r\n",
        "- device: the device type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nstD5iSqEv8X"
      },
      "source": [
        "z_dim = 64\r\n",
        "batch_size = 128\r\n",
        "device = 'cuda'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxOpk7oLLbsD"
      },
      "source": [
        "### Train a Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJZonzLcEv5W"
      },
      "source": [
        "def train_classifier(filename):\r\n",
        "    labels_indices = range(40)\r\n",
        "    n_epochs = 3\r\n",
        "    display_step = 500\r\n",
        "    lr = 0.001\r\n",
        "    beta_1 = 0.5\r\n",
        "    beta_2 = 0.999\r\n",
        "    image_size = 64\r\n",
        "\r\n",
        "    transform = transforms.Compose([\r\n",
        "        transforms.Resize(image_size),\r\n",
        "        transforms.CenterCrop(image_size),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\r\n",
        "    ])\r\n",
        "    dataloader = DataLoader(\r\n",
        "        CelebA(\".\", split=\"train\", download=True, transform=transform),\r\n",
        "        batch_size=batch_size,\r\n",
        "        shuffle=True\r\n",
        "    )\r\n",
        "    classifier = Classifier(n_classes=len(len_indices)).to(device)\r\n",
        "    class_opt = torch.optim.Adam(\r\n",
        "        classifier.parameters(), \r\n",
        "        lr=lr, \r\n",
        "        betas=(beta_1, beta_2)\r\n",
        "    )\r\n",
        "    criterion = nn.BCEWithLogitsLoss()\r\n",
        "\r\n",
        "    cur_step = 0\r\n",
        "    classifier_losses = []\r\n",
        "\r\n",
        "    for epoch in range(n_epochs):\r\n",
        "        # Dataloader returns the batches\r\n",
        "        for real, labels in tqdm(dataloader):\r\n",
        "            real = real.to(device)\r\n",
        "            labels = labels[:, label_indices].to(device).float()\r\n",
        "\r\n",
        "            class_opt.zero_grad()\r\n",
        "            class_pred = classifier(real)\r\n",
        "            class_loss = criterion(class_pred, labels)\r\n",
        "            class_loss.backward() # Calculate the gradients\r\n",
        "            class_opt.step() # Update the weights\r\n",
        "            classifier_losses += [class_loss.item()]\r\n",
        "\r\n",
        "            ## Visualization code ##\r\n",
        "            if cur_step % display_step == 0 and cur_step > 0:\r\n",
        "                class_mean = sum(classifier_losses[-display_step:]) / display_step\r\n",
        "                print(f\"Step {cur_step}: Classifier loss: {class_mean}\")\r\n",
        "                step_bins = 20\r\n",
        "                x_axis = sorted([i * step_bins for i in range(len(classifier_losses) // step_bins)] * step_bins)\r\n",
        "                sns.lineplot(x_axis, classifier_losses[:len(x_axis)], label=\"Classifier Loss\")\r\n",
        "                plt.legend()\r\n",
        "                plt.show()\r\n",
        "                torch.save({\"classifier\": classifier.state_dict()}, filename)\r\n",
        "            cur_step += 1\r\n",
        "\r\n",
        "# Uncomment the last line to train your own classfier - this line will not work in Coursera.\r\n",
        "# If you'd like to do this, you'll have to download it and run it, ideally using a GPU \r\n",
        "# train_classifier(\"filename\")\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC0goUkRQSor"
      },
      "source": [
        "### Loading the Pretrained Model\r\n",
        "\r\n",
        "You will then load the pretrained generator and classifier using the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACrCCbFBEv2Y",
        "outputId": "9d1c79d0-cd7a-4726-f3f8-6d0a47704c7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load pretrained generator\r\n",
        "gen = Generator(z_dim).to(device)\r\n",
        "gen_dict = torch.load(\r\n",
        "    \"pretrained_celeba.pth\",\r\n",
        "    map_location=torch.device(device)\r\n",
        ")[\"gen\"]\r\n",
        "gen.load_state_dict(gen_dict)\r\n",
        "gen.eval()\r\n",
        "\r\n",
        "n_classes = 40\r\n",
        "classifier = Classifier(n_classes=n_classes).to(device)\r\n",
        "class_dict = torch.load(\r\n",
        "    \"pretrained_classifier.pth\", \r\n",
        "    map_location=torch.device(device)\r\n",
        ")[\"classifier\"]\r\n",
        "classifier.load_state_dict(class_dict)\r\n",
        "classifier.eval()\r\n",
        "print(\"Pretrained models loading complete.\")\r\n",
        "\r\n",
        "opt = torch.optim.Adam(classifier.parameters(), lr=0.01)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pretrained models loading complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JXndIjGkdTt"
      },
      "source": [
        "### Training\r\n",
        "\r\n",
        "Now you can start implementing a method for controlling your GAN!\r\n",
        "\r\n",
        "For training, you need to write the code to update the noise to produce more of your desired feature. You do this by performing stochastic gradient ascent. You use stochastic gradient ascent to find the local maxima, as opposed to stochastic gradient descent which finds the local minima. Gradient ascent is gradient descent over the negative of the value being optimized. Their formulas are essentially the same, however, instead of subtracting the weighted value, stochastic gradient ascent adds it; it can be calculated by `new = old + (∇ old * weight)`, where ∇ is the gradient of `old`. You perform stochastic gradient ascent to try and maximize the amount of the feature you want. If you wanted to reduce the amount of the feature, you would perform gradient descent. However, in this assignment you are interested in maximize your feature using gradient ascent, since many features in the dataset are not present much more often than they're present and you are trying to add a feature to the images, not remove.\r\n",
        "\r\n",
        "Given the noise with its gradient already calculated through the classifier, you want to return the new noise vector.\r\n",
        "\r\n",
        "<details>\r\n",
        "\r\n",
        "<summary>\r\n",
        "<font size=\"3\" color=\"green\">\r\n",
        "<b>Optional hint for <code><font size=\"4\">calculate_updated_noise</font></code></b>\r\n",
        "</font>\r\n",
        "</summary>\r\n",
        "\r\n",
        "1.   Remember the equation for gradient ascent: `new = old + (∇ old * weight)`.\r\n",
        "\r\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdWhlRRnEvzW"
      },
      "source": [
        "def calculate_updated_noise(noise, weight):\r\n",
        "    \"\"\"\r\n",
        "    Function to return the noise vectors update with stochastic\r\n",
        "    gradient ascent.\r\n",
        "    Parameters:\r\n",
        "        noise: the current noise vectors. You have already called the backwards \r\n",
        "               function on the target class so you can access the gradient of\r\n",
        "               the output class with respect to the noise by using noise.grad\r\n",
        "        weight: the scalar amount by which you should weight the noise gradient\r\n",
        "    \"\"\"\r\n",
        "    #### START CODE HERE ####\r\n",
        "    new_noise = noise + noise.grad * weight\r\n",
        "    #### END CODE HERE ####\r\n",
        "    return new_noise\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1cH2fc6EvwZ",
        "outputId": "809a0e1b-f026-4a82-97cd-20dd492736fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Unit test\r\n",
        "opt.zero_grad()\r\n",
        "noise = torch.ones(20, 20) * 2\r\n",
        "noise.requires_grad_()\r\n",
        "fake_classes = (noise ** 2).mean()\r\n",
        "fake_classes.backward()\r\n",
        "new_noise = calculate_updated_noise(noise, 0.1)\r\n",
        "assert type(new_noise) == torch.Tensor\r\n",
        "assert tuple(new_noise.shape) == (20, 20)\r\n",
        "assert new_noise.max() == 2.0010\r\n",
        "assert new_noise.min() == 2.0010\r\n",
        "assert torch.isclose(new_noise.sum(), torch.tensor(0.4) + 20 * 20 * 2)\r\n",
        "print(\"Success!\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t81xJSJSEvtX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMb4jHn0Evqj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By9FMBtvEvnZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}