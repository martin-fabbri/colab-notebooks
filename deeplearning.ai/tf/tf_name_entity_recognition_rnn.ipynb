{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "name_entity_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM88dBAhDcO41Ef7a6fLu1e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/tf_name_entity_recognition_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx0HfnFKVPY8",
        "cellView": "form",
        "outputId": "af995443-3f61-423d-a0c6-a986b375b5b7"
      },
      "source": [
        "#@title Download Kaggle Dataset\r\n",
        "#@markdown Dataset: Annotated Corpus for Named Entity Recognition <br>\r\n",
        "#@markdown https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\r\n",
        "#@markdown ___\r\n",
        "\r\n",
        "kaggle_dataset_id = \"abhinavwalia95/entity-annotated-corpus\" #@param {type:\"string\"}\r\n",
        "\r\n",
        "!pip install -q kaggle\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp /content/gdrive/My\\ Drive/kaggle/kaggle.json ~/.kaggle/kaggle.json\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json\r\n",
        "!kaggle datasets download -d {kaggle_dataset_id}\r\n",
        "!ls -l /content\r\n",
        "!unzip -o /content/entity-annotated-corpus"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "entity-annotated-corpus.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "total 195268\n",
            "-rw-r--r-- 1 root root  27703149 Dec 24 07:44 entity-annotated-corpus.zip\n",
            "drwx------ 5 root root      4096 Dec 24 07:44 gdrive\n",
            "-rw-r--r-- 1 root root 157030359 Sep 20  2019 ner.csv\n",
            "-rw-r--r-- 1 root root  15208151 Sep 20  2019 ner_dataset.csv\n",
            "drwxr-xr-x 1 root root      4096 Dec 21 17:29 sample_data\n",
            "Archive:  /content/entity-annotated-corpus.zip\n",
            "  inflating: ner.csv                 \n",
            "  inflating: ner_dataset.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiVNesPUlvmY",
        "outputId": "5032f2fc-082c-4190-fcc1-9421f2490ebd"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-d60ce961-179e-66ef-3c51-3b5e2c11c2e4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCcbeu8PWUTt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "df85962e-3024-4122-a298-03ee447777dd"
      },
      "source": [
        "import math\r\n",
        "import pathlib\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_addons as tf_ad\r\n",
        "from numpy.random import seed\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.callbacks import TensorBoard\r\n",
        "from tensorflow.keras.layers import (\r\n",
        "    LSTM,\r\n",
        "    Bidirectional,\r\n",
        "    Dense,\r\n",
        "    Embedding,\r\n",
        "    TimeDistributed,\r\n",
        ")\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.random import set_seed\r\n",
        "\r\n",
        "set_seed(42)\r\n",
        "seed(42)\r\n",
        "\r\n",
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorflow_logs\"\r\n",
        "shutil.rmtree(logdir, ignore_errors=True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3b5889bbeba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'CRF'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1JpDNgHWNt4"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "GTYrpk2FVbAI",
        "outputId": "18c3869f-0915-4560-9fe0-99bad9eb8a99"
      },
      "source": [
        "df = pd.read_csv(\"ner.csv\", encoding=\"ISO-8859-1\", error_bad_lines=False)\r\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>lemma</th>\n",
              "      <th>next-lemma</th>\n",
              "      <th>next-next-lemma</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-shape</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-shape</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-iob</th>\n",
              "      <th>prev-lemma</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-iob</th>\n",
              "      <th>prev-prev-lemma</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-shape</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-shape</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>shape</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thousand</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__start2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>thousand</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>VBN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>thousand</td>\n",
              "      <td>NNS</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>london</td>\n",
              "      <td>NNP</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     lemma next-lemma  ...        shape           word tag\n",
              "0           0  thousand         of  ...  capitalized      Thousands   O\n",
              "1           1        of   demonstr  ...    lowercase             of   O\n",
              "2           2  demonstr       have  ...    lowercase  demonstrators   O\n",
              "3           3      have      march  ...    lowercase           have   O\n",
              "4           4     march    through  ...    lowercase        marched   O\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "wG4MpL6Nt0cx",
        "outputId": "9603536d-b839-49df-caec-632fece46444"
      },
      "source": [
        "data = df[[\"sentence_idx\", \"word\", \"tag\"]]\r\n",
        "data.head(15)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>through</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>London</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>protest</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>war</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>demand</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentence_idx           word    tag\n",
              "0            1.0      Thousands      O\n",
              "1            1.0             of      O\n",
              "2            1.0  demonstrators      O\n",
              "3            1.0           have      O\n",
              "4            1.0        marched      O\n",
              "5            1.0        through      O\n",
              "6            1.0         London  B-geo\n",
              "7            1.0             to      O\n",
              "8            1.0        protest      O\n",
              "9            1.0            the      O\n",
              "10           1.0            war      O\n",
              "11           1.0             in      O\n",
              "12           1.0           Iraq  B-geo\n",
              "13           1.0            and      O\n",
              "14           1.0         demand      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InVYe7a8ujFB",
        "outputId": "de077f5c-6745-40c5-89bf-0386be06b2ec"
      },
      "source": [
        "data[\"tag\"].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        889973\n",
              "B-geo     37525\n",
              "B-tim     20193\n",
              "B-org     20184\n",
              "I-per     17382\n",
              "B-per     17011\n",
              "I-org     16537\n",
              "B-gpe     16392\n",
              "I-geo      7409\n",
              "I-tim      6298\n",
              "B-art       434\n",
              "B-eve       348\n",
              "I-eve       297\n",
              "I-art       280\n",
              "I-gpe       229\n",
              "B-nat       226\n",
              "I-nat        76\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGR9Y5mbwh_q",
        "outputId": "c185c1c0-8f69-4684-ee9e-4639f65d121c"
      },
      "source": [
        "agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"], s[\"tag\"])]\r\n",
        "data.groupby(\"sentence_idx\").apply(agg_func)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence_idx\n",
              "1.0        [(Thousands, O), (of, O), (demonstrators, O), ...\n",
              "2.0        [(Families, O), (of, O), (soldiers, O), (kille...\n",
              "3.0        [(They, O), (marched, O), (from, O), (the, O),...\n",
              "4.0        [(Police, O), (put, O), (the, O), (number, O),...\n",
              "5.0        [(The, O), (protest, O), (comes, O), (on, O), ...\n",
              "                                 ...                        \n",
              "47955.0    [(Indian, B-gpe), (border, O), (security, O), ...\n",
              "47956.0    [(Indian, B-gpe), (officials, O), (said, O), (...\n",
              "47957.0    [(Two, O), (more, O), (landed, O), (in, O), (f...\n",
              "47958.0    [(They, O), (say, O), (not, O), (all, O), (of,...\n",
              "47959.0    [(Indian, B-gpe), (forces, O), (said, O), (the...\n",
              "Length: 35177, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SAQvFZuvG_I",
        "outputId": "d5f0cd0b-6d09-46ef-d695-29bd39a49c08"
      },
      "source": [
        "class SentenceGetter():\r\n",
        "    def __init__(self, dataset):\r\n",
        "        self.n_sent = 1\r\n",
        "        self.dataset = dataset\r\n",
        "        self.empty = False\r\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"], s[\"tag\"])]\r\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\r\n",
        "        self.sentences = [s for s in self.grouped]\r\n",
        "    \r\n",
        "    def get_next(self):\r\n",
        "        try:\r\n",
        "            s = self.grouped[f\"Sentence: {self.n_sent}\"]\r\n",
        "            self.n_sent += 1\r\n",
        "            return s\r\n",
        "        except:\r\n",
        "            return None\r\n",
        "\r\n",
        "getter = SentenceGetter(data)\r\n",
        "sentences = getter.sentences\r\n",
        "print(repr(sentences[0][:4]), \"...\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O')] ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6FTBOvszaBu",
        "outputId": "4cbbca2f-f6fc-4528-e324-6e35731d0b66"
      },
      "source": [
        "tokens = data[\"word\"].unique()\r\n",
        "tokens = {\"unk\" if t is math.nan or isinstance(t, float) else t for t in tokens}\r\n",
        "num_tokens = len(tokens)\r\n",
        "\r\n",
        "maxlen = max([len(t) for t in tokens])\r\n",
        "\r\n",
        "tags = data[\"tag\"].unique()\r\n",
        "tags = {\"unk\" if t is math.nan or isinstance(t, float) else t for t in tags}\r\n",
        "num_tags = len(tags)\r\n",
        "\r\n",
        "print(f\"Num tokenks: {num_tokens:,}  Num tags: {num_tags}  maxlen: {maxlen}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num tokenks: 30,173  Num tags: 18  maxlen: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAP5-ttp3U9F"
      },
      "source": [
        "token2idx = {token: idx for idx, token in enumerate(tokens)}\r\n",
        "idx2token = {idx: token for idx, token in enumerate(tokens)}\r\n",
        "tag2idx = {tag: idx for idx, tag in enumerate(tags)}\r\n",
        "idx2tag = {idx: tag for idx, tag in enumerate(tags)}\r\n",
        "\r\n",
        "unk_token_idx = token2idx['unk']\r\n",
        "unk_tag_idx = tag2idx['unk']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi1jOnW63U2Q"
      },
      "source": [
        "X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n",
        "X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=unk_token_idx)\r\n",
        "\r\n",
        "y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n",
        "y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=unk_tag_idx)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnzKX10nGG1V",
        "outputId": "15f1e916-7249-481e-fe25-dfe4c4ba7f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tf2crf"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf2crf in /usr/local/lib/python3.6/dist-packages (0.1.29)\n",
            "Requirement already satisfied: tensorflow-addons>=0.8.2 in /usr/local/lib/python3.6/dist-packages (from tf2crf) (0.8.3)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tf2crf) (2.4.0)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons>=0.8.2->tf2crf) (2.7.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.36.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.12)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.32.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (2.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.1.2)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.19.4)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->tf2crf) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.1.0->tf2crf) (51.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (3.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (3.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->tf2crf) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "wS_NRQOX3UzR",
        "outputId": "d99bfbef-afa2-47e0-f9c9-690f6a2adb50"
      },
      "source": [
        "from tensorflow_addons.text.crf import \r\n",
        "word_embedding_size = 150\r\n",
        "\r\n",
        "model = Sequential([\r\n",
        "    Embedding(input_dim=num_tokens, output_dim=word_embedding_size),\r\n",
        "    Bidirectional(LSTM(\r\n",
        "        units=word_embedding_size,\r\n",
        "        return_sequences=True,\r\n",
        "        dropout=0.5,\r\n",
        "        recurrent_dropout=0.5\r\n",
        "    )),\r\n",
        "    LSTM(\r\n",
        "        units=word_embedding_size * 2,\r\n",
        "        return_sequences=True,\r\n",
        "        recurrent_dropout=0.5\r\n",
        "    ),\r\n",
        "    crf_log_likelihood(TimeDistributed(Dense(num_tags, activation=\"relu\"))),\r\n",
        "])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-617f10f99e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     ),\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcrf_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m ])\n",
            "\u001b[0;31mTypeError\u001b[0m: crf_log_likelihood() missing 2 required positional arguments: 'tag_indices' and 'sequence_lengths'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V1GW2jvBdfD"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-boCzekTIK8D",
        "outputId": "118f6e9e-1260-4c32-e199-4732d741f72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-1e20f5902fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_addons.layers' has no attribute 'CRF'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvAotxncIO9O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}