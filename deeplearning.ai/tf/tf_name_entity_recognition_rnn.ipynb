{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "name_entity_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMYuYBJtLHLrv7kCpB+4uUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/tf_name_entity_recognition_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx0HfnFKVPY8",
        "cellView": "form",
        "outputId": "245966af-4b72-4a52-b0b1-a60f97280f88"
      },
      "source": [
        "#@title Download Kaggle Dataset\r\n",
        "#@markdown Dataset: Annotated Corpus for Named Entity Recognition <br>\r\n",
        "#@markdown https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\r\n",
        "#@markdown ___\r\n",
        "\r\n",
        "kaggle_dataset_id = \"abhinavwalia95/entity-annotated-corpus\" #@param {type:\"string\"}\r\n",
        "\r\n",
        "!pip install -q kaggle\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp /content/gdrive/My\\ Drive/kaggle/kaggle.json ~/.kaggle/kaggle.json\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json\r\n",
        "!kaggle datasets download -d {kaggle_dataset_id}\r\n",
        "!ls -l /content\r\n",
        "!unzip -o /content/entity-annotated-corpus"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "entity-annotated-corpus.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "total 195268\n",
            "-rw-r--r-- 1 root root  27703149 Dec 24 07:44 entity-annotated-corpus.zip\n",
            "drwx------ 5 root root      4096 Dec 24 07:44 gdrive\n",
            "-rw-r--r-- 1 root root 157030359 Sep 20  2019 ner.csv\n",
            "-rw-r--r-- 1 root root  15208151 Sep 20  2019 ner_dataset.csv\n",
            "drwxr-xr-x 1 root root      4096 Dec 21 17:29 sample_data\n",
            "Archive:  /content/entity-annotated-corpus.zip\n",
            "  inflating: ner.csv                 \n",
            "  inflating: ner_dataset.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiVNesPUlvmY",
        "outputId": "73fba921-099c-48d1-966d-90f26258da52"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-d60ce961-179e-66ef-3c51-3b5e2c11c2e4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCcbeu8PWUTt"
      },
      "source": [
        "import math\r\n",
        "import pathlib\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_addons as tf_ad\r\n",
        "from numpy.random import seed\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.callbacks import TensorBoard\r\n",
        "from tensorflow.keras.layers import (\r\n",
        "    LSTM,\r\n",
        "    Bidirectional,\r\n",
        "    Dense,\r\n",
        "    Embedding,\r\n",
        "    TimeDistributed,\r\n",
        "    Dropout,\r\n",
        "    SpatialDropout1D\r\n",
        ")\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.random import set_seed\r\n",
        "\r\n",
        "set_seed(42)\r\n",
        "seed(42)\r\n",
        "\r\n",
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorflow_logs\"\r\n",
        "shutil.rmtree(logdir, ignore_errors=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1JpDNgHWNt4"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "GTYrpk2FVbAI",
        "outputId": "56186a6a-e0db-45de-edf7-1d4ed4b00455"
      },
      "source": [
        "df = pd.read_csv(\"ner.csv\", encoding=\"ISO-8859-1\", error_bad_lines=False)\r\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>lemma</th>\n",
              "      <th>next-lemma</th>\n",
              "      <th>next-next-lemma</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-shape</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-shape</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-iob</th>\n",
              "      <th>prev-lemma</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-iob</th>\n",
              "      <th>prev-prev-lemma</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-shape</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-shape</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>shape</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thousand</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__start2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>thousand</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>VBN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>thousand</td>\n",
              "      <td>NNS</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>london</td>\n",
              "      <td>NNP</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     lemma next-lemma  ...        shape           word tag\n",
              "0           0  thousand         of  ...  capitalized      Thousands   O\n",
              "1           1        of   demonstr  ...    lowercase             of   O\n",
              "2           2  demonstr       have  ...    lowercase  demonstrators   O\n",
              "3           3      have      march  ...    lowercase           have   O\n",
              "4           4     march    through  ...    lowercase        marched   O\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "wG4MpL6Nt0cx",
        "outputId": "891fcf05-4c8a-46e9-fac6-232bc6f962d1"
      },
      "source": [
        "data = df[[\"sentence_idx\", \"word\", \"tag\"]]\r\n",
        "data.head(15)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>through</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>London</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>protest</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>war</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>demand</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentence_idx           word    tag\n",
              "0            1.0      Thousands      O\n",
              "1            1.0             of      O\n",
              "2            1.0  demonstrators      O\n",
              "3            1.0           have      O\n",
              "4            1.0        marched      O\n",
              "5            1.0        through      O\n",
              "6            1.0         London  B-geo\n",
              "7            1.0             to      O\n",
              "8            1.0        protest      O\n",
              "9            1.0            the      O\n",
              "10           1.0            war      O\n",
              "11           1.0             in      O\n",
              "12           1.0           Iraq  B-geo\n",
              "13           1.0            and      O\n",
              "14           1.0         demand      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InVYe7a8ujFB",
        "outputId": "4104b6c7-f90e-47a5-ac91-b74dd5b35a90"
      },
      "source": [
        "data[\"tag\"].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        889973\n",
              "B-geo     37525\n",
              "B-tim     20193\n",
              "B-org     20184\n",
              "I-per     17382\n",
              "B-per     17011\n",
              "I-org     16537\n",
              "B-gpe     16392\n",
              "I-geo      7409\n",
              "I-tim      6298\n",
              "B-art       434\n",
              "B-eve       348\n",
              "I-eve       297\n",
              "I-art       280\n",
              "I-gpe       229\n",
              "B-nat       226\n",
              "I-nat        76\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGR9Y5mbwh_q",
        "outputId": "5a3deb36-f77e-4908-da87-f8c0965b69e3"
      },
      "source": [
        "agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"], s[\"tag\"])]\r\n",
        "data.groupby(\"sentence_idx\").apply(agg_func)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence_idx\n",
              "1.0        [(Thousands, O), (of, O), (demonstrators, O), ...\n",
              "2.0        [(Families, O), (of, O), (soldiers, O), (kille...\n",
              "3.0        [(They, O), (marched, O), (from, O), (the, O),...\n",
              "4.0        [(Police, O), (put, O), (the, O), (number, O),...\n",
              "5.0        [(The, O), (protest, O), (comes, O), (on, O), ...\n",
              "                                 ...                        \n",
              "47955.0    [(Indian, B-gpe), (border, O), (security, O), ...\n",
              "47956.0    [(Indian, B-gpe), (officials, O), (said, O), (...\n",
              "47957.0    [(Two, O), (more, O), (landed, O), (in, O), (f...\n",
              "47958.0    [(They, O), (say, O), (not, O), (all, O), (of,...\n",
              "47959.0    [(Indian, B-gpe), (forces, O), (said, O), (the...\n",
              "Length: 35177, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SAQvFZuvG_I",
        "outputId": "77941d19-bdc8-4c2e-ad5d-098d12a53d2f"
      },
      "source": [
        "class SentenceGetter():\r\n",
        "    def __init__(self, dataset):\r\n",
        "        self.n_sent = 1\r\n",
        "        self.dataset = dataset\r\n",
        "        self.empty = False\r\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"], s[\"tag\"])]\r\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\r\n",
        "        self.sentences = [s for s in self.grouped]\r\n",
        "    \r\n",
        "    def get_next(self):\r\n",
        "        try:\r\n",
        "            s = self.grouped[f\"Sentence: {self.n_sent}\"]\r\n",
        "            self.n_sent += 1\r\n",
        "            return s\r\n",
        "        except:\r\n",
        "            return None\r\n",
        "\r\n",
        "getter = SentenceGetter(data)\r\n",
        "sentences = getter.sentences\r\n",
        "print(repr(sentences[0][:4]), \"...\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O')] ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6FTBOvszaBu",
        "outputId": "5ba4eb48-b600-4208-b7b4-898437fd1d4f"
      },
      "source": [
        "tokens = data[\"word\"].unique()\r\n",
        "tokens = {\"unk\" if t is math.nan or isinstance(t, float) else t for t in tokens}\r\n",
        "num_tokens = len(tokens)\r\n",
        "\r\n",
        "maxlen = max([len(t) for t in tokens])\r\n",
        "\r\n",
        "tags = data[\"tag\"].unique()\r\n",
        "tags = {\"unk\" if t is math.nan or isinstance(t, float) else t for t in tags}\r\n",
        "num_tags = len(tags)\r\n",
        "\r\n",
        "print(f\"Num tokenks: {num_tokens:,}  Num tags: {num_tags}  maxlen: {maxlen}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num tokenks: 30,173  Num tags: 18  maxlen: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAP5-ttp3U9F"
      },
      "source": [
        "token2idx = {token: idx for idx, token in enumerate(tokens)}\r\n",
        "idx2token = {idx: token for idx, token in enumerate(tokens)}\r\n",
        "tag2idx = {tag: idx for idx, tag in enumerate(tags)}\r\n",
        "idx2tag = {idx: tag for idx, tag in enumerate(tags)}\r\n",
        "\r\n",
        "unk_token_idx = token2idx['unk']\r\n",
        "unk_tag_idx = tag2idx['unk']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi1jOnW63U2Q"
      },
      "source": [
        "X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n",
        "X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=unk_token_idx)\r\n",
        "\r\n",
        "y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n",
        "y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=unk_tag_idx)\r\n",
        "y = [to_categorical(tag_idx, num_classes=num_tags) for tag_idx in y]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS_NRQOX3UzR"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V1GW2jvBdfD",
        "outputId": "c58e0915-5f52-4bf1-af4e-080a2ab12c1d"
      },
      "source": [
        "model = Sequential([\r\n",
        "    Embedding(input_dim=num_tokens, output_dim=64),\r\n",
        "    SpatialDropout1D(0.1),\r\n",
        "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\r\n",
        "    TimeDistributed(Dense(num_tags, activation=\"softmax\"))\r\n",
        "])\r\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 64)          1931072   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, None, 64)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 200)         132000    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 18)          3618      \n",
            "=================================================================\n",
            "Total params: 2,066,690\n",
            "Trainable params: 2,066,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-boCzekTIK8D"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn-t2Q4dQmSO",
        "outputId": "3b3d4654-e84f-45d3-a8f1-bd09349c0695"
      },
      "source": [
        "history = model.fit(X_train, np.array(y_train), validation_split=0.2, batch_size=32, epochs=3, verbose=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "792/792 [==============================] - 263s 326ms/step - loss: 0.5258 - accuracy: 0.8842 - val_loss: 0.0880 - val_accuracy: 0.9760\n",
            "Epoch 2/3\n",
            "792/792 [==============================] - 257s 325ms/step - loss: 0.0715 - accuracy: 0.9801 - val_loss: 0.0601 - val_accuracy: 0.9822\n",
            "Epoch 3/3\n",
            "792/792 [==============================] - 256s 324ms/step - loss: 0.0439 - accuracy: 0.9869 - val_loss: 0.0566 - val_accuracy: 0.9831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tIbuOmiQ9BS",
        "outputId": "954f9f1a-b792-49e6-f662-9570523ea46b"
      },
      "source": [
        "model.evaluate(X_test, np.array(y_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 4s 32ms/step - loss: 0.0564 - accuracy: 0.9835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.056382834911346436, 0.9834822416305542]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFRd9filUScz",
        "outputId": "b1b71497-b7c0-4d70-de52-0f7384bf9d6f"
      },
      "source": [
        "sample_idx = np.random.randint(0, len(X_test))\r\n",
        "pred = model.predict(X_test[sample_idx])\r\n",
        "pred_tags = np.argmax(pred, axis=-1).flatten()\r\n",
        "ground_truth = np.argmax(y_test[sample_idx], axis=1)\r\n",
        "\r\n",
        "print(f\"{'Word':15}{'True':5}\\t {'Pred'}\\n\")\r\n",
        "print(\"_\"*30)\r\n",
        "for token, gt_tag, pred_tag in zip(X_test[sample_idx], ground_truth, pred_tags):\r\n",
        "    print(f\"{idx2token[token]:15}{idx2tag[gt_tag]}\\t{idx2tag[pred_tag]}\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           True \t Pred\n",
            "\n",
            "______________________________\n",
            "The            O\tO\n",
            "military       O\tO\n",
            "also           O\tO\n",
            "said           O\tO\n",
            "Iraqi          B-gpe\tB-gpe\n",
            "soldiers       O\tO\n",
            "recovered      O\tO\n",
            "Iranian-made   O\tB-geo\n",
            "rockets        O\tO\n",
            "and            O\tO\n",
            "other          O\tO\n",
            "weapons        O\tO\n",
            "in             O\tO\n",
            "Baghdad        B-geo\tB-geo\n",
            "'s             O\tO\n",
            "Sadr           B-geo\tB-geo\n",
            "City           I-geo\tI-geo\n",
            "district       O\tO\n",
            "on             O\tO\n",
            "Monday         B-tim\tB-tim\n",
            ".              O\tO\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjr7--R1U0YO",
        "outputId": "f8590f78-7bc5-4de7-ce8d-f33a953db1b0"
      },
      "source": [
        "model_222 = Sequential([\r\n",
        "    Embedding(input_dim=num_tokens, output_dim=64),\r\n",
        "    SpatialDropout1D(0.1),\r\n",
        "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\r\n",
        "    TimeDistributed(Dense(num_tags))\r\n",
        "])\r\n",
        "model_222.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\r\n",
        "X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n",
        "X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=unk_token_idx)\r\n",
        "\r\n",
        "y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n",
        "y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=unk_tag_idx)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\r\n",
        "history = model_222.fit(X_train, np.array(y_train), validation_split=0.2, batch_size=32, epochs=3, verbose=1)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/3\n",
            "792/792 [==============================] - 267s 333ms/step - loss: 0.6833 - accuracy: 0.9014 - val_loss: 0.2084 - val_accuracy: 0.9594\n",
            "Epoch 2/3\n",
            "792/792 [==============================] - 269s 340ms/step - loss: 0.3472 - accuracy: 0.9071 - val_loss: 0.1583 - val_accuracy: 0.9724\n",
            "Epoch 3/3\n",
            "792/792 [==============================] - 275s 347ms/step - loss: 0.1440 - accuracy: 0.9746 - val_loss: 0.1685 - val_accuracy: 0.9745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJqUq-0oV3mH",
        "outputId": "0324ccad-9a7c-45bd-d166-81594e41fce7"
      },
      "source": [
        "model_222.evaluate(X_test, np.array(y_test))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 4s 34ms/step - loss: 0.1651 - accuracy: 0.9750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16509294509887695, 0.9749813675880432]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vuv5NN6ct4P",
        "outputId": "bdc8b7ba-e7d6-462c-ad86-7a1283f7dd9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_idx = np.random.randint(0, len(X_test))\r\n",
        "pred = model_222(tf.expand_dims(X_test[sample_idx], 0))\r\n",
        "pred = tf.squeeze(pred, 0)\r\n",
        "pred = tf.random.categorical(pred, num_samples=1)\r\n",
        "pred_tags = pred.numpy().flatten()\r\n",
        "ground_truth = y_test[sample_idx]\r\n",
        "\r\n",
        "print(f\"{'Word':15}{'True':5}\\t {'Pred'}\\n\")\r\n",
        "print(\"_\"*30)\r\n",
        "for token, gt_tag, pred_tag in zip(X_test[sample_idx], ground_truth, pred_tags):\r\n",
        "    print(f\"{idx2token[token]:15}{idx2tag[gt_tag]}\\t{idx2tag[pred_tag]}\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           True \t Pred\n",
            "\n",
            "______________________________\n",
            "The            O\tB-nat\n",
            "United         B-geo\tI-tim\n",
            "States         I-geo\tO\n",
            "has            O\tB-per\n",
            "been           O\tO\n",
            "pressing       O\tI-eve\n",
            "for            O\tB-org\n",
            "the            O\tB-per\n",
            "expansion      O\tI-art\n",
            "to             O\tO\n",
            "relieve        O\tB-gpe\n",
            "pressure       O\tB-geo\n",
            "on             O\tI-per\n",
            "stretched      O\tI-org\n",
            "American       B-gpe\tB-art\n",
            "forces         O\tunk\n",
            ".              O\tB-org\n",
            "unk            unk\tI-tim\n",
            "unk            unk\tB-per\n",
            "unk            unk\tB-per\n",
            "unk            unk\tI-nat\n",
            "unk            unk\tunk\n",
            "unk            unk\tO\n",
            "unk            unk\tI-tim\n",
            "unk            unk\tB-org\n",
            "unk            unk\tI-per\n",
            "unk            unk\tB-nat\n",
            "unk            unk\tI-art\n",
            "unk            unk\tI-gpe\n",
            "unk            unk\tI-tim\n",
            "unk            unk\tunk\n",
            "unk            unk\tB-per\n",
            "unk            unk\tI-nat\n",
            "unk            unk\tI-nat\n",
            "unk            unk\tI-org\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tB-per\n",
            "unk            unk\tB-tim\n",
            "unk            unk\tB-tim\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tO\n",
            "unk            unk\tB-per\n",
            "unk            unk\tunk\n",
            "unk            unk\tI-nat\n",
            "unk            unk\tB-org\n",
            "unk            unk\tunk\n",
            "unk            unk\tB-art\n",
            "unk            unk\tI-nat\n",
            "unk            unk\tB-eve\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tI-tim\n",
            "unk            unk\tunk\n",
            "unk            unk\tI-per\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tI-per\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tB-tim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v1PDVsKeJ0R",
        "outputId": "5b681297-7c9d-4fd9-e020-81f8d7306a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 1), dtype=int64, numpy=\n",
              "array([[ 9],\n",
              "       [14],\n",
              "       [17],\n",
              "       [ 9],\n",
              "       [ 9],\n",
              "       [ 6],\n",
              "       [15],\n",
              "       [16],\n",
              "       [17],\n",
              "       [11],\n",
              "       [11],\n",
              "       [ 9],\n",
              "       [ 2],\n",
              "       [ 8],\n",
              "       [ 0],\n",
              "       [ 2],\n",
              "       [15],\n",
              "       [ 1],\n",
              "       [ 2],\n",
              "       [ 4],\n",
              "       [ 8],\n",
              "       [12],\n",
              "       [13],\n",
              "       [15],\n",
              "       [ 6],\n",
              "       [ 5],\n",
              "       [ 0],\n",
              "       [ 6],\n",
              "       [ 8],\n",
              "       [13],\n",
              "       [ 9],\n",
              "       [ 6],\n",
              "       [ 3],\n",
              "       [11],\n",
              "       [16],\n",
              "       [15],\n",
              "       [ 1],\n",
              "       [15],\n",
              "       [17],\n",
              "       [ 5],\n",
              "       [ 6],\n",
              "       [ 6],\n",
              "       [ 9],\n",
              "       [ 8],\n",
              "       [ 9],\n",
              "       [ 5],\n",
              "       [ 4],\n",
              "       [11],\n",
              "       [ 9],\n",
              "       [13],\n",
              "       [16],\n",
              "       [ 0],\n",
              "       [ 6],\n",
              "       [11],\n",
              "       [15],\n",
              "       [ 4],\n",
              "       [ 4],\n",
              "       [14],\n",
              "       [17],\n",
              "       [12],\n",
              "       [ 2],\n",
              "       [ 7],\n",
              "       [ 7],\n",
              "       [ 7]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih7nzDQ-eKHP",
        "outputId": "fecd3149-04a1-4233-b16e-310e3ef1dab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred_tags"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.03643083,  0.03061048,  0.02354746, ...,  0.0033778 ,\n",
              "       -0.04422568,  0.18118353], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SyS8W-GewQK",
        "outputId": "c6446cab-2d89-4ff7-8078-ebadf26514aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        ""
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-a4b0aed3c7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36msqueeze_v2\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   4429\u001b[0m   \"\"\"\n\u001b[1;32m   4430\u001b[0m   \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4431\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 instructions)\n\u001b[0;32m--> 538\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(input, axis, name, squeeze_dims)\u001b[0m\n\u001b[1;32m   4377\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4379\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m  10154\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10155\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10156\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10157\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10158\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[0], expected a dimension of 1, got 64 [Op:Squeeze]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3qt-Cfgfegr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}