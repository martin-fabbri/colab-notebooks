{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c3_w2_loading_text.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbCRhbhoEEUON5P4wi8Bws",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/c3_w2_loading_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPXHnP2dD91b"
      },
      "source": [
        "# Load Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl5cBqD-EGiR"
      },
      "source": [
        "We will use lower-level utilities like `tf.data.TextLineDataset` to load text files, and `tf.text` to preprocess the data for finer-grain control."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXgZgdXrFn6g",
        "outputId": "864bf704-dc29-4ab3-cab9-cfe935a5e7bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow_text -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.6MB 23.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PihQwFJbC4Mh",
        "outputId": "bcc82a06-e3ed-4c6f-e550-fa6619a21f17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import collections\n",
        "import pathlib\n",
        "import re\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "tf.__version__, tfds.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.3.0', '4.0.1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJkyqOTrGT0x"
      },
      "source": [
        "## Predict the tag for a Stack Overflow question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvbL46Z0FHGj",
        "outputId": "71cbb740-af0f-4292-d03e-8482421c4b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_url = 'https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\n",
        "dataset = utils.get_file(\n",
        "    'stack_overflow_16k.tar.gz',\n",
        "    data_url,\n",
        "    untar=True,\n",
        "    cache_dir='stack_overflow',\n",
        "    cache_subdir=''\n",
        ")\n",
        "dataset_dir = pathlib.Path(dataset).parent\n",
        "dataset_dir, pathlib.Path(dataset)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz\n",
            "6053888/6053168 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('/tmp/.keras'), PosixPath('/tmp/.keras/stack_overflow_16k.tar.gz'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrnshUv9GSEU",
        "outputId": "d88e91ee-2bd0-486d-80a5-7681c7e63ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list(dataset_dir.iterdir())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/tmp/.keras/README.md'),\n",
              " PosixPath('/tmp/.keras/train'),\n",
              " PosixPath('/tmp/.keras/stack_overflow_16k.tar.gz.tar.gz'),\n",
              " PosixPath('/tmp/.keras/test')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP11js0sGSJ1",
        "outputId": "37ecacb1-e189-475f-c746-a6d282632b09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dir = dataset_dir/'train'\n",
        "list(train_dir.iterdir())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/tmp/.keras/train/javascript'),\n",
              " PosixPath('/tmp/.keras/train/python'),\n",
              " PosixPath('/tmp/.keras/train/csharp'),\n",
              " PosixPath('/tmp/.keras/train/java')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRJs0cyXISj1"
      },
      "source": [
        "The `train/csharp`, `train/java`, `train/python`, and `train/javascript` directories contain many text files, each of wich is Stack Overflow question. Print a file and inspect the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYvH4eB-GSMt",
        "outputId": "12b0ea19-1547-4d48-e444-66e4ed67a354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sample_file = train_dir/'python/1757.txt'\n",
        "with open(sample_file) as f:\n",
        "  print(f.read())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"i want to return a specific list when i have a collection of lists i want to return a specific list, when i have a collection of lists, but i am not to sure how to do this. i tried this approach but it didn't work. any ideas..this_list1 = [2,3,4,5].this_list2 = [5,6,9,8]..x = input(\"\"which list do you want\"\")..print this_list(x)\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NweuvvvIJpal"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "Next, we will load the data off disk and prepare it into a format suitable for training. To do so, you will use `text_dataset_from_directory` utility to create a labeled `tf.data.Dataset`.\n",
        "\n",
        "The `preprocessing.text_dataset_from_directory` expects a directory structure as follows.\n",
        "\n",
        "```\n",
        "train/\n",
        "...csharp/\n",
        "......1.txt\n",
        "......2.txt\n",
        "...java/\n",
        "......1.txt\n",
        "......2.txt\n",
        "...javascript/\n",
        "......1.txt\n",
        "......2.txt\n",
        "...python/\n",
        "......1.txt\n",
        "......2.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE_vy8MKKnjM"
      },
      "source": [
        "When running a machine learning experiment, it is a best practice to divide your dataset into three splits: train, validation and test. Test Stack Overflow has already been divided into train and test, but it lack a validation set. Create a validation set using a 80:20 split of the training data by using the `validation_split` argument below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTCVSQKvGSHF",
        "outputId": "bf7b527c-fc9e-4850-9d72-25ed63b7ab24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "raw_train_ds = preprocessing.text_dataset_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed    \n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 6400 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr4rsQhONNka"
      },
      "source": [
        "As you can see above, there are 8,000 examples in the training folder, of which you will use 80% (or 6,400) for training. As you will see in a moment, you can train a model by passing a `tf.data.Dataset` directly to `model.fit`. First, iterate over the dataset and print out a few examples, to get a feel for the data.\n",
        "\n",
        "Note: To increase the difficulty of the classification problem, the dataset author replaced occurrences of the words *Python*, *CSharp*, *JavaScript*, or *Java* in the programming question with the word *blank*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfJmyx_CGSBR",
        "outputId": "1e3269cc-bd9a-4df4-b30b-ede9623352ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for text_batch, label_batch in raw_train_ds.take(1):\n",
        "  for i in range(10):\n",
        "    print('Question:', text_batch.numpy()[i][:100], '...')\n",
        "    print('Label:', label_batch.numpy()[i])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question: b'\"set blank to quit on exception? i\\'m using blank 3..i\\'ve been looking around for an answer to this, ' ...\n",
            "Label: 3\n",
            "Question: b'\"how do i convert a binary image into an in-memory data structure in blank? context: ...i am using b' ...\n",
            "Label: 3\n",
            "Question: b'\"adding an array of div ids to a var so i have animate multiple divs across site i found some js on ' ...\n",
            "Label: 2\n",
            "Question: b'\"fails on encountering null this code is part of a shopify sync utility. never has failed, until we ' ...\n",
            "Label: 0\n",
            "Question: b'\"blank...help me understand the include of _db.users.include(\"\"something\"\") a newbie question, i kno' ...\n",
            "Label: 0\n",
            "Question: b'\"insert table into docx file using docx project i create a word document using docx project...i need' ...\n",
            "Label: 0\n",
            "Question: b'\"printing by prototype not working in js i am trying to make a constructor function. then i am tryin' ...\n",
            "Label: 2\n",
            "Question: b'\"calculate percentage if percentage sign is in the text my project has a textbox field which is name' ...\n",
            "Label: 0\n",
            "Question: b'\"how can i execute a js function from the top of the stack? i\\'d like to execute a function from the ' ...\n",
            "Label: 2\n",
            "Question: b'\"does latest version of blank ( jdk 8u ) support jdbcodbcdriver does latest version of blank jdk 8u ' ...\n",
            "Label: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrcIgCNSOMN2"
      },
      "source": [
        "The labels are `0`, `1`, `2` or `3`. To see which of these correspond to which string label, you can check the `class_names` property on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0i9QZRkNj2V",
        "outputId": "15cdaff9-08a4-4abd-ddb7-d59c48dd1b1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i, label in enumerate(raw_train_ds.class_names):\n",
        "  print('Label', i, 'corresponds to', label)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 0 corresponds to csharp\n",
            "Label 1 corresponds to java\n",
            "Label 2 corresponds to javascript\n",
            "Label 3 corresponds to python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIsCv1UHOnL8",
        "outputId": "927574cb-a46c-4f30-bb60-c4420587edaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "raw_train_ds.class_names"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['csharp', 'java', 'javascript', 'python']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WtrRZ0HOnRo",
        "outputId": "361e58a7-ca24-40dc-9089-1e21264dee55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "raw_val_ds = preprocessing.text_dataset_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 1600 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48XxrVKsOnXn",
        "outputId": "3cb835d4-71ca-4211-e9a8-e4493f17ff94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_dir = dataset_dir/'test'\n",
        "raw_test_dir = preprocessing.text_dataset_from_directory(\n",
        "    test_dir,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erKaDD0gOndJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKWPRHjZOnjC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JSsQYgyOnmF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc5GVpAlOngK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_ZlaDUJOnai"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hynx2d9wOnUr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7AEPgtGOnO3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asuqfy5iOnIr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}