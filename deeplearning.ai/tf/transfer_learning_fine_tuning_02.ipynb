{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer-learning-fine-tuning-02.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFdAAfR/7iM1kLfYyVaFQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/transfer_learning_fine_tuning_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7-_hMJptbgE"
      },
      "source": [
        "# Transfer learning and fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXIeNi5Htg6x"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUUzYGRDtVsw"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Z8zzAgtqwv"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "**Transfer learning** consists of taking features learned on one problem, and\n",
        "leveraging them on a new, similar problem. For instance, features from a model that has\n",
        "learned to identify racoons may be useful to kick-start a model meant to identify\n",
        " tanukis.\n",
        "\n",
        "Transfer learning is usually done for **tasks where your dataset has too little data to\n",
        " train** a full-scale model from scratch.\n",
        "\n",
        "The most common incarnation of transfer learning in the context of deep learning is the\n",
        " following workflow:\n",
        "\n",
        "1. Take layers from a previously trained model.\n",
        "2. Freeze them, so as to avoid destroying any of the information they contain during\n",
        " future training rounds.\n",
        "3. Add some new, trainable layers on top of the frozen layers. They will learn to turn\n",
        " the old features into predictions on a  new dataset.\n",
        "4. Train the new layers on your dataset.\n",
        "\n",
        "A last, optional step, is **fine-tuning**, which consists of unfreezing the entire\n",
        "model you obtained above (or part of it), and re-training it on the new data with a\n",
        "very low learning rate. This can potentially achieve meaningful improvements, by\n",
        " incrementally adapting the pretrained features to the new data.\n",
        "\n",
        "First, we will go over the Keras `trainable` API in detail, which underlies most\n",
        " transfer learning & fine-tuning workflows.\n",
        "\n",
        "Then, we'll demonstrate the typical workflow by taking a model pretrained on the\n",
        "ImageNet dataset, and retraining it on the Kaggle \"cats vs dogs\" classification\n",
        " dataset.\n",
        "\n",
        "This is adapted from\n",
        "[Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)\n",
        " and the 2016 blog post\n",
        "[\"building powerful image classification models using very little\n",
        " data\"](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrDQz2vduzKq"
      },
      "source": [
        "## Freezing layers: understanding the `trainable` attribute\n",
        "\n",
        "Layers & models have three weight attributes:\n",
        "\n",
        "- `weights` is the list of all weights variables of the layer.\n",
        "- `trainable_weights` is the list of those that are meant to be updated (via gradient\n",
        " descent) to minimize the loss during training.\n",
        "- `non_trainable_weights` is the list of those that aren't meant to be trained.\n",
        " Typically they are updated by the model during the forward pass.\n",
        "\n",
        "**Example: the `Dense` layer has 2 trainable weights (kernel & bias)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL4qTjlvtqHA",
        "outputId": "1092453d-cadc-4485-8b6f-e5ad9d3fcb92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "layer = keras.layers.Dense(3)\n",
        "layer.build((None, 4)) # create weights\n",
        "\n",
        "print('weights:', len(layer.weights))\n",
        "print('trainable_weights:', len(layer.trainable_weights))\n",
        "print('non_trainable_weights:', len(layer.non_trainable_weights))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: 2\n",
            "trainable_weights: 2\n",
            "non_trainable_weights: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyinshjUv9GN"
      },
      "source": [
        "In general, all weights are trainable weights. The only built-in layer that has\n",
        "non-trainable weights is the `BatchNormalization` layer. It uses non-trainable weights\n",
        " to keep track of the mean and variance of its inputs during training.\n",
        "To learn how to use non-trainable weights in your own custom layers, see the\n",
        "[guide to writing new layers from scratch](https://keras.io/guides/making_new_layers_and_models_via_subclassing/).\n",
        "\n",
        "**Example: the `BatchNormalization` layer has 2 trainable weights and 2 non-trainable\n",
        " weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1TdnUSptqEf",
        "outputId": "ec97b7bc-0b60-44f4-ca5b-7121cbe7636a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "layer = keras.layers.BatchNormalization()\n",
        "layer.build((None, 4))  # Create the weights\n",
        "\n",
        "print(\"weights:\", len(layer.weights))\n",
        "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
        "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: 4\n",
            "trainable_weights: 2\n",
            "non_trainable_weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiOQJBLRwfcF"
      },
      "source": [
        "Layers & models also feature a boolean attribute `trainable`. Its value can be changed.\n",
        "Setting `layer.trainable` to `False` moves all the layer's weights from trainable to\n",
        "non-trainable.  This is called \"freezing\" the layer: the state of a frozen layer won't\n",
        "be updated during training (either when training with `fit()` or when training with\n",
        " any custom loop that relies on `trainable_weights` to apply gradient updates).\n",
        "\n",
        "**Example: setting `trainable` to `False`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZhcrAdOwe7L",
        "outputId": "f816d12b-3da8-4d64-ddd0-a6f5f920b107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "layer = keras.layers.Dense(3)\n",
        "layer.build((None, 4))\n",
        "layer.trainable = False\n",
        "\n",
        "print('weights:', len(layer.weights))\n",
        "print('trainable_weights:', len(layer.trainable_weights))\n",
        "print('non_trainable_weights:', len(layer.non_trainable_weights))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: 2\n",
            "trainable_weights: 0\n",
            "non_trainable_weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QCo-kMzw_Ro"
      },
      "source": [
        "When a trainable weight becomes non-trainable, its value is no longer updated during\n",
        " training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGmkavwwtqBf",
        "outputId": "b6bf121e-ea63-4787-94dc-83642203f14a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "layer1 = keras.layers.Dense(3, activation='relu')\n",
        "layer2 = keras.layers.Dense(3, activation='sigmoid')\n",
        "model = keras.Sequential([\n",
        "  keras.Input(shape=(3,)), \n",
        "  layer1, \n",
        "  layer2\n",
        "])\n",
        "layer1.trainable = False\n",
        "initial_layer1_weights_values = layer1.get_weights()\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))\n",
        "\n",
        "final_layer1_weights_values = layer1.get_weights()\n",
        "np.testing.assert_allclose(\n",
        "    initial_layer1_weights_values[0], final_layer1_weights_values[0]\n",
        ")\n",
        "np.testing.assert_allclose(\n",
        "    initial_layer1_weights_values[1], final_layer1_weights_values[1]\n",
        ")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvP1Jgqktp-r"
      },
      "source": [
        "layer1 = keras.layers.Dense(3, activation='relu')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_cDsuy1tp1F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}