{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_ner_bi_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmF+A5u9JazeNtoKh1Had/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/tf_ner_bi_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx0HfnFKVPY8",
        "cellView": "form",
        "outputId": "afcb8667-bfb2-4436-f29b-bb3b3e7a1fd3"
      },
      "source": [
        "#@title Download Kaggle Dataset\r\n",
        "#@markdown Dataset: Annotated Corpus for Named Entity Recognition <br>\r\n",
        "#@markdown https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\r\n",
        "#@markdown ___\r\n",
        "\r\n",
        "kaggle_dataset_id = \"abhinavwalia95/entity-annotated-corpus\" #@param {type:\"string\"}\r\n",
        "\r\n",
        "!pip install -q kaggle\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp /content/gdrive/My\\ Drive/kaggle/kaggle.json ~/.kaggle/kaggle.json\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json\r\n",
        "!kaggle datasets download -d {kaggle_dataset_id}\r\n",
        "!ls -l /content\r\n",
        "!unzip -o /content/entity-annotated-corpus\r\n",
        "\r\n",
        "#@markdown ___\r\n",
        "#@markdown Install dependencies<br>\r\n",
        "#@markdown - seqeval\r\n",
        "!pip install -Uqq seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "entity-annotated-corpus.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "total 195268\n",
            "-rw-r--r-- 1 root root  27703149 Dec 26 05:40 entity-annotated-corpus.zip\n",
            "drwx------ 5 root root      4096 Dec 26 05:40 gdrive\n",
            "-rw-r--r-- 1 root root 157030359 Sep 20  2019 ner.csv\n",
            "-rw-r--r-- 1 root root  15208151 Sep 20  2019 ner_dataset.csv\n",
            "drwxr-xr-x 1 root root      4096 Dec 21 17:29 sample_data\n",
            "Archive:  /content/entity-annotated-corpus.zip\n",
            "  inflating: ner.csv                 \n",
            "  inflating: ner_dataset.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiVNesPUlvmY",
        "outputId": "97fa076c-7de5-4c24-db68-dd25b68e13e2"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-9cbd5fbf-ff72-0849-7da7-51e586f90cf7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCcbeu8PWUTt"
      },
      "source": [
        "import math\r\n",
        "import pathlib\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_addons as tf_ad\r\n",
        "from numpy.random import seed\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.callbacks import TensorBoard\r\n",
        "from tensorflow.keras.layers import (\r\n",
        "    LSTM,\r\n",
        "    Bidirectional,\r\n",
        "    Dense,\r\n",
        "    Embedding,\r\n",
        "    TimeDistributed,\r\n",
        "    Dropout,\r\n",
        "    SpatialDropout1D\r\n",
        ")\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.random import set_seed\r\n",
        "\r\n",
        "set_seed(42)\r\n",
        "seed(42)\r\n",
        "\r\n",
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorflow_logs\"\r\n",
        "shutil.rmtree(logdir, ignore_errors=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWqVJaak23jf"
      },
      "source": [
        "#@title Utils\r\n",
        "#@markdown ```\r\n",
        "#@markdown - build_vocab(): Extracts unique tokens and tags\r\n",
        "#@markdown - build_indexes(): Builds the tokens and tags mapping indexes\r\n",
        "#@markdown ```\r\n",
        "\r\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "def configure_dataset(dataset):\r\n",
        "    return dataset.cache().prefetch(buffer_size=AUTOTUNE)\r\n",
        "\r\n",
        "def build_vocab(data):\r\n",
        "    tokens = {token for token in data[\"word\"]}\r\n",
        "    tokens = {\"unk\" if t is math.nan or isinstance(t, float) else t for t in tokens}\r\n",
        "    \r\n",
        "    tags = {tag for tag in data[\"tag\"]}\r\n",
        "    tags = {\"unk\" if t is math.nan or isinstance(t, float) else t for t in tags}\r\n",
        "    return tokens, tags\r\n",
        "\r\n",
        "def build_tagged_senteces(data):\r\n",
        "    agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"], s[\"tag\"])]\r\n",
        "    grouped = data.groupby(\"sentence_idx\").apply(agg_func)\r\n",
        "    sentences = [s for s in grouped]\r\n",
        "    return sentences\r\n",
        "\r\n",
        "def build_indexes(tokens, tags):\r\n",
        "    token2idx = {token: idx for idx, token in enumerate(tokens)}\r\n",
        "    idx2token = {idx: token for idx, token in enumerate(tokens)}\r\n",
        "    tag2idx = {tag: idx for idx, tag in enumerate(tags)}\r\n",
        "    idx2tag = {idx: tag for idx, tag in enumerate(tags)}\r\n",
        "    return token2idx, idx2token, tag2idx, idx2tag\r\n",
        "\r\n",
        "def tokenize(sentences, token2idx, tag2idx, one_hot_encode_tags=True):\r\n",
        "    unk_token_idx, unk_tag_idx = token2idx['unk'], tag2idx['unk']\r\n",
        "\r\n",
        "    X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n",
        "    X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=unk_token_idx)\r\n",
        "\r\n",
        "    y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n",
        "    y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=unk_tag_idx)\r\n",
        "    if one_hot_encode_tags:\r\n",
        "        y = [to_categorical(tag_idx, num_classes=num_tags) for tag_idx in y]\r\n",
        "    return X, np.array(y)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1JpDNgHWNt4"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "GTYrpk2FVbAI",
        "outputId": "98c31c44-3b1d-4ac9-b008-f50cb7fb1df8"
      },
      "source": [
        "df = pd.read_csv(\"ner.csv\", encoding=\"ISO-8859-1\", error_bad_lines=False)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>lemma</th>\n",
              "      <th>next-lemma</th>\n",
              "      <th>next-next-lemma</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-shape</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-shape</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-iob</th>\n",
              "      <th>prev-lemma</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-iob</th>\n",
              "      <th>prev-prev-lemma</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-shape</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-shape</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>shape</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thousand</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__start2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>thousand</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>VBN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>thousand</td>\n",
              "      <td>NNS</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>london</td>\n",
              "      <td>NNP</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     lemma next-lemma  ...        shape           word tag\n",
              "0           0  thousand         of  ...  capitalized      Thousands   O\n",
              "1           1        of   demonstr  ...    lowercase             of   O\n",
              "2           2  demonstr       have  ...    lowercase  demonstrators   O\n",
              "3           3      have      march  ...    lowercase           have   O\n",
              "4           4     march    through  ...    lowercase        marched   O\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "wG4MpL6Nt0cx",
        "outputId": "269b62f0-d122-4e5b-f578-9d9aa2f10daa"
      },
      "source": [
        "data = df[[\"sentence_idx\", \"word\", \"tag\"]]\r\n",
        "data.head(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>through</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>London</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>protest</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>war</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>demand</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentence_idx           word    tag\n",
              "0            1.0      Thousands      O\n",
              "1            1.0             of      O\n",
              "2            1.0  demonstrators      O\n",
              "3            1.0           have      O\n",
              "4            1.0        marched      O\n",
              "5            1.0        through      O\n",
              "6            1.0         London  B-geo\n",
              "7            1.0             to      O\n",
              "8            1.0        protest      O\n",
              "9            1.0            the      O\n",
              "10           1.0            war      O\n",
              "11           1.0             in      O\n",
              "12           1.0           Iraq  B-geo\n",
              "13           1.0            and      O\n",
              "14           1.0         demand      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InVYe7a8ujFB",
        "outputId": "f4ad1eda-3fc4-4700-82f8-5ea668868566"
      },
      "source": [
        "data[\"tag\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        889973\n",
              "B-geo     37525\n",
              "B-tim     20193\n",
              "B-org     20184\n",
              "I-per     17382\n",
              "B-per     17011\n",
              "I-org     16537\n",
              "B-gpe     16392\n",
              "I-geo      7409\n",
              "I-tim      6298\n",
              "B-art       434\n",
              "B-eve       348\n",
              "I-eve       297\n",
              "I-art       280\n",
              "I-gpe       229\n",
              "B-nat       226\n",
              "I-nat        76\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuQNAILwBXpb"
      },
      "source": [
        "### Build vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6FTBOvszaBu",
        "outputId": "32955b53-8953-4c1d-b94c-7245b5fa1253"
      },
      "source": [
        "tagged_sentences = build_tagged_senteces(data)\r\n",
        "print(\"Sample tagged sentence\")\r\n",
        "print(repr(tagged_sentences[0][:4]), \"...\")\r\n",
        "\r\n",
        "tokens, tags = build_vocab(data)\r\n",
        "num_tokens, num_tags = len(tokens), len(tags)\r\n",
        "print(\"\\nStats\")\r\n",
        "print(f\"Num tokens: {num_tokens:,}\")\r\n",
        "print(f\"Num tags: {num_tags}\")\r\n",
        "\r\n",
        "maxlen = max([len(t) for t in tokens])\r\n",
        "print(f\"maxlen: {maxlen}\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample tagged sentence\n",
            "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O')] ...\n",
            "\n",
            "Stats\n",
            "Num tokens: 30,173\n",
            "Num tags: 18\n",
            "maxlen: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyTO50ql71OJ"
      },
      "source": [
        "### Tokenize sentence and label sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAP5-ttp3U9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9fbaf7-8bc5-4e98-80c4-9902895ad181"
      },
      "source": [
        "token2idx, idx2token, tag2idx, idx2tag = build_indexes(tokens, tags)\r\n",
        "X, y = tokenize(tagged_sentences, token2idx, tag2idx)\r\n",
        "\r\n",
        "print(f\"Sentences dimension: {X.shape}\")\r\n",
        "print(f\"Labels dimension: {y.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences dimension: (35177, 64)\n",
            "Labels dimension: (35177, 64, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0wSHkWELH2r"
      },
      "source": [
        "### Split the dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS_NRQOX3UzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75196bd9-65b0-43c2-8204-8eddb84b19f8"
      },
      "source": [
        "VALIDATION_SIZE = int(len(X) * 0.1)\r\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "BUFFER_SIZE = 50000\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, y))\r\n",
        "train_dataset = dataset.skip(VALIDATION_SIZE).shuffle(BUFFER_SIZE).batch(64, drop_remainder=True)\r\n",
        "train_dataset = configure_dataset(train_dataset)\r\n",
        "\r\n",
        "test_dataset = dataset.take(VALIDATION_SIZE)\r\n",
        "test_dataset = configure_dataset(test_dataset).batch(64, drop_remainder=True)\r\n",
        "\r\n",
        "train_dataset.cardinality(), test_dataset.cardinality()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=int64, numpy=494>,\n",
              " <tf.Tensor: shape=(), dtype=int64, numpy=54>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V1GW2jvBdfD",
        "outputId": "e9e81364-319e-4ea3-b905-d197a61f7d62"
      },
      "source": [
        "model = Sequential([\r\n",
        "    Embedding(input_dim=num_tokens, output_dim=64),\r\n",
        "    SpatialDropout1D(0.1),\r\n",
        "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\r\n",
        "    TimeDistributed(Dense(num_tags, activation=\"softmax\"))\r\n",
        "])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          1931072   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, None, 64)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 200)         132000    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, None, 18)          3618      \n",
            "=================================================================\n",
            "Total params: 2,066,690\n",
            "Trainable params: 2,066,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-boCzekTIK8D"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn-t2Q4dQmSO",
        "outputId": "4a82c6a0-28ba-4f8c-bf2a-2e48e3ed7ee4"
      },
      "source": [
        "# history = model.fit(train_dataset, epochs=3, verbose=1)\r\n",
        "history = model.fit(train_dataset, epochs=3, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "494/494 [==============================] - 101s 197ms/step - loss: 0.6638 - accuracy: 0.8508\n",
            "Epoch 2/3\n",
            "494/494 [==============================] - 94s 190ms/step - loss: 0.1006 - accuracy: 0.9718\n",
            "Epoch 3/3\n",
            "494/494 [==============================] - 95s 192ms/step - loss: 0.0521 - accuracy: 0.9849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tIbuOmiQ9BS",
        "outputId": "6eb93d98-cefb-47dc-c058-7f4d19672de5"
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54/54 [==============================] - 3s 39ms/step - loss: 0.1138 - accuracy: 0.9702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11380528658628464, 0.9701877236366272]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFRd9filUScz",
        "outputId": "8501355d-9ff7-4ae8-cd6d-02780fb9bb32"
      },
      "source": [
        "X_test, y_test = next(test_dataset.take(1).as_numpy_iterator())\r\n",
        "sample_idx = np.random.randint(0, len(X_test))\r\n",
        "X_test = X_test[sample_idx]\r\n",
        "y_test = y_test[sample_idx]\r\n",
        "pred = model.predict(X_test)\r\n",
        "pred_tags = np.argmax(pred, axis=-1).flatten()\r\n",
        "ground_truth = np.argmax(y_test, axis=1)\r\n",
        "X_test.shape\r\n",
        "print(f\"{'Word':15}{'True':5}\\t {'Pred'}\\n\")\r\n",
        "print(\"_\"*30)\r\n",
        "for token, gt_tag, pred_tag in zip(X_test, ground_truth, pred_tags):\r\n",
        "    print(f\"{idx2token[token]:15}{idx2tag[gt_tag]}\\t{idx2tag[pred_tag]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           True \t Pred\n",
            "\n",
            "______________________________\n",
            "The            O\tO\n",
            "London         B-geo\tB-geo\n",
            "march          O\tO\n",
            "came           O\tO\n",
            "ahead          O\tO\n",
            "of             O\tO\n",
            "anti-war       O\tO\n",
            "protests       O\tO\n",
            "today          O\tB-tim\n",
            "in             O\tO\n",
            "other          O\tO\n",
            "cities         O\tO\n",
            ",              O\tO\n",
            "including      O\tO\n",
            "Rome           B-geo\tunk\n",
            ",              O\tO\n",
            "Paris          B-geo\tB-geo\n",
            ",              O\tO\n",
            "and            O\tO\n",
            "Madrid         B-geo\tB-gpe\n",
            ".              O\tO\n",
            "The            O\tO\n",
            "London         B-geo\tB-geo\n",
            "march          O\tO\n",
            "came           O\tO\n",
            "ahead          O\tO\n",
            "of             O\tO\n",
            "anti-war       O\tO\n",
            "protests       O\tO\n",
            "today          O\tB-tim\n",
            "in             O\tO\n",
            "other          O\tO\n",
            "cities         O\tO\n",
            ",              O\tO\n",
            "including      O\tO\n",
            "Rome           B-geo\tunk\n",
            ",              O\tO\n",
            "Paris          B-geo\tB-geo\n",
            ",              O\tO\n",
            "and            O\tO\n",
            "Madrid         B-geo\tB-gpe\n",
            ".              O\tO\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJxXzgA7v-L8"
      },
      "source": [
        "y_true = [[idx2tag[tag] for tag in ground_truth]]\r\n",
        "y_pred = [[idx2tag[tag] for tag in pred_tags]]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGe3EzRQo2PU",
        "outputId": "50f4e8c2-5dfd-4beb-ccb4-d78ae2061e34"
      },
      "source": [
        "# from seqeval.metrics import classification_report\r\n",
        "# classification_report(ground_truth, pred_tags)\r\n",
        "\r\n",
        "from seqeval.metrics import f1_score\r\n",
        "f1_score(y_true, y_pred)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: unk seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSTnBAQpw5hg",
        "outputId": "63d5ffc2-c450-4441-8b60-686f6f9debe9"
      },
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         geo       1.00      0.50      0.67         8\n",
            "         gpe       0.00      0.00      0.00         0\n",
            "          nk       0.33      1.00      0.50         1\n",
            "         tim       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.45      0.56      0.50         9\n",
            "   macro avg       0.33      0.38      0.29         9\n",
            "weighted avg       0.93      0.56      0.65         9\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: unk seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjr7--R1U0YO",
        "outputId": "69107a0e-b812-41e2-bb9d-60ddf9d53200"
      },
      "source": [
        "model_222 = Sequential([\r\n",
        "    Embedding(input_dim=num_tokens, output_dim=64),\r\n",
        "    SpatialDropout1D(0.5),\r\n",
        "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.5)),\r\n",
        "    LSTM(units=100, return_sequences=True, recurrent_dropout=0.5),\r\n",
        "    TimeDistributed(Dense(num_tags))\r\n",
        "])\r\n",
        "\r\n",
        "def loss(labels, logits):\r\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\r\n",
        "\r\n",
        "model_222.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\r\n",
        "X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n",
        "X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=unk_token_idx)\r\n",
        "\r\n",
        "y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n",
        "y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=unk_tag_idx)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\r\n",
        "history = model_222.fit(X_train, np.array(y_train), validation_split=0.2, batch_size=32, epochs=3, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/3\n",
            "792/792 [==============================] - 421s 526ms/step - loss: 0.5097 - accuracy: 0.8819 - val_loss: 0.1277 - val_accuracy: 0.9607\n",
            "Epoch 2/3\n",
            "792/792 [==============================] - 414s 523ms/step - loss: 0.1124 - accuracy: 0.9670 - val_loss: 0.0767 - val_accuracy: 0.9781\n",
            "Epoch 3/3\n",
            "792/792 [==============================] - 408s 516ms/step - loss: 0.0688 - accuracy: 0.9799 - val_loss: 0.0668 - val_accuracy: 0.9806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJqUq-0oV3mH",
        "outputId": "d0d6bd23-fba1-46da-b469-d3ecb06f5e14"
      },
      "source": [
        "model_222.evaluate(X_test, np.array(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 6s 51ms/step - loss: 0.0648 - accuracy: 0.9811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06481315195560455, 0.9811416268348694]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vuv5NN6ct4P",
        "outputId": "ecc0538e-53a6-4712-de28-c22d50703a5b"
      },
      "source": [
        "sample_idx = np.random.randint(0, len(X_test))\r\n",
        "pred = model_222(tf.expand_dims(X_test[sample_idx], 0))\r\n",
        "pred = tf.squeeze(pred, 0)\r\n",
        "pred = tf.random.categorical(pred, num_samples=1)\r\n",
        "pred_tags = pred.numpy().flatten()\r\n",
        "ground_truth = y_test[sample_idx]\r\n",
        "\r\n",
        "print(f\"{'Word':15}{'True':5}\\t {'Pred'}\\n\")\r\n",
        "print(\"_\"*30)\r\n",
        "for token, gt_tag, pred_tag in zip(X_test[sample_idx], ground_truth, pred_tags):\r\n",
        "    print(f\"{idx2token[token]:15}{idx2tag[gt_tag]}\\t{idx2tag[pred_tag]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           True \t Pred\n",
            "\n",
            "______________________________\n",
            "In             O\tO\n",
            "Baghdad        B-geo\tB-geo\n",
            ",              O\tO\n",
            "militants      O\tO\n",
            "freed          O\tO\n",
            "the            O\tO\n",
            "brother        O\tO\n",
            "of             O\tO\n",
            "Interior       O\tB-org\n",
            "Minister       O\tI-org\n",
            "Bayan          B-per\tI-per\n",
            "Jabor          I-per\tI-per\n",
            ",              O\tO\n",
            "who            O\tO\n",
            "was            O\tO\n",
            "kidnapped      O\tO\n",
            "one            B-tim\tO\n",
            "day            I-tim\tB-tim\n",
            "earlier        O\tO\n",
            "near           O\tO\n",
            "the            O\tO\n",
            "Sadr           B-geo\tB-geo\n",
            "City           I-geo\tI-geo\n",
            "district       O\tO\n",
            ".              O\tO\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n",
            "unk            unk\tunk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnTjlUnGuLa1"
      },
      "source": [
        "# Bidirectional LSTM CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SyS8W-GewQK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3qt-Cfgfegr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}