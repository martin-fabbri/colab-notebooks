{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_ner_bi_lstm.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/tf_ner_bi_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cx0HfnFKVPY8","executionInfo":{"status":"ok","timestamp":1609142963604,"user_tz":480,"elapsed":13030,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"6ba877f1-b766-4acd-f67e-f5e0b02f6338"},"source":["#@title Download Kaggle Dataset\r\n","#@markdown Dataset: Annotated Corpus for Named Entity Recognition <br>\r\n","#@markdown https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\r\n","#@markdown ___\r\n","\r\n","kaggle_dataset_id = \"abhinavwalia95/entity-annotated-corpus\" #@param {type:\"string\"}\r\n","\r\n","!pip install -q kaggle\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","\r\n","!mkdir -p ~/.kaggle\r\n","!cp /content/gdrive/My\\ Drive/kaggle/kaggle.json ~/.kaggle/kaggle.json\r\n","!chmod 600 ~/.kaggle/kaggle.json\r\n","!kaggle datasets download -d {kaggle_dataset_id}\r\n","!ls -l /content\r\n","!unzip -o /content/entity-annotated-corpus\r\n","\r\n","#@markdown ___\r\n","#@markdown Install dependencies<br>\r\n","#@markdown - seqeval: Sequence labeling evaluation (F1, precision, etc).\r\n","#@markdown - fastprogress: Progress bar for Jupyter notebooks.\r\n","\r\n","!pip install -Uqq seqeval\r\n","!pip install -Uqq fastprogress"],"execution_count":80,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","entity-annotated-corpus.zip: Skipping, found more recently modified local copy (use --force to force download)\n","ls: cannot access '/content/drive': Transport endpoint is not connected\n","total 195268\n","d????????? ? ?    ?            ?            ? drive\n","-rw-r--r-- 1 root root  27703149 Dec 28 05:29 entity-annotated-corpus.zip\n","drwx------ 5 root root      4096 Dec 28 08:09 gdrive\n","-rw-r--r-- 1 root root 157030359 Sep 20  2019 ner.csv\n","-rw-r--r-- 1 root root  15208151 Sep 20  2019 ner_dataset.csv\n","drwxr-xr-x 1 root root      4096 Dec 21 17:29 sample_data\n","Archive:  /content/entity-annotated-corpus.zip\n","  inflating: ner.csv                 \n","  inflating: ner_dataset.csv         \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JiVNesPUlvmY","executionInfo":{"status":"ok","timestamp":1609142963606,"user_tz":480,"elapsed":13022,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"59fc48f2-414d-49c4-d554-bff5cf0d29c0"},"source":["!nvidia-smi -L"],"execution_count":81,"outputs":[{"output_type":"stream","text":["GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-27e91500-0846-4d72-5058-70f66330e6b1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cCcbeu8PWUTt","executionInfo":{"status":"ok","timestamp":1609142963607,"user_tz":480,"elapsed":13015,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["import math\r\n","import pathlib\r\n","import shutil\r\n","import tempfile\r\n","\r\n","import numpy as np\r\n","import pandas as pd\r\n","import tensorflow as tf\r\n","import tensorflow_addons as tf_ad\r\n","from fastprogress.fastprogress import progress_bar\r\n","from numpy.random import seed\r\n","from seqeval.metrics import classification_report, f1_score\r\n","from sklearn.model_selection import train_test_split\r\n","from tensorflow.keras import Sequential, Model\r\n","from tensorflow.keras.callbacks import TensorBoard\r\n","from tensorflow.keras.layers import (\r\n","    LSTM,\r\n","    Bidirectional,\r\n","    Dense,\r\n","    Dropout,\r\n","    Embedding,\r\n","    SpatialDropout1D,\r\n","    TimeDistributed,\r\n",")\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n","from tensorflow.keras.utils import to_categorical\r\n","from tensorflow.random import set_seed\r\n","\r\n","set_seed(42)\r\n","seed(42)\r\n","\r\n","logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorflow_logs\"\r\n","shutil.rmtree(logdir, ignore_errors=True)"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"xWqVJaak23jf","executionInfo":{"status":"ok","timestamp":1609142963962,"user_tz":480,"elapsed":13364,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["#@title Utils\r\n","#@markdown ```\r\n","#@markdown - build_vocab(): Extracts unique tokens and tags\r\n","#@markdown - build_indexes(): Builds the tokens and tags mapping indexes\r\n","#@markdown - decode_one_hot_tags_sequence():\r\n","#@markdown - decode_tags_batch()\r\n","#@markdown - test_inference()\r\n","#@markdown ```\r\n","\r\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n","\r\n","def configure_dataset(dataset):\r\n","    return dataset.cache().prefetch(buffer_size=AUTOTUNE)\r\n","\r\n","def build_vocab(data):\r\n","    tokens = {token for token in data[\"word\"]}\r\n","    tokens = {\"unk\" if t is math.nan or isinstance(t, float) else t for t in tokens}\r\n","    tokens.add(\"PAD\")\r\n","\r\n","    tags = {tag for tag in data[\"tag\"]}\r\n","    tags = {\"O\" if t is math.nan or isinstance(t, float) else t for t in tags}\r\n","    return tokens, tags\r\n","\r\n","def build_tagged_senteces(data):\r\n","    agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"], s[\"tag\"])]\r\n","    grouped = data.groupby(\"sentence_idx\").apply(agg_func)\r\n","    sentences = [s for s in grouped]\r\n","    return sentences\r\n","\r\n","def build_indexes(tokens, tags):\r\n","    token2idx = {token: idx for idx, token in enumerate(tokens)}\r\n","    idx2token = {idx: token for idx, token in enumerate(tokens)}\r\n","    tag2idx = {tag: idx for idx, tag in enumerate(tags)}\r\n","    idx2tag = {idx: tag for idx, tag in enumerate(tags)}\r\n","    return token2idx, idx2token, tag2idx, idx2tag\r\n","\r\n","def tokenize(sentences, token2idx, tag2idx, one_hot_encode_tags=True):\r\n","    pad_token_idx, pad_tag_idx = token2idx[\"PAD\"], tag2idx[\"O\"]\r\n","\r\n","    X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n","    X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=pad_token_idx)\r\n","\r\n","    y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n","    y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=pad_tag_idx)\r\n","    if one_hot_encode_tags:\r\n","        y = [to_categorical(tag_idx, num_classes=num_tags) for tag_idx in y]\r\n","    return X, np.array(y)\r\n","\r\n","def decode_one_hot_tags_sequence(tags_sequence):\r\n","    idx_tags = np.argmax(tags_sequence, axis=-1)\r\n","    return [idx2tag[idx] for idx in idx_tags]\r\n","\r\n","def decode_tags_batch(encoded_tags_sequences):\r\n","    return [decode_one_hot_tags_sequence(seq) for seq in encoded_tags_sequences]\r\n","\r\n","def test_inference(inference_model, test_dataset):\r\n","    true_labels = []\r\n","    pred_labels = []\r\n","\r\n","    num_test_batches = test_dataset.cardinality().numpy()\r\n","    for X_batch, y_true in progress_bar(test_dataset, total=num_test_batches):\r\n","        y_pred = inference_model.predict(X_batch)\r\n","        pred_labels.append(decode_tags_batch(y_pred))\r\n","        true_labels.append(decode_tags_batch(y_true.numpy()))\r\n","\r\n","    true_labels = np.array(true_labels)\r\n","    num_batches, num_samples, sentence_lenght = true_labels.shape\r\n","    true_labels = true_labels.reshape(num_batches * num_samples, sentence_lenght)\r\n","    true_labels = true_labels.tolist()\r\n","\r\n","    pred_labels = np.array(pred_labels)\r\n","    pred_labels = pred_labels.reshape(num_batches * num_samples, sentence_lenght)\r\n","    pred_labels = pred_labels.tolist()\r\n","\r\n","    return true_labels, pred_labels"],"execution_count":83,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L1JpDNgHWNt4"},"source":["## Load the dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"GTYrpk2FVbAI","executionInfo":{"status":"ok","timestamp":1609142967482,"user_tz":480,"elapsed":16878,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"77e59afc-e195-4679-bb1b-69eadfde5caf"},"source":["df = pd.read_csv(\"ner.csv\", encoding=\"ISO-8859-1\", error_bad_lines=False)\r\n","df.head()"],"execution_count":84,"outputs":[{"output_type":"stream","text":["b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>lemma</th>\n","      <th>next-lemma</th>\n","      <th>next-next-lemma</th>\n","      <th>next-next-pos</th>\n","      <th>next-next-shape</th>\n","      <th>next-next-word</th>\n","      <th>next-pos</th>\n","      <th>next-shape</th>\n","      <th>next-word</th>\n","      <th>pos</th>\n","      <th>prev-iob</th>\n","      <th>prev-lemma</th>\n","      <th>prev-pos</th>\n","      <th>prev-prev-iob</th>\n","      <th>prev-prev-lemma</th>\n","      <th>prev-prev-pos</th>\n","      <th>prev-prev-shape</th>\n","      <th>prev-prev-word</th>\n","      <th>prev-shape</th>\n","      <th>prev-word</th>\n","      <th>sentence_idx</th>\n","      <th>shape</th>\n","      <th>word</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>thousand</td>\n","      <td>of</td>\n","      <td>demonstr</td>\n","      <td>NNS</td>\n","      <td>lowercase</td>\n","      <td>demonstrators</td>\n","      <td>IN</td>\n","      <td>lowercase</td>\n","      <td>of</td>\n","      <td>NNS</td>\n","      <td>__START1__</td>\n","      <td>__start1__</td>\n","      <td>__START1__</td>\n","      <td>__START2__</td>\n","      <td>__start2__</td>\n","      <td>__START2__</td>\n","      <td>wildcard</td>\n","      <td>__START2__</td>\n","      <td>wildcard</td>\n","      <td>__START1__</td>\n","      <td>1.0</td>\n","      <td>capitalized</td>\n","      <td>Thousands</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>of</td>\n","      <td>demonstr</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>lowercase</td>\n","      <td>have</td>\n","      <td>NNS</td>\n","      <td>lowercase</td>\n","      <td>demonstrators</td>\n","      <td>IN</td>\n","      <td>O</td>\n","      <td>thousand</td>\n","      <td>NNS</td>\n","      <td>__START1__</td>\n","      <td>__start1__</td>\n","      <td>__START1__</td>\n","      <td>wildcard</td>\n","      <td>__START1__</td>\n","      <td>capitalized</td>\n","      <td>Thousands</td>\n","      <td>1.0</td>\n","      <td>lowercase</td>\n","      <td>of</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>demonstr</td>\n","      <td>have</td>\n","      <td>march</td>\n","      <td>VBN</td>\n","      <td>lowercase</td>\n","      <td>marched</td>\n","      <td>VBP</td>\n","      <td>lowercase</td>\n","      <td>have</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","      <td>thousand</td>\n","      <td>NNS</td>\n","      <td>capitalized</td>\n","      <td>Thousands</td>\n","      <td>lowercase</td>\n","      <td>of</td>\n","      <td>1.0</td>\n","      <td>lowercase</td>\n","      <td>demonstrators</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>have</td>\n","      <td>march</td>\n","      <td>through</td>\n","      <td>IN</td>\n","      <td>lowercase</td>\n","      <td>through</td>\n","      <td>VBN</td>\n","      <td>lowercase</td>\n","      <td>marched</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","      <td>demonstr</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>lowercase</td>\n","      <td>of</td>\n","      <td>lowercase</td>\n","      <td>demonstrators</td>\n","      <td>1.0</td>\n","      <td>lowercase</td>\n","      <td>have</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>march</td>\n","      <td>through</td>\n","      <td>london</td>\n","      <td>NNP</td>\n","      <td>capitalized</td>\n","      <td>London</td>\n","      <td>IN</td>\n","      <td>lowercase</td>\n","      <td>through</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","      <td>demonstr</td>\n","      <td>NNS</td>\n","      <td>lowercase</td>\n","      <td>demonstrators</td>\n","      <td>lowercase</td>\n","      <td>have</td>\n","      <td>1.0</td>\n","      <td>lowercase</td>\n","      <td>marched</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0     lemma next-lemma  ...        shape           word tag\n","0           0  thousand         of  ...  capitalized      Thousands   O\n","1           1        of   demonstr  ...    lowercase             of   O\n","2           2  demonstr       have  ...    lowercase  demonstrators   O\n","3           3      have      march  ...    lowercase           have   O\n","4           4     march    through  ...    lowercase        marched   O\n","\n","[5 rows x 25 columns]"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":494},"id":"wG4MpL6Nt0cx","executionInfo":{"status":"ok","timestamp":1609142967485,"user_tz":480,"elapsed":16874,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"03628dcc-4935-4a1d-dc0c-6714525996f9"},"source":["data = df[[\"sentence_idx\", \"word\", \"tag\"]]\r\n","data.head(15)"],"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_idx</th>\n","      <th>word</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>Thousands</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>of</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>demonstrators</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>have</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>marched</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.0</td>\n","      <td>through</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1.0</td>\n","      <td>London</td>\n","      <td>B-geo</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1.0</td>\n","      <td>to</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.0</td>\n","      <td>protest</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1.0</td>\n","      <td>the</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1.0</td>\n","      <td>war</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1.0</td>\n","      <td>in</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1.0</td>\n","      <td>Iraq</td>\n","      <td>B-geo</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1.0</td>\n","      <td>and</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1.0</td>\n","      <td>demand</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sentence_idx           word    tag\n","0            1.0      Thousands      O\n","1            1.0             of      O\n","2            1.0  demonstrators      O\n","3            1.0           have      O\n","4            1.0        marched      O\n","5            1.0        through      O\n","6            1.0         London  B-geo\n","7            1.0             to      O\n","8            1.0        protest      O\n","9            1.0            the      O\n","10           1.0            war      O\n","11           1.0             in      O\n","12           1.0           Iraq  B-geo\n","13           1.0            and      O\n","14           1.0         demand      O"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"InVYe7a8ujFB","executionInfo":{"status":"ok","timestamp":1609142967487,"user_tz":480,"elapsed":16869,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"b078468a-4245-42fa-a9bb-9ba93b950fbd"},"source":["data[\"tag\"].value_counts()"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["O        889973\n","B-geo     37525\n","B-tim     20193\n","B-org     20184\n","I-per     17382\n","B-per     17011\n","I-org     16537\n","B-gpe     16392\n","I-geo      7409\n","I-tim      6298\n","B-art       434\n","B-eve       348\n","I-eve       297\n","I-art       280\n","I-gpe       229\n","B-nat       226\n","I-nat        76\n","Name: tag, dtype: int64"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"TuQNAILwBXpb"},"source":["### Build vocab"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6FTBOvszaBu","executionInfo":{"status":"ok","timestamp":1609142970637,"user_tz":480,"elapsed":20014,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"ef40c0b6-b2ea-46ea-f479-cda00bddbaf9"},"source":["tagged_sentences = build_tagged_senteces(data)\r\n","print(\"Sample tagged sentence\")\r\n","print(repr(tagged_sentences[0][:4]), \"...\")\r\n","\r\n","tokens, tags = build_vocab(data)\r\n","num_tokens, num_tags = len(tokens), len(tags)\r\n","print(\"\\nStats\")\r\n","print(f\"Num tokens: {num_tokens:,}\")\r\n","print(f\"Num tags: {num_tags}\")\r\n","\r\n","maxlen = max([len(t) for t in tokens])\r\n","print(f\"maxlen: {maxlen}\")\r\n"],"execution_count":87,"outputs":[{"output_type":"stream","text":["Sample tagged sentence\n","[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O')] ...\n","\n","Stats\n","Num tokens: 30,173\n","Num tags: 17\n","maxlen: 64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZyTO50ql71OJ"},"source":["### Tokenize sentence and label sequences"]},{"cell_type":"code","metadata":{"id":"CAP5-ttp3U9F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609142971806,"user_tz":480,"elapsed":21171,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"09c926f5-6951-472d-8285-e7463a3ddc4f"},"source":["token2idx, idx2token, tag2idx, idx2tag = build_indexes(tokens, tags)\r\n","X, y = tokenize(tagged_sentences, token2idx, tag2idx)\r\n","\r\n","print(f\"Sentences dimension: {X.shape}\")\r\n","print(f\"Labels dimension: {y.shape}\")"],"execution_count":88,"outputs":[{"output_type":"stream","text":["Sentences dimension: (35177, 64)\n","Labels dimension: (35177, 64, 17)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j0wSHkWELH2r"},"source":["### Split the dataset into train and test"]},{"cell_type":"code","metadata":{"id":"wS_NRQOX3UzR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609142971807,"user_tz":480,"elapsed":21163,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"af5f2e57-e58a-4b53-b21e-14b8fad52407"},"source":["VALIDATION_SIZE = int(len(X) * 0.1)\r\n","BUFFER_SIZE = 50000\r\n","\r\n","dataset = tf.data.Dataset.from_tensor_slices((X, y))\r\n","train_dataset = dataset.skip(VALIDATION_SIZE).shuffle(BUFFER_SIZE).batch(64, drop_remainder=True)\r\n","train_dataset = configure_dataset(train_dataset)\r\n","\r\n","test_dataset = dataset.take(VALIDATION_SIZE)\r\n","test_dataset = configure_dataset(test_dataset).batch(64, drop_remainder=True)\r\n","\r\n","train_dataset.cardinality(), test_dataset.cardinality()"],"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(), dtype=int64, numpy=494>,\n"," <tf.Tensor: shape=(), dtype=int64, numpy=54>)"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5V1GW2jvBdfD","executionInfo":{"status":"ok","timestamp":1609142972106,"user_tz":480,"elapsed":21453,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"73d38568-c1cd-495f-9319-a6ca7317f499"},"source":["model = Sequential([\r\n","    Embedding(input_dim=num_tokens, output_dim=64),\r\n","    SpatialDropout1D(0.1),\r\n","    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\r\n","    TimeDistributed(Dense(num_tags, activation=\"softmax\"))\r\n","])\r\n","model.summary()"],"execution_count":90,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_20 (Embedding)     (None, None, 64)          1931072   \n","_________________________________________________________________\n","spatial_dropout1d_10 (Spatia (None, None, 64)          0         \n","_________________________________________________________________\n","bidirectional_16 (Bidirectio (None, None, 200)         132000    \n","_________________________________________________________________\n","time_distributed_6 (TimeDist (None, None, 17)          3417      \n","=================================================================\n","Total params: 2,066,489\n","Trainable params: 2,066,489\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-boCzekTIK8D","executionInfo":{"status":"ok","timestamp":1609142972107,"user_tz":480,"elapsed":21445,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wn-t2Q4dQmSO","executionInfo":{"status":"ok","timestamp":1609143287703,"user_tz":480,"elapsed":337036,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"23a952f3-6f20-401b-e9c1-8b8d665af8b7"},"source":["# history = model.fit(train_dataset, epochs=3, verbose=1)\r\n","history = model.fit(train_dataset, epochs=3, verbose=1)"],"execution_count":92,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","494/494 [==============================] - 107s 212ms/step - loss: 0.5397 - accuracy: 0.9231\n","Epoch 2/3\n","494/494 [==============================] - 104s 211ms/step - loss: 0.0922 - accuracy: 0.9755\n","Epoch 3/3\n","494/494 [==============================] - 104s 211ms/step - loss: 0.0491 - accuracy: 0.9856\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6tIbuOmiQ9BS","executionInfo":{"status":"ok","timestamp":1609143290772,"user_tz":480,"elapsed":340100,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"97f360eb-eae5-48a7-ae4a-28120e1e2d59"},"source":["model.evaluate(test_dataset)"],"execution_count":93,"outputs":[{"output_type":"stream","text":["54/54 [==============================] - 3s 43ms/step - loss: 0.1139 - accuracy: 0.9698\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.1139177680015564, 0.9697898626327515]"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jFRd9filUScz","executionInfo":{"status":"ok","timestamp":1609143291062,"user_tz":480,"elapsed":340385,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"459b5601-880a-4ea2-e29b-ac2bd47efe7c"},"source":["X_test, y_test = next(test_dataset.take(1).as_numpy_iterator())\r\n","sample_idx = np.random.randint(0, len(X_test))\r\n","\r\n","X_test = X_test[sample_idx]\r\n","y_pred = model.predict(X_test)\r\n","pred_tags = decode_tags_batch(y_pred)\r\n","pred_tags = np.squeeze(pred_tags)\r\n","\r\n","y_test = y_test[sample_idx]\r\n","true_tags = decode_tags_batch([y_test])\r\n","true_tags = np.squeeze(true_tags)\r\n","\r\n","print(f\"{'Word':15}{'True':5}\\t {'Pred'}\\n\")\r\n","print(\"_\"*30)\r\n","for token_idx, true_tag, pred_tag in zip(X_test, true_tags, pred_tags):\r\n","    print(f\"{idx2token[token_idx]:15}{true_tag}\\t{pred_tag}\")"],"execution_count":94,"outputs":[{"output_type":"stream","text":["Word           True \t Pred\n","\n","______________________________\n","They           O\tO\n","marched        O\tO\n","from           O\tO\n","the            O\tO\n","Houses         O\tO\n","of             O\tO\n","Parliament     O\tB-org\n","to             O\tO\n","a              O\tO\n","rally          O\tO\n","in             O\tO\n","Hyde           B-geo\tI-per\n","Park           I-geo\tI-geo\n",".              O\tO\n","They           O\tO\n","marched        O\tO\n","from           O\tO\n","the            O\tO\n","Houses         O\tO\n","of             O\tO\n","Parliament     O\tB-org\n","to             O\tO\n","a              O\tO\n","rally          O\tO\n","in             O\tO\n","Hyde           B-geo\tI-per\n","Park           I-geo\tI-geo\n",".              O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d6VLMrKvWeqS"},"source":["## Evaluate Model"]},{"cell_type":"code","metadata":{"id":"t-PJqEmVp4St","colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"status":"ok","timestamp":1609143302452,"user_tz":480,"elapsed":351769,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"b0dea6fc-de1a-4b5e-9722-7d4d30f562e5"},"source":["true_labels, pred_labels = test_inference(model, test_dataset)\r\n","print(classification_report(true_labels, pred_labels))"],"execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='54' class='' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [54/54 00:07<00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         art       0.00      0.00      0.00       121\n","         eve       0.00      0.00      0.00        93\n","         geo       0.72      0.85      0.78      4770\n","         gpe       0.93      0.75      0.83      2716\n","         nat       0.00      0.00      0.00        46\n","         org       0.58      0.54      0.56      2704\n","         per       0.65      0.61      0.63      2403\n","         tim       0.81      0.82      0.82      2658\n","\n","   micro avg       0.74      0.72      0.73     15511\n","   macro avg       0.46      0.45      0.45     15511\n","weighted avg       0.73      0.72      0.72     15511\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UnTjlUnGuLa1"},"source":["# Bidirectional LSTM CRF"]},{"cell_type":"code","metadata":{"id":"XkuRy1mtOHdI","executionInfo":{"status":"ok","timestamp":1609143302454,"user_tz":480,"elapsed":351766,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["SPATIAL_DROPOUT_RATE = 0.5\r\n","RECURRENT_DROPOUT_RATE = 0.5\r\n","\r\n","class NerBiLstmCRF(Model):\r\n","    def __init__(self, vocab_dim, tag_dim, embedding_dim=128, lstm_men_dim=200, name=\"BiLstmCRF\", **kwargs):\r\n","        super(NerBiLstmCRF, self).__init__(name=name, **kwargs)\r\n","        self.embedding = Embedding(vocab_dim, embedding_dim)\r\n","        self.embedding_dropout = SpatialDropout1D(SPATIAL_DROPOUT_RATE)\r\n","        self.lstm = LSTM(lstm_men_dim, return_sequences=True, recurrent_dropout=RECURRENT_DROPOUT_RATE)\r\n","        self.bilstm = Bidirectional(self.lstm)\r\n","        self.classifier = Dense(tag_dim, activation=\"softmax\")\r\n","        self.time_distributed_classifier = TimeDistributed(self.classifier)\r\n","    \r\n","    def call(self, inputs):\r\n","        token_embeddings = self.embedding(inputs)\r\n","        token_embeddings = self.embedding_dropout(token_embeddings)\r\n","        bi_lstm = self.bilstm(token_embeddings)\r\n","        logits = self.time_distributed_classifier(bi_lstm)\r\n","        return logits"],"execution_count":96,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"otSrTw4A6SLH","outputId":"7af2c22d-9290-4f50-da44-9dfcd13b9918"},"source":["m = NerBiLstmCRF(num_tokens, num_tags)\r\n","m.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\r\n","m.fit(train_dataset, epochs=3)\r\n","#m.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","494/494 [==============================] - 114s 225ms/step - loss: 0.4331 - accuracy: 0.9270\n","Epoch 2/3\n","494/494 [==============================] - 110s 224ms/step - loss: 0.0649 - accuracy: 0.9814\n","Epoch 3/3\n"," 67/494 [===>..........................] - ETA: 1:35 - loss: 0.0447 - accuracy: 0.9863"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"10hvgCt3IJec"},"source":["m.evaluate(test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZjhHDDiJsEN"},"source":["true_labels, pred_labels = test_inference(m, test_dataset)\r\n","print(classification_report(true_labels, pred_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VOxdm2jDIQAE"},"source":["true_labels = []\r\n","pred_labels = []\r\n","\r\n","num_test_batches = test_dataset.cardinality().numpy()\r\n","for X_batch, y_true in progress_bar(test_dataset, total=num_test_batches):\r\n","    y_pred = model.predict(X_batch)\r\n","    pred_labels.append(decode_tags_batch(y_pred))\r\n","    true_labels.append(decode_tags_batch(y_true.numpy()))\r\n","\r\n","true_labels = np.array(true_labels)\r\n","num_batches, num_samples, sentence_lenght = true_labels.shape\r\n","true_labels = true_labels.reshape(num_batches * num_samples, sentence_lenght)\r\n","true_labels = true_labels.tolist()\r\n","\r\n","pred_labels = np.array(pred_labels)\r\n","pred_labels = pred_labels.reshape(num_batches * num_samples, sentence_lenght)\r\n","pred_labels = pred_labels.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjr7--R1U0YO"},"source":["model_222 = Sequential([\r\n","    Embedding(input_dim=num_tokens, output_dim=64),\r\n","    SpatialDropout1D(0.5),\r\n","    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.5)),\r\n","    LSTM(units=100, return_sequences=True, recurrent_dropout=0.5),\r\n","    TimeDistributed(Dense(num_tags))\r\n","])\r\n","\r\n","def loss(labels, logits):\r\n","    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\r\n","\r\n","model_222.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\r\n","X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n","X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=unk_token_idx)\r\n","\r\n","y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n","y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=unk_tag_idx)\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\r\n","history = model_222.fit(X_train, np.array(y_train), validation_split=0.2, batch_size=32, epochs=3, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJqUq-0oV3mH"},"source":["model_222.evaluate(X_test, np.array(y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Vuv5NN6ct4P"},"source":["sample_idx = np.random.randint(0, len(X_test))\r\n","pred = model_222(tf.expand_dims(X_test[sample_idx], 0))\r\n","pred = tf.squeeze(pred, 0)\r\n","pred = tf.random.categorical(pred, num_samples=1)\r\n","pred_tags = pred.numpy().flatten()\r\n","ground_truth = y_test[sample_idx]\r\n","\r\n","print(f\"{'Word':15}{'True':5}\\t {'Pred'}\\n\")\r\n","print(\"_\"*30)\r\n","for token, gt_tag, pred_tag in zip(X_test[sample_idx], ground_truth, pred_tags):\r\n","    print(f\"{idx2token[token]:15}{idx2tag[gt_tag]}\\t{idx2tag[pred_tag]}\")"],"execution_count":null,"outputs":[]}]}