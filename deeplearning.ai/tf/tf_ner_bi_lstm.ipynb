{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_ner_bi_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNeDZGUvy2cOSaA8tTKAMSE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/tf_ner_bi_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx0HfnFKVPY8",
        "outputId": "55057bd9-243c-45d0-c6b7-e2127c49224b"
      },
      "source": [
        "#@title Download Kaggle Dataset\r\n",
        "#@markdown Dataset: Annotated Corpus for Named Entity Recognition <br>\r\n",
        "#@markdown https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\r\n",
        "#@markdown ___\r\n",
        "\r\n",
        "kaggle_dataset_id = \"abhinavwalia95/entity-annotated-corpus\" #@param {type:\"string\"}\r\n",
        "\r\n",
        "!pip install -q kaggle\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp /content/gdrive/My\\ Drive/kaggle/kaggle.json ~/.kaggle/kaggle.json\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json\r\n",
        "!kaggle datasets download -d {kaggle_dataset_id}\r\n",
        "!ls -l /content\r\n",
        "!unzip -o /content/entity-annotated-corpus\r\n",
        "\r\n",
        "#@markdown ___\r\n",
        "#@markdown Install dependencies<br>\r\n",
        "#@markdown - seqeval: Sequence labeling evaluation (F1, precision, etc).\r\n",
        "#@markdown - fastprogress: Progress bar for Jupyter notebooks.\r\n",
        "\r\n",
        "!pip install -Uqq seqeval\r\n",
        "!pip install -Uqq fastprogress"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "entity-annotated-corpus.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "total 195268\n",
            "-rw-r--r-- 1 root root  27703149 Dec 26 22:53 entity-annotated-corpus.zip\n",
            "drwx------ 5 root root      4096 Dec 26 22:53 gdrive\n",
            "-rw-r--r-- 1 root root 157030359 Sep 20  2019 ner.csv\n",
            "-rw-r--r-- 1 root root  15208151 Sep 20  2019 ner_dataset.csv\n",
            "drwxr-xr-x 1 root root      4096 Dec 21 17:29 sample_data\n",
            "Archive:  /content/entity-annotated-corpus.zip\n",
            "  inflating: ner.csv                 \n",
            "  inflating: ner_dataset.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiVNesPUlvmY",
        "outputId": "1b932b54-abc9-4861-c76a-6c547c7d7a09"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-0326531b-2fdd-5b63-484f-b8068ae280c6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCcbeu8PWUTt"
      },
      "source": [
        "import math\r\n",
        "import pathlib\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_addons as tf_ad\r\n",
        "from fastprogress.fastprogress import progress_bar\r\n",
        "from numpy.random import seed\r\n",
        "from seqeval.metrics import classification_report\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.callbacks import TensorBoard\r\n",
        "from tensorflow.keras.layers import (\r\n",
        "    LSTM,\r\n",
        "    Bidirectional,\r\n",
        "    Dense,\r\n",
        "    Dropout,\r\n",
        "    Embedding,\r\n",
        "    SpatialDropout1D,\r\n",
        "    TimeDistributed,\r\n",
        ")\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.random import set_seed\r\n",
        "\r\n",
        "set_seed(42)\r\n",
        "seed(42)\r\n",
        "\r\n",
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorflow_logs\"\r\n",
        "shutil.rmtree(logdir, ignore_errors=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWqVJaak23jf"
      },
      "source": [
        "#@title Utils\r\n",
        "#@markdown ```\r\n",
        "#@markdown - build_vocab(): Extracts unique tokens and tags\r\n",
        "#@markdown - build_indexes(): Builds the tokens and tags mapping indexes\r\n",
        "#@markdown ```\r\n",
        "\r\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "def configure_dataset(dataset):\r\n",
        "    return dataset.cache().prefetch(buffer_size=AUTOTUNE)\r\n",
        "\r\n",
        "def build_vocab(data):\r\n",
        "    tokens = {token for token in data[\"word\"]}\r\n",
        "    tokens = {\"unk\" if t is math.nan or isinstance(t, float) else t for t in tokens}\r\n",
        "    \r\n",
        "    tags = {tag for tag in data[\"tag\"]}\r\n",
        "    tags = {\"unk\" if t is math.nan or isinstance(t, float) else t for t in tags}\r\n",
        "    return tokens, tags\r\n",
        "\r\n",
        "def build_tagged_senteces(data):\r\n",
        "    agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"], s[\"tag\"])]\r\n",
        "    grouped = data.groupby(\"sentence_idx\").apply(agg_func)\r\n",
        "    sentences = [s for s in grouped]\r\n",
        "    return sentences\r\n",
        "\r\n",
        "def build_indexes(tokens, tags):\r\n",
        "    token2idx = {token: idx for idx, token in enumerate(tokens)}\r\n",
        "    idx2token = {idx: token for idx, token in enumerate(tokens)}\r\n",
        "    tag2idx = {tag: idx for idx, tag in enumerate(tags)}\r\n",
        "    idx2tag = {idx: tag for idx, tag in enumerate(tags)}\r\n",
        "    return token2idx, idx2token, tag2idx, idx2tag\r\n",
        "\r\n",
        "def tokenize(sentences, token2idx, tag2idx, one_hot_encode_tags=True):\r\n",
        "    unk_token_idx, unk_tag_idx = token2idx['unk'], tag2idx['unk']\r\n",
        "\r\n",
        "    X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n",
        "    X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=unk_token_idx)\r\n",
        "\r\n",
        "    y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n",
        "    y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=unk_tag_idx)\r\n",
        "    if one_hot_encode_tags:\r\n",
        "        y = [to_categorical(tag_idx, num_classes=num_tags) for tag_idx in y]\r\n",
        "    return X, np.array(y)\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1JpDNgHWNt4"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "GTYrpk2FVbAI",
        "outputId": "20675307-85ee-41f0-8992-55c5dfd92f28"
      },
      "source": [
        "df = pd.read_csv(\"ner.csv\", encoding=\"ISO-8859-1\", error_bad_lines=False)\r\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>lemma</th>\n",
              "      <th>next-lemma</th>\n",
              "      <th>next-next-lemma</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-shape</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-shape</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-iob</th>\n",
              "      <th>prev-lemma</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-iob</th>\n",
              "      <th>prev-prev-lemma</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-shape</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-shape</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>shape</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>thousand</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__start2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>thousand</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__start1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>wildcard</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>VBN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>thousand</td>\n",
              "      <td>NNS</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>have</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>of</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>march</td>\n",
              "      <td>through</td>\n",
              "      <td>london</td>\n",
              "      <td>NNP</td>\n",
              "      <td>capitalized</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>demonstr</td>\n",
              "      <td>NNS</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>lowercase</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     lemma next-lemma  ...        shape           word tag\n",
              "0           0  thousand         of  ...  capitalized      Thousands   O\n",
              "1           1        of   demonstr  ...    lowercase             of   O\n",
              "2           2  demonstr       have  ...    lowercase  demonstrators   O\n",
              "3           3      have      march  ...    lowercase           have   O\n",
              "4           4     march    through  ...    lowercase        marched   O\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "wG4MpL6Nt0cx",
        "outputId": "72574fc9-1094-47f7-f061-8749cc99a32e"
      },
      "source": [
        "data = df[[\"sentence_idx\", \"word\", \"tag\"]]\r\n",
        "data.head(15)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>through</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>London</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>protest</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>war</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>demand</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentence_idx           word    tag\n",
              "0            1.0      Thousands      O\n",
              "1            1.0             of      O\n",
              "2            1.0  demonstrators      O\n",
              "3            1.0           have      O\n",
              "4            1.0        marched      O\n",
              "5            1.0        through      O\n",
              "6            1.0         London  B-geo\n",
              "7            1.0             to      O\n",
              "8            1.0        protest      O\n",
              "9            1.0            the      O\n",
              "10           1.0            war      O\n",
              "11           1.0             in      O\n",
              "12           1.0           Iraq  B-geo\n",
              "13           1.0            and      O\n",
              "14           1.0         demand      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InVYe7a8ujFB",
        "outputId": "c0baf190-a522-47a1-f1ec-fa966d87a4fa"
      },
      "source": [
        "data[\"tag\"].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        889973\n",
              "B-geo     37525\n",
              "B-tim     20193\n",
              "B-org     20184\n",
              "I-per     17382\n",
              "B-per     17011\n",
              "I-org     16537\n",
              "B-gpe     16392\n",
              "I-geo      7409\n",
              "I-tim      6298\n",
              "B-art       434\n",
              "B-eve       348\n",
              "I-eve       297\n",
              "I-art       280\n",
              "I-gpe       229\n",
              "B-nat       226\n",
              "I-nat        76\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuQNAILwBXpb"
      },
      "source": [
        "### Build vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6FTBOvszaBu",
        "outputId": "702bc5c4-278c-45ad-c403-fac522da6c0c"
      },
      "source": [
        "tagged_sentences = build_tagged_senteces(data)\r\n",
        "print(\"Sample tagged sentence\")\r\n",
        "print(repr(tagged_sentences[0][:4]), \"...\")\r\n",
        "\r\n",
        "tokens, tags = build_vocab(data)\r\n",
        "num_tokens, num_tags = len(tokens), len(tags)\r\n",
        "print(\"\\nStats\")\r\n",
        "print(f\"Num tokens: {num_tokens:,}\")\r\n",
        "print(f\"Num tags: {num_tags}\")\r\n",
        "\r\n",
        "maxlen = max([len(t) for t in tokens])\r\n",
        "print(f\"maxlen: {maxlen}\")\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample tagged sentence\n",
            "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O')] ...\n",
            "\n",
            "Stats\n",
            "Num tokens: 30,173\n",
            "Num tags: 18\n",
            "maxlen: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyTO50ql71OJ"
      },
      "source": [
        "### Tokenize sentence and label sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAP5-ttp3U9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8703fc-7a7e-4f0c-eda8-63296aa077b3"
      },
      "source": [
        "token2idx, idx2token, tag2idx, idx2tag = build_indexes(tokens, tags)\r\n",
        "X, y = tokenize(tagged_sentences, token2idx, tag2idx)\r\n",
        "\r\n",
        "print(f\"Sentences dimension: {X.shape}\")\r\n",
        "print(f\"Labels dimension: {y.shape}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences dimension: (35177, 64)\n",
            "Labels dimension: (35177, 64, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0wSHkWELH2r"
      },
      "source": [
        "### Split the dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS_NRQOX3UzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64d0d08-e00c-4365-e1dc-8a0e14e435e0"
      },
      "source": [
        "VALIDATION_SIZE = int(len(X) * 0.1)\r\n",
        "BUFFER_SIZE = 50000\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, y))\r\n",
        "train_dataset = dataset.skip(VALIDATION_SIZE).shuffle(BUFFER_SIZE).batch(64, drop_remainder=True)\r\n",
        "train_dataset = configure_dataset(train_dataset)\r\n",
        "\r\n",
        "test_dataset = dataset.take(VALIDATION_SIZE)\r\n",
        "test_dataset = configure_dataset(test_dataset).batch(64, drop_remainder=True)\r\n",
        "\r\n",
        "train_dataset.cardinality(), test_dataset.cardinality()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=int64, numpy=494>,\n",
              " <tf.Tensor: shape=(), dtype=int64, numpy=54>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V1GW2jvBdfD",
        "outputId": "0fae7ad9-f889-49e3-f4e7-ce3ad75d4917"
      },
      "source": [
        "model = Sequential([\r\n",
        "    Embedding(input_dim=num_tokens, output_dim=64),\r\n",
        "    SpatialDropout1D(0.1),\r\n",
        "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\r\n",
        "    TimeDistributed(Dense(num_tags, activation=\"softmax\"))\r\n",
        "])\r\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          1931072   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, None, 64)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 200)         132000    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, None, 18)          3618      \n",
            "=================================================================\n",
            "Total params: 2,066,690\n",
            "Trainable params: 2,066,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-boCzekTIK8D"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn-t2Q4dQmSO",
        "outputId": "5f444fbb-add9-481b-ac95-12312eba308f"
      },
      "source": [
        "# history = model.fit(train_dataset, epochs=3, verbose=1)\r\n",
        "history = model.fit(train_dataset, epochs=3, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "494/494 [==============================] - 104s 203ms/step - loss: 0.6362 - accuracy: 0.8563\n",
            "Epoch 2/3\n",
            "494/494 [==============================] - 101s 205ms/step - loss: 0.0885 - accuracy: 0.9767\n",
            "Epoch 3/3\n",
            "494/494 [==============================] - 102s 206ms/step - loss: 0.0486 - accuracy: 0.9858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tIbuOmiQ9BS",
        "outputId": "7bd9430a-b823-4fc3-d839-3395e3249418"
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54/54 [==============================] - 3s 44ms/step - loss: 0.1143 - accuracy: 0.9702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11432279646396637, 0.9701967835426331]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFRd9filUScz",
        "outputId": "214c4f84-6b51-46d6-ca7d-8d4f20407b7f"
      },
      "source": [
        "X_test, y_test = next(test_dataset.take(1).as_numpy_iterator())\r\n",
        "sample_idx = np.random.randint(0, len(X_test))\r\n",
        "X_test = X_test[sample_idx]\r\n",
        "y_test = y_test[sample_idx]\r\n",
        "\r\n",
        "pred = model.predict(X_test)\r\n",
        "\r\n",
        "y_true = np.argmax(y_test, axis=-1)\r\n",
        "y_pred = np.argmax(pred, axis=-1).flatten()\r\n",
        "\r\n",
        "print(f\"{'Word':15}{'True':5}\\t {'Pred'}\\n\")\r\n",
        "print(\"_\"*30)\r\n",
        "for token_idx, true_tag, pred_tag in zip(X_test, y_true, y_pred):\r\n",
        "    print(f\"{idx2token[token_idx]:15}{idx2tag[true_tag]}\\t{idx2tag[pred_tag]}\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word           True \t Pred\n",
            "\n",
            "______________________________\n",
            "the            O\tO\n",
            "supply         O\tO\n",
            "boat           O\tO\n",
            "Wednesday      B-tim\tB-tim\n",
            "as             O\tO\n",
            "it             O\tO\n",
            "sailed         O\tO\n",
            "from           O\tO\n",
            "Delta          B-geo\tunk\n",
            "State          I-geo\tI-org\n",
            "to             O\tO\n",
            "Bayelsa        B-geo\tB-geo\n",
            "State          I-geo\tI-org\n",
            "to             O\tO\n",
            "inspect        O\tO\n",
            "an             O\tO\n",
            "offshore       O\tO\n",
            "oil            O\tO\n",
            "field          O\tO\n",
            "owned          O\tO\n",
            "by             O\tO\n",
            "Royal-Dutch    B-org\tB-geo\n",
            "Shell          I-org\tunk\n",
            ".              O\tO\n",
            "An             O\tO\n",
            "official       O\tO\n",
            "with           O\tO\n",
            "the            O\tO\n",
            "German         B-gpe\tB-gpe\n",
            "firm           O\tO\n",
            "Bilfinger      B-org\tunk\n",
            "Berger         I-org\tI-per\n",
            ",              O\tO\n",
            "Thomas         B-per\tB-per\n",
            "Horbach        I-per\tO\n",
            ",              O\tO\n",
            "said           O\tO\n",
            "the            O\tO\n",
            "gunmen         O\tO\n",
            "stopped        O\tO\n",
            "the            O\tO\n",
            "supply         O\tO\n",
            "boat           O\tO\n",
            "Wednesday      B-tim\tB-tim\n",
            "as             O\tO\n",
            "it             O\tO\n",
            "sailed         O\tO\n",
            "from           O\tO\n",
            "Delta          B-geo\tunk\n",
            "State          I-geo\tI-org\n",
            "to             O\tO\n",
            "Bayelsa        B-geo\tB-geo\n",
            "State          I-geo\tI-org\n",
            "to             O\tO\n",
            "inspect        O\tO\n",
            "an             O\tO\n",
            "offshore       O\tO\n",
            "oil            O\tO\n",
            "field          O\tO\n",
            "owned          O\tO\n",
            "by             O\tO\n",
            "Royal-Dutch    B-org\tB-geo\n",
            "Shell          I-org\tunk\n",
            ".              O\tO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6VLMrKvWeqS"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "CSTnBAQpw5hg",
        "outputId": "277c0efd-524e-4d40-e28a-4b5edf39db5d"
      },
      "source": [
        "y_pred = []\r\n",
        "y_true = []\r\n",
        "num_test_batches = test_dataset.cardinality().numpy()\r\n",
        "for X_batch, y_batch in progress_bar(test_dataset, total=num_test_batches):\r\n",
        "    y_batch_pred = model.predict(X_batch)\r\n",
        "    y_pred.append(y_batch_pred)\r\n",
        "    y_true.append(y_batch.numpy())\r\n",
        "\r\n",
        "y_true = np.array(y_true)\r\n",
        "num_batches, num_sentences, length_sequence, num_tags = y_true.shape\r\n",
        "y_true = y_true.reshape(num_batches * num_sentences, length_sequence, num_tags)\r\n",
        "y_true.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='54' class='' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [54/54 00:06<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3456, 64, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJxXzgA7v-L8"
      },
      "source": [
        "def reconstruct_tags(one_hot_tags):\r\n",
        "    tags = [np.argmax(encoded_tag, axis=-1) for encoded_tag in one_hot_tags]\r\n",
        "    return np.array(tags)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQHSrNAYXz1A",
        "outputId": "7a8416c3-7289-427e-d2a2-11626100271a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_true = np.array(reconstruct_tags(y_true))\r\n",
        "y_true.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3456, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjr7--R1U0YO"
      },
      "source": [
        "model_222 = Sequential([\r\n",
        "    Embedding(input_dim=num_tokens, output_dim=64),\r\n",
        "    SpatialDropout1D(0.5),\r\n",
        "    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.5)),\r\n",
        "    LSTM(units=100, return_sequences=True, recurrent_dropout=0.5),\r\n",
        "    TimeDistributed(Dense(num_tags))\r\n",
        "])\r\n",
        "\r\n",
        "def loss(labels, logits):\r\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\r\n",
        "\r\n",
        "model_222.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\r\n",
        "X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n",
        "X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=unk_token_idx)\r\n",
        "\r\n",
        "y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n",
        "y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=unk_tag_idx)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\r\n",
        "history = model_222.fit(X_train, np.array(y_train), validation_split=0.2, batch_size=32, epochs=3, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJqUq-0oV3mH"
      },
      "source": [
        "model_222.evaluate(X_test, np.array(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vuv5NN6ct4P"
      },
      "source": [
        "sample_idx = np.random.randint(0, len(X_test))\r\n",
        "pred = model_222(tf.expand_dims(X_test[sample_idx], 0))\r\n",
        "pred = tf.squeeze(pred, 0)\r\n",
        "pred = tf.random.categorical(pred, num_samples=1)\r\n",
        "pred_tags = pred.numpy().flatten()\r\n",
        "ground_truth = y_test[sample_idx]\r\n",
        "\r\n",
        "print(f\"{'Word':15}{'True':5}\\t {'Pred'}\\n\")\r\n",
        "print(\"_\"*30)\r\n",
        "for token, gt_tag, pred_tag in zip(X_test[sample_idx], ground_truth, pred_tags):\r\n",
        "    print(f\"{idx2token[token]:15}{idx2tag[gt_tag]}\\t{idx2tag[pred_tag]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnTjlUnGuLa1"
      },
      "source": [
        "# Bidirectional LSTM CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SyS8W-GewQK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3qt-Cfgfegr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}