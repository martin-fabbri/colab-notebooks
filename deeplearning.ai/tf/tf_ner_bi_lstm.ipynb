{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_ner_bi_lstm.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/tf_ner_bi_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cx0HfnFKVPY8","executionInfo":{"status":"ok","timestamp":1609175329195,"user_tz":480,"elapsed":46329,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"8b88a396-16c0-49ef-d0da-436cf09d664c"},"source":["#@title Download Kaggle Dataset\r\n","#@markdown Dataset: Annotated Corpus for Named Entity Recognition <br>\r\n","#@markdown https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\r\n","#@markdown ___\r\n","\r\n","kaggle_dataset_id = \"abhinavwalia95/entity-annotated-corpus\" #@param {type:\"string\"}\r\n","\r\n","!pip install -q kaggle\r\n","from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","\r\n","!mkdir -p ~/.kaggle\r\n","!cp /content/gdrive/My\\ Drive/kaggle/kaggle.json ~/.kaggle/kaggle.json\r\n","!chmod 600 ~/.kaggle/kaggle.json\r\n","!kaggle datasets download -d {kaggle_dataset_id}\r\n","!ls -l /content\r\n","!unzip -o /content/entity-annotated-corpus\r\n","\r\n","#@markdown ___\r\n","#@markdown Install dependencies<br>\r\n","#@markdown - seqeval: Sequence labeling evaluation (F1, precision, etc).\r\n","#@markdown - fastprogress: Progress bar for Jupyter notebooks.\r\n","\r\n","!pip install -Uqq seqeval\r\n","!pip install -Uqq fastprogress"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","Downloading entity-annotated-corpus.zip to /content\n"," 64% 17.0M/26.4M [00:01<00:00, 13.2MB/s]\n","100% 26.4M/26.4M [00:01<00:00, 18.9MB/s]\n","total 27064\n","-rw-r--r-- 1 root root 27703149 Dec 28 17:08 entity-annotated-corpus.zip\n","drwx------ 5 root root     4096 Dec 28 17:08 gdrive\n","drwxr-xr-x 1 root root     4096 Dec 21 17:29 sample_data\n","Archive:  /content/entity-annotated-corpus.zip\n","  inflating: ner.csv                 \n","  inflating: ner_dataset.csv         \n","\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n","\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JiVNesPUlvmY","executionInfo":{"status":"ok","timestamp":1609175373587,"user_tz":480,"elapsed":1148,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"c997faa0-b33f-440d-c42a-5f3c338ffba5"},"source":["!nvidia-smi -L"],"execution_count":3,"outputs":[{"output_type":"stream","text":["GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-f4ca656e-a449-1e4b-359b-42f4add93ee1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cCcbeu8PWUTt","executionInfo":{"status":"ok","timestamp":1609175375876,"user_tz":480,"elapsed":3433,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["import math\r\n","import pathlib\r\n","import shutil\r\n","import tempfile\r\n","\r\n","import numpy as np\r\n","import pandas as pd\r\n","import tensorflow as tf\r\n","import tensorflow_addons as tf_ad\r\n","from fastprogress.fastprogress import progress_bar\r\n","from numpy.random import seed\r\n","from seqeval.metrics import classification_report, f1_score\r\n","from sklearn.model_selection import train_test_split\r\n","from tensorflow.keras import Sequential, Model\r\n","from tensorflow.keras.callbacks import TensorBoard\r\n","from tensorflow.keras.layers import (\r\n","    LSTM,\r\n","    Bidirectional,\r\n","    Dense,\r\n","    Dropout,\r\n","    Embedding,\r\n","    SpatialDropout1D,\r\n","    TimeDistributed,\r\n",")\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n","from tensorflow.keras.utils import to_categorical\r\n","from tensorflow.random import set_seed\r\n","\r\n","set_seed(42)\r\n","seed(42)\r\n","\r\n","logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorflow_logs\"\r\n","shutil.rmtree(logdir, ignore_errors=True)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"xWqVJaak23jf","executionInfo":{"status":"ok","timestamp":1609175375878,"user_tz":480,"elapsed":3432,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["#@title Utils\r\n","#@markdown ```\r\n","#@markdown - build_vocab(): Extracts unique tokens and tags\r\n","#@markdown - build_indexes(): Builds the tokens and tags mapping indexes\r\n","#@markdown - decode_one_hot_tags_sequence():\r\n","#@markdown - decode_tags_batch()\r\n","#@markdown - test_inference()\r\n","#@markdown ```\r\n","\r\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n","\r\n","def configure_dataset(dataset):\r\n","    return dataset.cache().prefetch(buffer_size=AUTOTUNE)\r\n","\r\n","def build_vocab(data):\r\n","    tokens = {token for token in data[\"word\"]}\r\n","    tokens = {\"unk\" if t is math.nan or isinstance(t, float) else t for t in tokens}\r\n","    tokens.add(\"PAD\")\r\n","\r\n","    tags = {tag for tag in data[\"tag\"]}\r\n","    tags = {\"O\" if t is math.nan or isinstance(t, float) else t for t in tags}\r\n","    return tokens, tags\r\n","\r\n","def build_tagged_senteces(data):\r\n","    agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"], s[\"tag\"])]\r\n","    grouped = data.groupby(\"sentence_idx\").apply(agg_func)\r\n","    sentences = [s for s in grouped]\r\n","    return sentences\r\n","\r\n","def build_indexes(tokens, tags):\r\n","    token2idx = {token: idx for idx, token in enumerate(tokens)}\r\n","    idx2token = {idx: token for idx, token in enumerate(tokens)}\r\n","    tag2idx = {tag: idx for idx, tag in enumerate(tags)}\r\n","    idx2tag = {idx: tag for idx, tag in enumerate(tags)}\r\n","    return token2idx, idx2token, tag2idx, idx2tag\r\n","\r\n","def tokenize(sentences, token2idx, tag2idx, one_hot_encode_tags=True):\r\n","    pad_token_idx, pad_tag_idx = token2idx[\"PAD\"], tag2idx[\"O\"]\r\n","\r\n","    X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n","    X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=pad_token_idx)\r\n","\r\n","    y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n","    y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=pad_tag_idx)\r\n","    if one_hot_encode_tags:\r\n","        y = [to_categorical(tag_idx, num_classes=num_tags) for tag_idx in y]\r\n","    return X, np.array(y)\r\n","\r\n","def decode_one_hot_tags_sequence(tags_sequence):\r\n","    idx_tags = np.argmax(tags_sequence, axis=-1)\r\n","    return [idx2tag[idx] for idx in idx_tags]\r\n","\r\n","def decode_tags_batch(encoded_tags_sequences):\r\n","    return [decode_one_hot_tags_sequence(seq) for seq in encoded_tags_sequences]\r\n","\r\n","def test_inference(inference_model, test_dataset):\r\n","    true_labels = []\r\n","    pred_labels = []\r\n","\r\n","    num_test_batches = test_dataset.cardinality().numpy()\r\n","    for X_batch, y_true in progress_bar(test_dataset, total=num_test_batches):\r\n","        y_pred = inference_model.predict(X_batch)\r\n","        pred_labels.append(decode_tags_batch(y_pred))\r\n","        true_labels.append(decode_tags_batch(y_true.numpy()))\r\n","\r\n","    true_labels = np.array(true_labels)\r\n","    num_batches, num_samples, sentence_lenght = true_labels.shape\r\n","    true_labels = true_labels.reshape(num_batches * num_samples, sentence_lenght)\r\n","    true_labels = true_labels.tolist()\r\n","\r\n","    pred_labels = np.array(pred_labels)\r\n","    pred_labels = pred_labels.reshape(num_batches * num_samples, sentence_lenght)\r\n","    pred_labels = pred_labels.tolist()\r\n","\r\n","    return true_labels, pred_labels"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L1JpDNgHWNt4"},"source":["## Load the dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"GTYrpk2FVbAI","executionInfo":{"status":"ok","timestamp":1609175379594,"user_tz":480,"elapsed":7139,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"2e134841-d03d-4f11-ac4d-c32e2f44dc0d"},"source":["df = pd.read_csv(\"ner.csv\", encoding=\"ISO-8859-1\", error_bad_lines=False)\r\n","df.head()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>lemma</th>\n","      <th>next-lemma</th>\n","      <th>next-next-lemma</th>\n","      <th>next-next-pos</th>\n","      <th>next-next-shape</th>\n","      <th>next-next-word</th>\n","      <th>next-pos</th>\n","      <th>next-shape</th>\n","      <th>next-word</th>\n","      <th>pos</th>\n","      <th>prev-iob</th>\n","      <th>prev-lemma</th>\n","      <th>prev-pos</th>\n","      <th>prev-prev-iob</th>\n","      <th>prev-prev-lemma</th>\n","      <th>prev-prev-pos</th>\n","      <th>prev-prev-shape</th>\n","      <th>prev-prev-word</th>\n","      <th>prev-shape</th>\n","      <th>prev-word</th>\n","      <th>sentence_idx</th>\n","      <th>shape</th>\n","      <th>word</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>thousand</td>\n","      <td>of</td>\n","      <td>demonstr</td>\n","      <td>NNS</td>\n","      <td>lowercase</td>\n","      <td>demonstrators</td>\n","      <td>IN</td>\n","      <td>lowercase</td>\n","      <td>of</td>\n","      <td>NNS</td>\n","      <td>__START1__</td>\n","      <td>__start1__</td>\n","      <td>__START1__</td>\n","      <td>__START2__</td>\n","      <td>__start2__</td>\n","      <td>__START2__</td>\n","      <td>wildcard</td>\n","      <td>__START2__</td>\n","      <td>wildcard</td>\n","      <td>__START1__</td>\n","      <td>1.0</td>\n","      <td>capitalized</td>\n","      <td>Thousands</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>of</td>\n","      <td>demonstr</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>lowercase</td>\n","      <td>have</td>\n","      <td>NNS</td>\n","      <td>lowercase</td>\n","      <td>demonstrators</td>\n","      <td>IN</td>\n","      <td>O</td>\n","      <td>thousand</td>\n","      <td>NNS</td>\n","      <td>__START1__</td>\n","      <td>__start1__</td>\n","      <td>__START1__</td>\n","      <td>wildcard</td>\n","      <td>__START1__</td>\n","      <td>capitalized</td>\n","      <td>Thousands</td>\n","      <td>1.0</td>\n","      <td>lowercase</td>\n","      <td>of</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>demonstr</td>\n","      <td>have</td>\n","      <td>march</td>\n","      <td>VBN</td>\n","      <td>lowercase</td>\n","      <td>marched</td>\n","      <td>VBP</td>\n","      <td>lowercase</td>\n","      <td>have</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","      <td>thousand</td>\n","      <td>NNS</td>\n","      <td>capitalized</td>\n","      <td>Thousands</td>\n","      <td>lowercase</td>\n","      <td>of</td>\n","      <td>1.0</td>\n","      <td>lowercase</td>\n","      <td>demonstrators</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>have</td>\n","      <td>march</td>\n","      <td>through</td>\n","      <td>IN</td>\n","      <td>lowercase</td>\n","      <td>through</td>\n","      <td>VBN</td>\n","      <td>lowercase</td>\n","      <td>marched</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","      <td>demonstr</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>lowercase</td>\n","      <td>of</td>\n","      <td>lowercase</td>\n","      <td>demonstrators</td>\n","      <td>1.0</td>\n","      <td>lowercase</td>\n","      <td>have</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>march</td>\n","      <td>through</td>\n","      <td>london</td>\n","      <td>NNP</td>\n","      <td>capitalized</td>\n","      <td>London</td>\n","      <td>IN</td>\n","      <td>lowercase</td>\n","      <td>through</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","      <td>demonstr</td>\n","      <td>NNS</td>\n","      <td>lowercase</td>\n","      <td>demonstrators</td>\n","      <td>lowercase</td>\n","      <td>have</td>\n","      <td>1.0</td>\n","      <td>lowercase</td>\n","      <td>marched</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0     lemma next-lemma  ...        shape           word tag\n","0           0  thousand         of  ...  capitalized      Thousands   O\n","1           1        of   demonstr  ...    lowercase             of   O\n","2           2  demonstr       have  ...    lowercase  demonstrators   O\n","3           3      have      march  ...    lowercase           have   O\n","4           4     march    through  ...    lowercase        marched   O\n","\n","[5 rows x 25 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":494},"id":"wG4MpL6Nt0cx","executionInfo":{"status":"ok","timestamp":1609175379596,"user_tz":480,"elapsed":7133,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"2e2ba00e-4bf2-4038-a8f8-f31547253117"},"source":["data = df[[\"sentence_idx\", \"word\", \"tag\"]]\r\n","data.head(15)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_idx</th>\n","      <th>word</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>Thousands</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>of</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>demonstrators</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>have</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>marched</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.0</td>\n","      <td>through</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1.0</td>\n","      <td>London</td>\n","      <td>B-geo</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1.0</td>\n","      <td>to</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.0</td>\n","      <td>protest</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1.0</td>\n","      <td>the</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1.0</td>\n","      <td>war</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1.0</td>\n","      <td>in</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1.0</td>\n","      <td>Iraq</td>\n","      <td>B-geo</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1.0</td>\n","      <td>and</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1.0</td>\n","      <td>demand</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sentence_idx           word    tag\n","0            1.0      Thousands      O\n","1            1.0             of      O\n","2            1.0  demonstrators      O\n","3            1.0           have      O\n","4            1.0        marched      O\n","5            1.0        through      O\n","6            1.0         London  B-geo\n","7            1.0             to      O\n","8            1.0        protest      O\n","9            1.0            the      O\n","10           1.0            war      O\n","11           1.0             in      O\n","12           1.0           Iraq  B-geo\n","13           1.0            and      O\n","14           1.0         demand      O"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"InVYe7a8ujFB","executionInfo":{"status":"ok","timestamp":1609175379599,"user_tz":480,"elapsed":7129,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"fc9636ca-7c1f-4045-a710-fa437a04395c"},"source":["data[\"tag\"].value_counts()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["O        889973\n","B-geo     37525\n","B-tim     20193\n","B-org     20184\n","I-per     17382\n","B-per     17011\n","I-org     16537\n","B-gpe     16392\n","I-geo      7409\n","I-tim      6298\n","B-art       434\n","B-eve       348\n","I-eve       297\n","I-art       280\n","I-gpe       229\n","B-nat       226\n","I-nat        76\n","Name: tag, dtype: int64"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"TuQNAILwBXpb"},"source":["### Build vocab"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6FTBOvszaBu","executionInfo":{"status":"ok","timestamp":1609175382414,"user_tz":480,"elapsed":9937,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"2eae00fb-9015-4094-ab59-668c745279ee"},"source":["tagged_sentences = build_tagged_senteces(data)\r\n","print(\"Sample tagged sentence\")\r\n","print(repr(tagged_sentences[0][:4]), \"...\")\r\n","\r\n","tokens, tags = build_vocab(data)\r\n","num_tokens, num_tags = len(tokens), len(tags)\r\n","print(\"\\nStats\")\r\n","print(f\"Num tokens: {num_tokens:,}\")\r\n","print(f\"Num tags: {num_tags}\")\r\n","\r\n","maxlen = max([len(t) for t in tokens])\r\n","print(f\"maxlen: {maxlen}\")\r\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Sample tagged sentence\n","[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O')] ...\n","\n","Stats\n","Num tokens: 30,173\n","Num tags: 17\n","maxlen: 64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZyTO50ql71OJ"},"source":["### Tokenize sentence and label sequences"]},{"cell_type":"code","metadata":{"id":"CAP5-ttp3U9F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609175383589,"user_tz":480,"elapsed":11106,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"420982b4-9cbe-497b-ab92-820eeff38393"},"source":["token2idx, idx2token, tag2idx, idx2tag = build_indexes(tokens, tags)\r\n","X, y = tokenize(tagged_sentences, token2idx, tag2idx)\r\n","\r\n","print(f\"Sentences dimension: {X.shape}\")\r\n","print(f\"Labels dimension: {y.shape}\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Sentences dimension: (35177, 64)\n","Labels dimension: (35177, 64, 17)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j0wSHkWELH2r"},"source":["### Split the dataset into train and test"]},{"cell_type":"code","metadata":{"id":"wS_NRQOX3UzR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609175387082,"user_tz":480,"elapsed":14594,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"133265e5-cfc8-4c9e-cea8-849c387c446e"},"source":["VALIDATION_SIZE = int(len(X) * 0.1)\r\n","BUFFER_SIZE = 50000\r\n","\r\n","dataset = tf.data.Dataset.from_tensor_slices((X, y))\r\n","train_dataset = dataset.skip(VALIDATION_SIZE).shuffle(BUFFER_SIZE).batch(64, drop_remainder=True)\r\n","train_dataset = configure_dataset(train_dataset)\r\n","\r\n","test_dataset = dataset.take(VALIDATION_SIZE)\r\n","test_dataset = configure_dataset(test_dataset).batch(64, drop_remainder=True)\r\n","\r\n","train_dataset.cardinality(), test_dataset.cardinality()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(), dtype=int64, numpy=494>,\n"," <tf.Tensor: shape=(), dtype=int64, numpy=54>)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5V1GW2jvBdfD","executionInfo":{"status":"ok","timestamp":1609175387952,"user_tz":480,"elapsed":15456,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"ab9e155d-96a6-4d04-92b8-15f8909d9384"},"source":["model = Sequential([\r\n","    Embedding(input_dim=num_tokens, output_dim=64),\r\n","    SpatialDropout1D(0.1),\r\n","    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\r\n","    TimeDistributed(Dense(num_tags, activation=\"softmax\"))\r\n","])\r\n","model.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 64)          1931072   \n","_________________________________________________________________\n","spatial_dropout1d (SpatialDr (None, None, 64)          0         \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, None, 200)         132000    \n","_________________________________________________________________\n","time_distributed (TimeDistri (None, None, 17)          3417      \n","=================================================================\n","Total params: 2,066,489\n","Trainable params: 2,066,489\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-boCzekTIK8D","executionInfo":{"status":"ok","timestamp":1609175387953,"user_tz":480,"elapsed":15454,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wn-t2Q4dQmSO","executionInfo":{"status":"ok","timestamp":1609175662222,"user_tz":480,"elapsed":289717,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"63f3b894-24af-46e4-c0bb-7a3082441e81"},"source":["# history = model.fit(train_dataset, epochs=3, verbose=1)\r\n","history = model.fit(train_dataset, epochs=3, verbose=1)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","494/494 [==============================] - 93s 182ms/step - loss: 0.5156 - accuracy: 0.9270\n","Epoch 2/3\n","494/494 [==============================] - 90s 182ms/step - loss: 0.0894 - accuracy: 0.9758\n","Epoch 3/3\n","494/494 [==============================] - 91s 183ms/step - loss: 0.0486 - accuracy: 0.9857\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6tIbuOmiQ9BS","executionInfo":{"status":"ok","timestamp":1609175665117,"user_tz":480,"elapsed":292605,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"87b25f45-5bdf-44dc-9e6e-ebcf898810af"},"source":["model.evaluate(test_dataset)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["54/54 [==============================] - 3s 37ms/step - loss: 0.1136 - accuracy: 0.9696\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.11357695609331131, 0.9696316123008728]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jFRd9filUScz","executionInfo":{"status":"ok","timestamp":1609176468319,"user_tz":480,"elapsed":908,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"f9ad466d-47b7-4162-f6b3-ce6acd3b418e"},"source":["X_test, y_test = next(test_dataset.take(1).as_numpy_iterator())\r\n","sample_idx = np.random.randint(0, len(X_test))\r\n","\r\n","X_test = X_test[sample_idx]\r\n","y_pred = model.predict(X_test)\r\n","pred_tags = decode_tags_batch(y_pred)\r\n","pred_tags = np.squeeze(pred_tags)\r\n","\r\n","y_test = y_test[sample_idx]\r\n","true_tags = decode_tags_batch([y_test])\r\n","true_tags = np.squeeze(true_tags)\r\n","\r\n","print(f\"{'Word':15}{'True':5}\\t {'Pred'}\\n\")\r\n","print(\"_\"*30)\r\n","for token_idx, true_tag, pred_tag in zip(X_test, true_tags, pred_tags):\r\n","    print(f\"{idx2token[token_idx]:15}{true_tag}\\t{pred_tag}\")"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Word           True \t Pred\n","\n","______________________________\n","The            O\tO\n","area           O\tO\n","became         O\tO\n","a              O\tO\n","refuge         O\tO\n","for            O\tO\n","many           O\tO\n","al-Qaida       B-org\tB-org\n","and            O\tO\n","Taleban        B-org\tB-org\n","fighters       O\tO\n","after          O\tO\n","the            O\tO\n","Taleban        B-org\tB-org\n","government     O\tO\n","was            O\tO\n","ousted         O\tO\n","in             O\tO\n","Afghanistan    B-geo\tB-gpe\n","in             O\tO\n","2001           B-tim\tI-tim\n",".              O\tO\n","The            O\tO\n","area           O\tO\n","became         O\tO\n","a              O\tO\n","refuge         O\tO\n","for            O\tO\n","many           O\tO\n","al-Qaida       B-org\tB-org\n","and            O\tO\n","Taleban        B-org\tB-org\n","fighters       O\tO\n","after          O\tO\n","the            O\tO\n","Taleban        B-org\tB-org\n","government     O\tO\n","was            O\tO\n","ousted         O\tO\n","in             O\tO\n","Afghanistan    B-geo\tB-gpe\n","in             O\tO\n","2001           B-tim\tI-tim\n",".              O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n","PAD            O\tO\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d6VLMrKvWeqS"},"source":["## Evaluate Model"]},{"cell_type":"code","metadata":{"id":"t-PJqEmVp4St","colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"status":"ok","timestamp":1609175674444,"user_tz":480,"elapsed":301919,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"bed3afe0-2e8f-443d-a6a7-b87842cd75d6"},"source":["true_labels, pred_labels = test_inference(model, test_dataset)\r\n","print(classification_report(true_labels, pred_labels))"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='54' class='' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [54/54 00:06<00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         art       0.00      0.00      0.00       121\n","         eve       0.00      0.00      0.00        93\n","         geo       0.72      0.84      0.78      4770\n","         gpe       0.93      0.75      0.83      2716\n","         nat       0.00      0.00      0.00        46\n","         org       0.54      0.55      0.54      2704\n","         per       0.65      0.60      0.62      2403\n","         tim       0.81      0.82      0.82      2658\n","\n","   micro avg       0.72      0.72      0.72     15511\n","   macro avg       0.46      0.44      0.45     15511\n","weighted avg       0.72      0.72      0.71     15511\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UnTjlUnGuLa1"},"source":["# Bidirectional LSTM CRF"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sde1HgV8Z3Kq","executionInfo":{"status":"ok","timestamp":1609177692297,"user_tz":480,"elapsed":1468,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"877fbb46-ef92-467f-db0a-116f1bb5d12e"},"source":["X, y = tokenize(tagged_sentences, token2idx, tag2idx, one_hot_encode_tags=False)\r\n","\r\n","print(f\"Sentences dimension: {X.shape}\")\r\n","print(f\"Labels dimension: {y.shape}\")\r\n","\r\n","dataset = tf.data.Dataset.from_tensor_slices((X, y))\r\n","train_dataset = (\r\n","    dataset.skip(VALIDATION_SIZE).shuffle(BUFFER_SIZE).batch(64, drop_remainder=True)\r\n",")\r\n","train_dataset = configure_dataset(train_dataset)\r\n","\r\n","test_dataset = dataset.take(VALIDATION_SIZE)\r\n","test_dataset = configure_dataset(test_dataset).batch(64, drop_remainder=True)\r\n","\r\n","train_dataset.cardinality(), test_dataset.cardinality()"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Sentences dimension: (35177, 64)\n","Labels dimension: (35177, 64)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(), dtype=int64, numpy=494>,\n"," <tf.Tensor: shape=(), dtype=int64, numpy=54>)"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"XkuRy1mtOHdI","executionInfo":{"status":"ok","timestamp":1609177993459,"user_tz":480,"elapsed":652,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["SPATIAL_DROPOUT_RATE = 0.5\r\n","RECURRENT_DROPOUT_RATE = 0.5\r\n","\r\n","\r\n","class NerBiLstmCRF(Model):\r\n","    def __init__(\r\n","        self,\r\n","        vocab_dim,\r\n","        tag_dim,\r\n","        max_seq_len,\r\n","        embedding_dim=128,\r\n","        lstm_men_dim=200,\r\n","        name=\"BiLstmCRF\",\r\n","        **kwargs\r\n","    ):\r\n","        super(NerBiLstmCRF, self).__init__(name=name, **kwargs)\r\n","        self.embedding = Embedding(vocab_dim, embedding_dim)\r\n","        self.dropout = SpatialDropout1D(SPATIAL_DROPOUT_RATE)\r\n","        self.lstm = LSTM(\r\n","            lstm_men_dim,\r\n","            return_sequences=True,\r\n","            recurrent_dropout=RECURRENT_DROPOUT_RATE,\r\n","        )\r\n","        self.bi_lstm = Bidirectional(self.lstm)\r\n","        self.classifier = Dense(tag_dim, activation=\"softmax\")\r\n","        self.time_distributed_classifier = TimeDistributed(self.classifier)\r\n","        self.sequence_lengths = tf.expand_dims(max_seq_len, axis=0)\r\n","\r\n","        # self.transition_params = tf.Variable(\r\n","        #     tf.random.uniform(shape=(tag_dim, tag_dim))\r\n","        # )\r\n","\r\n","    def call(self, inputs, labels=None, training=False):\r\n","        # text_lens = tf.math.reduce_sum(\r\n","        #     tf.cast(tf.math.not_equal(inputs, 0), dtype=tf.int32), axis=-1\r\n","        # )\r\n","        token_embeddings = self.embedding(inputs)\r\n","        token_embeddings = self.dropout(token_embeddings, training)\r\n","        logits = self.bi_lstm(token_embeddings)\r\n","        logits = self.time_distributed_classifier(logits)\r\n","\r\n","        if labels is not None:\r\n","            # label_sequences = tf.convert_to_tensor(labels, dtype=tf.int32)\r\n","            label_sequences = labels\r\n","            log_likelihood, _ = tf_ad.text.crf_log_likelihood(\r\n","                logits, label_sequences, self.sequence_lengths\r\n","            )\r\n","            return logits, log_likelihood\r\n","        return logits"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"jVAEgOpjkz53","executionInfo":{"status":"ok","timestamp":1609177996501,"user_tz":480,"elapsed":1099,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["# @tf.function\r\n","def train_one_step(model, optimizer, tokens_batch, labels_batch):\r\n","    with tf.GradientTape() as tape:\r\n","        logits, log_likelihood = model(\r\n","            text_batch, labels_batch, training=True\r\n","        )\r\n","        loss = -tf.reduce_mean(log_likelihood)\r\n","    gradients = tape.gradient(loss, model.trainable_variables)\r\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n","    return loss, logits"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B6-5YNEqmGvU","executionInfo":{"status":"ok","timestamp":1609177999492,"user_tz":480,"elapsed":1823,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"c8beb98e-d183-4733-fafe-601a8ee461e7"},"source":["bi_lstm_crf_model = NerBiLstmCRF(num_tokens, num_tags, max_seq_len=maxlen)\r\n","optimizer = tf.keras.optimizers.Adam()\r\n","\r\n","for text_batch, labels_batch in train_dataset.take(1):\r\n","    loss, logits = train_one_step(\r\n","        bi_lstm_crf_model, optimizer, text_batch, labels_batch\r\n","    )"],"execution_count":71,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Training!!!!\n","Training!!!!\n","Training!!!!\n","Training!!!!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"otSrTw4A6SLH","executionInfo":{"status":"aborted","timestamp":1609175675923,"user_tz":480,"elapsed":303377,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["m = NerBiLstmCRF(num_tokens, num_tags)\r\n","m.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\r\n","m.fit(train_dataset, epochs=3)\r\n","#m.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"10hvgCt3IJec","executionInfo":{"status":"aborted","timestamp":1609175675927,"user_tz":480,"elapsed":303375,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["m.evaluate(test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZjhHDDiJsEN","executionInfo":{"status":"aborted","timestamp":1609175675928,"user_tz":480,"elapsed":303369,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["true_labels, pred_labels = test_inference(m, test_dataset)\r\n","print(classification_report(true_labels, pred_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VOxdm2jDIQAE","executionInfo":{"status":"aborted","timestamp":1609175675930,"user_tz":480,"elapsed":303364,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["true_labels = []\r\n","pred_labels = []\r\n","\r\n","num_test_batches = test_dataset.cardinality().numpy()\r\n","for X_batch, y_true in progress_bar(test_dataset, total=num_test_batches):\r\n","    y_pred = model.predict(X_batch)\r\n","    pred_labels.append(decode_tags_batch(y_pred))\r\n","    true_labels.append(decode_tags_batch(y_true.numpy()))\r\n","\r\n","true_labels = np.array(true_labels)\r\n","num_batches, num_samples, sentence_lenght = true_labels.shape\r\n","true_labels = true_labels.reshape(num_batches * num_samples, sentence_lenght)\r\n","true_labels = true_labels.tolist()\r\n","\r\n","pred_labels = np.array(pred_labels)\r\n","pred_labels = pred_labels.reshape(num_batches * num_samples, sentence_lenght)\r\n","pred_labels = pred_labels.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjr7--R1U0YO","executionInfo":{"status":"aborted","timestamp":1609175675931,"user_tz":480,"elapsed":303358,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["model_222 = Sequential([\r\n","    Embedding(input_dim=num_tokens, output_dim=64),\r\n","    SpatialDropout1D(0.5),\r\n","    Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.5)),\r\n","    LSTM(units=100, return_sequences=True, recurrent_dropout=0.5),\r\n","    TimeDistributed(Dense(num_tags))\r\n","])\r\n","\r\n","def loss(labels, logits):\r\n","    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\r\n","\r\n","model_222.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\r\n","X = [[token2idx[t] for t, _ in s] for s in sentences]\r\n","X = pad_sequences(X, maxlen=maxlen, padding=\"post\", value=unk_token_idx)\r\n","\r\n","y = [[tag2idx[t] for _, t in s] for s in sentences]\r\n","y = pad_sequences(y, maxlen=maxlen, padding=\"post\", value=unk_tag_idx)\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\r\n","history = model_222.fit(X_train, np.array(y_train), validation_split=0.2, batch_size=32, epochs=3, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJqUq-0oV3mH","executionInfo":{"status":"aborted","timestamp":1609175675933,"user_tz":480,"elapsed":303354,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["model_222.evaluate(X_test, np.array(y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Vuv5NN6ct4P","executionInfo":{"status":"aborted","timestamp":1609175675934,"user_tz":480,"elapsed":303349,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["sample_idx = np.random.randint(0, len(X_test))\r\n","pred = model_222(tf.expand_dims(X_test[sample_idx], 0))\r\n","pred = tf.squeeze(pred, 0)\r\n","pred = tf.random.categorical(pred, num_samples=1)\r\n","pred_tags = pred.numpy().flatten()\r\n","ground_truth = y_test[sample_idx]\r\n","\r\n","print(f\"{'Word':15}{'True':5}\\t {'Pred'}\\n\")\r\n","print(\"_\"*30)\r\n","for token, gt_tag, pred_tag in zip(X_test[sample_idx], ground_truth, pred_tags):\r\n","    print(f\"{idx2token[token]:15}{idx2tag[gt_tag]}\\t{idx2tag[pred_tag]}\")"],"execution_count":null,"outputs":[]}]}