{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer-learning-and-fine-tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM4luWWFh2Rth8nIksqfwiB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/transfer_learning_and_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLpif-lXtaE3"
      },
      "source": [
        "# Transfer Learning and Fine Tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peRsbBxLta9C"
      },
      "source": [
        "The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively server as a generic model of the visual world. You can then take advantage of these leaned feature maps without having to start from scratch by training a large model on a large dataset.\n",
        "\n",
        "Transfer learning approached contained on this notebook:\n",
        "\n",
        "1. Feature Extraction: Use the representations learned by a previous network to extract meaningful features from new samples. You simply add a new classifier, which will be trained from scratch, on top of the pretrained model so that you can repurpose the feature maps learned previously from the dataset.\n",
        "\n",
        " You don't need to (re)train the entire model. The base convolutional network already contains features that are generically useful for classifying pictures. However, the final, classification part of the pretrained model is specific to the original classification task, and subsequently specific to the set of classes on which the model was trained.\n",
        "\n",
        "2. Fine-Tunning: Unfreeze a few of the top layers of a frozen model base and jointly train both the newly-added classfier layers and the last layers of the base model. This allow us to \"fine-tune\" the higher order feature representations in the base model in order to make them more relevant for the specific task.\n",
        "\n",
        "Plan of attack:\n",
        "\n",
        "1. Examine and understand the data\n",
        "2. Build an `input pipeline`, in this case using Keras ImageDataGenerator\n",
        "3. Compose the model\n",
        "  - Load in the pretrained base model (and pretrained weights)\n",
        "  - Stack the classfication layers on top\n",
        "4. Train the model \n",
        "5. Evaluate model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQLbrwlTtEyM"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqGCGPIXHcgB"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMXjeVQDHbhZ"
      },
      "source": [
        "### Data download\n",
        "\n",
        "We will use a dataset containing several thousand images of cats and cats. Download and extract a zip file containing the images, then create a `tf.data.Dataset` for training and validation using the `.image_dataset_from_directory` utility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3YC8zYuxwwa",
        "outputId": "a2b49bba-0bc1-4ca9-eb9d-18c7362c988c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, \n",
        "                                      extract=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AApkBD6Xx-V-",
        "outputId": "7c6de2e4-5b9d-4453-abdd-f6e708baf7f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'path_to_zip -> {path_to_zip}')\n",
        "print(f'os.path.dirname(path_to_zip) -> {os.path.dirname(path_to_zip)}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "path_to_zip -> /root/.keras/datasets/cats_and_dogs.zip\n",
            "os.path.dirname(path_to_zip) -> /root/.keras/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXU-IJkjHDq1",
        "outputId": "fb9818b5-62d5-4206-a556-7b68203207ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/cats_and_dogs_filtered'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCj5AOsmHFe4"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "train_dataset = image_dataset_from_directory"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}