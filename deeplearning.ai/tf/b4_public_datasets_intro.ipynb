{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "b4_public_datasets_intro.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMNEWxCYrbjRfR/aeg2Q7q+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/b4_public_datasets_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eo2xeG_BQ9O"
      },
      "source": [
        "# Using public datasets with TF Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npSuWr-hzcgb",
        "outputId": "8fb2d944-3348-4782-9b6b-477d7706f802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.8.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zofKXUsDBQQ9",
        "outputId": "757c441f-78b0-4ec9-a17b-bd70e8c2ba3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tfds.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.0.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXrJqfLTByQb",
        "outputId": "7aafc3f3-a592-464b-e59d-d14a2f065b12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist_data = tfds.load('fashion_mnist')\n",
        "type(mnist_data), mnist_data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict,\n",
              " {'test': <PrefetchDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>,\n",
              "  'train': <PrefetchDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOXXUdHSCCmN",
        "outputId": "9b964007-794d-48e9-89f3-b36f96cfaf1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for item in mnist_data:\n",
        "  print(type(item), item)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'> test\n",
            "<class 'str'> train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rNN4xdmDzNj"
      },
      "source": [
        "If you want to load these splits into a dataset containing the actual data, you can simply specify the split you want in the tfds.load command, like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXkn4VGRDDd3",
        "outputId": "8cd33646-1e93-4bf5-cd12-58d91d50a3e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist_train = tfds.load(name='fashion_mnist', split='train')\n",
        "assert isinstance(mnist_train, tf.data.Dataset)\n",
        "type(mnist_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W7PIRd2cwHP"
      },
      "source": [
        "In this instance, we we a `PrefetchDataset` object, which we can iterate through to inspect the data. One nice feature is that we can apply `take(1)` and get the first record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDh5oP9YcYG0",
        "outputId": "3c5edeb5-1c4b-4edc-ef64-cc7bdecf02c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "item = next(iter(mnist_train.take(1)))\n",
        "print(type(item))\n",
        "print(item.keys())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['image', 'label'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg88ERUsddUX",
        "outputId": "81c3be6f-c409-4163-f873-95568eb551c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "image = item['image']\n",
        "print(type(image))\n",
        "print(image.shape)\n",
        "print(image[0:0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "(28, 28, 1)\n",
            "tf.Tensor([], shape=(0, 28, 1), dtype=uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJPWpogZdwfw",
        "outputId": "eba1d9dd-e901-4d02-a971-7e84da0107d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "label = item['label']\n",
        "print(type(label))\n",
        "print(label)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbYAlzVyeP6s",
        "outputId": "ed4fd215-3b80-4e3c-adc5-6c2829e485cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist_test, info = tfds.load(name='fashion_mnist', with_info='true')\n",
        "info"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='fashion_mnist',\n",
              "    version=3.0.1,\n",
              "    description='Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.',\n",
              "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
              "    }),\n",
              "    total_num_examples=70000,\n",
              "    splits={\n",
              "        'test': 10000,\n",
              "        'train': 60000,\n",
              "    },\n",
              "    supervised_keys=('image', 'label'),\n",
              "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
              "      author    = {Han Xiao and\n",
              "                   Kashif Rasul and\n",
              "                   Roland Vollgraf},\n",
              "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
              "                   Algorithms},\n",
              "      journal   = {CoRR},\n",
              "      volume    = {abs/1708.07747},\n",
              "      year      = {2017},\n",
              "      url       = {http://arxiv.org/abs/1708.07747},\n",
              "      archivePrefix = {arXiv},\n",
              "      eprint    = {1708.07747},\n",
              "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
              "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
              "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTdptSE0geVO"
      },
      "source": [
        "## Using TFDS with Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4WpJ9BjfMmw",
        "outputId": "90472f7b-66c8-47f3-f1e7-2e6f951e6f10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "print(type(train_images))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIRtsLU0hMna"
      },
      "source": [
        "When using TFDS the code is very similar, but with some minor changes. The Keras datasets gave us `ndarray` that worked natively in `model.fit`. However, with TFDS we will need to do a little conversion work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL0DuvzkhB9X",
        "outputId": "62f1b8e9-2875-4fc8-ccd6-a0a5bc187b38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = \\\n",
        "  tfds.as_numpy(\n",
        "      tfds.load('fashion_mnist',\n",
        "                split=['train', 'test'],\n",
        "                batch_size=-1,\n",
        "                as_supervised=True))\n",
        "print(type(train_images))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dam52qBhiB3d",
        "outputId": "74c9ab23-478f-46bd-fa34-e3efca75c437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# we need to rescale our images before feeding them into the network\n",
        "# train_images = train_images * 1.0/255.0\n",
        "# test_images = test_images * 1.0/255.0\n",
        "# skipping this rescaling step in favor of adding rescaling directly\n",
        "# into the model pipeline(see layers...Rescaling) \n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1.0/255.0),\n",
        "  layers.Flatten(input_shape=(28, 28, 1)),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=5\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5283 - accuracy: 0.8138\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3998 - accuracy: 0.8541\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3670 - accuracy: 0.8657\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3464 - accuracy: 0.8729\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3294 - accuracy: 0.8794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f467c7eb2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBEEo0d4j3aL"
      },
      "source": [
        "The data is batched and shuffled to make training more effective?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU6RP8yPkaNG"
      },
      "source": [
        "## Human-or-Horses Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dx5IJJBmVRF",
        "outputId": "a015c94f-5788-45e9-dcc0-c271b43be6ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data = tfds.load('horses_or_humans', split='train', as_supervised=True)\n",
        "val_data = tfds.load('horses_or_humans', split='test', as_supervised=True)\n",
        " \n",
        "train_batches = data.shuffle(100).batch(10)\n",
        "validation_batches = val_data.batch(32)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255.0),\n",
        "    layers.Conv2D(16, (3,3), activation='relu', \n",
        "                           input_shape=(300, 300, 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches, \n",
        "    epochs=10,\n",
        "    validation_data=validation_batches\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "103/103 [==============================] - 5s 49ms/step - loss: 0.3218 - accuracy: 0.8627 - val_loss: 1.8059 - val_accuracy: 0.8477\n",
            "Epoch 2/10\n",
            "103/103 [==============================] - 5s 45ms/step - loss: 0.1534 - accuracy: 0.9484 - val_loss: 1.9836 - val_accuracy: 0.7773\n",
            "Epoch 3/10\n",
            "103/103 [==============================] - 5s 45ms/step - loss: 0.0628 - accuracy: 0.9747 - val_loss: 3.3394 - val_accuracy: 0.7969\n",
            "Epoch 4/10\n",
            "103/103 [==============================] - 5s 44ms/step - loss: 0.0671 - accuracy: 0.9757 - val_loss: 0.4579 - val_accuracy: 0.8984\n",
            "Epoch 5/10\n",
            "103/103 [==============================] - 5s 45ms/step - loss: 0.0354 - accuracy: 0.9912 - val_loss: 2.4246 - val_accuracy: 0.8086\n",
            "Epoch 6/10\n",
            "103/103 [==============================] - 5s 45ms/step - loss: 0.0074 - accuracy: 0.9971 - val_loss: 4.1770 - val_accuracy: 0.7734\n",
            "Epoch 7/10\n",
            "103/103 [==============================] - 5s 45ms/step - loss: 0.0973 - accuracy: 0.9708 - val_loss: 1.6175 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "103/103 [==============================] - 5s 44ms/step - loss: 0.0855 - accuracy: 0.9747 - val_loss: 2.5925 - val_accuracy: 0.8359\n",
            "Epoch 9/10\n",
            "103/103 [==============================] - 5s 44ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 3.8683 - val_accuracy: 0.8359\n",
            "Epoch 10/10\n",
            "103/103 [==============================] - 5s 44ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 3.3462 - val_accuracy: 0.8477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezL9rqjfnTxA"
      },
      "source": [
        "## Using Mapping Functions for Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvk6Ved2k3Ho"
      },
      "source": [
        "def augment_images(image, label):\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  return image, label"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNh9yiwkuUUt"
      },
      "source": [
        "train = data.map(augment_images)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M81OjUIOukYu",
        "outputId": "861b0fad-3de5-4048-c470-3cafd0a554ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_batches = train.shuffle(100).batch(32)\n",
        "model = tf.keras.models.Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255.0),\n",
        "    layers.Conv2D(16, (3,3), activation='relu', \n",
        "                           input_shape=(300, 300, 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches, \n",
        "    epochs=10,\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.3559 - accuracy: 0.8267\n",
            "Epoch 2/10\n",
            "33/33 [==============================] - 4s 119ms/step - loss: 0.1247 - accuracy: 0.9484\n",
            "Epoch 3/10\n",
            "33/33 [==============================] - 4s 121ms/step - loss: 0.0529 - accuracy: 0.9805\n",
            "Epoch 4/10\n",
            "33/33 [==============================] - 4s 120ms/step - loss: 0.0259 - accuracy: 0.9922\n",
            "Epoch 5/10\n",
            "33/33 [==============================] - 4s 120ms/step - loss: 0.0260 - accuracy: 0.9922\n",
            "Epoch 6/10\n",
            "33/33 [==============================] - 4s 121ms/step - loss: 0.0229 - accuracy: 0.9961\n",
            "Epoch 7/10\n",
            "33/33 [==============================] - 4s 120ms/step - loss: 0.0340 - accuracy: 0.9854\n",
            "Epoch 8/10\n",
            "33/33 [==============================] - 4s 119ms/step - loss: 0.0619 - accuracy: 0.9805\n",
            "Epoch 9/10\n",
            "33/33 [==============================] - 4s 120ms/step - loss: 0.0033 - accuracy: 0.9981\n",
            "Epoch 10/10\n",
            "33/33 [==============================] - 4s 118ms/step - loss: 0.0021 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJztAO63wOc4"
      },
      "source": [
        "## Sofisticated Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTEZeE-LwiK2"
      },
      "source": [
        "def resize(image, label):\n",
        "  image = tf.image.resize(image, [300, 300]) \n",
        "  return image, label "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXfJkrvmu7ny"
      },
      "source": [
        "def augment_image(image, label):\n",
        "  image, label = resize(image, label)\n",
        "  # random crop back to the original size\n",
        "  image = tf.image.random_crop(image, size=[300, 300, 3])\n",
        "  # random brightness\n",
        "  image = tf.image.random_brightness(image, max_delta=0.5)\n",
        "  # image = tfa.image.rotate(image, 40, interpolation='NEAREST')\n",
        "  image = tf.clip_by_value(image, 0, 1)\n",
        "  return image, label"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wjuVVozwhHv"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = (\n",
        "    train\n",
        "    .shuffle(1000)\n",
        "    .map(augment_image, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(32)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "588m47xlyMqH",
        "outputId": "08ccc07b-9a87-4cbe-cabd-61c984d34484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255.0),\n",
        "    layers.Conv2D(16, (3,3), activation='relu', \n",
        "                           input_shape=(300, 300, 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='Adam', loss='binary_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds, \n",
        "    epochs=10\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 2/33 [>.............................] - ETA: 2s - loss: 0.6928 - accuracy: 0.4844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0298s vs `on_train_batch_end` time: 0.0859s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0298s vs `on_train_batch_end` time: 0.0859s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "33/33 [==============================] - 2s 61ms/step - loss: 0.6942 - accuracy: 0.4956\n",
            "Epoch 2/10\n",
            "33/33 [==============================] - 2s 60ms/step - loss: 0.6932 - accuracy: 0.5131\n",
            "Epoch 3/10\n",
            "33/33 [==============================] - 2s 59ms/step - loss: 0.6931 - accuracy: 0.5131\n",
            "Epoch 4/10\n",
            "33/33 [==============================] - 2s 59ms/step - loss: 0.6933 - accuracy: 0.5131\n",
            "Epoch 5/10\n",
            "33/33 [==============================] - 2s 59ms/step - loss: 0.6929 - accuracy: 0.5131\n",
            "Epoch 6/10\n",
            "33/33 [==============================] - 2s 59ms/step - loss: 0.6929 - accuracy: 0.5131\n",
            "Epoch 7/10\n",
            "33/33 [==============================] - 2s 59ms/step - loss: 0.6928 - accuracy: 0.5131\n",
            "Epoch 8/10\n",
            "33/33 [==============================] - 2s 59ms/step - loss: 0.6929 - accuracy: 0.5131\n",
            "Epoch 9/10\n",
            "33/33 [==============================] - 2s 59ms/step - loss: 0.6929 - accuracy: 0.5131\n",
            "Epoch 10/10\n",
            "33/33 [==============================] - 2s 59ms/step - loss: 0.6929 - accuracy: 0.5131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi2ofqTJydhA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}