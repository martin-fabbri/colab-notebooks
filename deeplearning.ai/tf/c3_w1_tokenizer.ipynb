{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c3-w1-tokenizer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDdBroSm5nuNKQ6A4kYiUw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/tf/c3_w1_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T--gTjreFXes"
      },
      "source": [
        "# Text Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTgEWRfNGBCu"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhJED6sXFRki",
        "outputId": "4be537c9-9803-413d-b92c-330e3546cc3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentences = [\n",
        "  'i love my dog',\n",
        "  'I, love my cat',\n",
        "  'You love my dog!'\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "word_index"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': 5, 'dog': 4, 'i': 3, 'love': 1, 'my': 2, 'you': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqy6wK_xgr_2"
      },
      "source": [
        "The tokenizer is quite flexible. For example, if we were to expand the corpus with another sentence containing the word “today” but with a question mark after it, the results show that it would be smart enough to filter out “today?” as just “today”:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKmt0fNvF-kK",
        "outputId": "d6e90f2a-eab7-45f4-d6ed-68ec858cdea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentences = [\n",
        "  'i love my dog',\n",
        "  'I, love my cat',\n",
        "  'You love my dog!',\n",
        "  'Today is sunny.',\n",
        "  'Is it sunny today?',\n",
        "  'I love that it is sunny!',\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "word_index"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': 9,\n",
              " 'dog': 6,\n",
              " 'i': 2,\n",
              " 'is': 4,\n",
              " 'it': 8,\n",
              " 'love': 1,\n",
              " 'my': 3,\n",
              " 'sunny': 5,\n",
              " 'that': 11,\n",
              " 'today': 7,\n",
              " 'you': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr2HYnVEhQQh"
      },
      "source": [
        "This behavior is controlled by the `filters` parameter to the tokenizer, which defaults to removing all punctuation except the apostrophe character. So for example, “Today is a sunny day” would become a sequence containing [1, 2, 3, 4, 5] with the preceding encodings, and “Is it sunny today?” would become [2, 7, 4, 1]. Once you have the words in your sentences tokenized, the next step is to convert your sentences into lists of numbers, with the number being the value where the word is the key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpS-afi4hP3m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTs56cEDhP9P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z9izbt1hP6u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyNHEWVMhP1A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}