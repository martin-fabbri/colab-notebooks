{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"c3_w3_02_assignment_ner.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPTXmYW6w5H9cO8JgtM7Ubo"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"m6EIpHa9D_uk"},"source":["# Assignment 3 - Named Entity Recognition (NER)\r\n","\r\n","Welcome to the third programming assignment of Course 3. In this assignment, you will learn to build more complicated models with Trax. By completing this assignment, you will be able to: \r\n","\r\n","- Design the architecture of a neural network, train it, and test it. \r\n","- Process features and represents them\r\n","- Understand word padding\r\n","- Implement LSTMs\r\n","- Test with your own sentence\r\n","\r\n","## Outline\r\n","- [Introduction](#0)\r\n","- [Part 1:  Exploring the data](#1)\r\n","    - [1.1  Importing the Data](#1.1)\r\n","    - [1.2  Data generator](#1.2)\r\n","\t\t- [Exercise 01](#ex01)\r\n","- [Part 2:  Building the model](#2)\r\n","\t- [Exercise 02](#ex02)\r\n","- [Part 3:  Train the Model ](#3)\r\n","\t- [Exercise 03](#ex03)\r\n","- [Part 4:  Compute Accuracy](#4)\r\n","\t- [Exercise 04](#ex04)\r\n","- [Part 5:  Testing with your own sentence](#5)"]},{"cell_type":"markdown","metadata":{"id":"pW518F1PEEFu"},"source":["<a name=\"0\"></a>\r\n","# Introduction\r\n","\r\n","We first start by defining named entity recognition (NER). NER is a subtask of information extraction that locates and classifies named entities in a text. The named entities could be organizations, persons, locations, times, etc. \r\n","\r\n","For example:\r\n","\r\n","<img src=\"https://github.com/martin-fabbri/colab-notebooks/raw/master/deeplearning.ai/nlp/images/ner.png\" width=\"500px\"/>\r\n","\r\n","Is labeled as follows: \r\n","\r\n","- French: geopolitical entity\r\n","- Morocco: geographic entity \r\n","- Christmas: time indicator\r\n","\r\n","Everything else that is labeled with an `O` is not considered to be a named entity. In this assignment, you will train a named entity recognition system that could be trained in a few seconds (on a GPU) and will get around 75% accuracy. Then, you will load in the exact version of your model, which was trained for a longer period of time. You could then evaluate the trained version of your model to get 96% accuracy! Finally, you will be able to test your named entity recognition system with your own sentence."]},{"cell_type":"code","metadata":{"id":"8IjjHkZjFTVn","executionInfo":{"status":"ok","timestamp":1611805442155,"user_tz":480,"elapsed":3640,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["%%capture\r\n","!pip -q install trax==1.3.1"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"1feWRYDQDwus","executionInfo":{"status":"ok","timestamp":1611805718432,"user_tz":480,"elapsed":253,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["import trax\r\n","from trax import layers as tl\r\n","import os\r\n","import numpy as np\r\n","import pandas as pd\r\n","import random as rnd"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcPi_PSxF-mf","executionInfo":{"status":"ok","timestamp":1611805722196,"user_tz":480,"elapsed":290,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["def get_vocab(vocab_path, tags_path):\r\n","    vocab = {}\r\n","    with open(vocab_path) as f:\r\n","        for i, l in enumerate(f.read().splitlines()):\r\n","            vocab[l] = i  # to avoid the 0\r\n","        # loading tags (we require this to map tags to their indices)\r\n","    vocab['<PAD>'] = len(vocab) # 35180\r\n","    tag_map = {}\r\n","    with open(tags_path) as f:\r\n","        for i, t in enumerate(f.read().splitlines()):\r\n","            tag_map[t] = i \r\n","    \r\n","    return vocab, tag_map\r\n","\r\n","def get_params(vocab, tag_map, sentences_file, labels_file):\r\n","    sentences = []\r\n","    labels = []\r\n","\r\n","    with open(sentences_file) as f:\r\n","        for sentence in f.read().splitlines():\r\n","            # replace each token by its index if it is in vocab\r\n","            # else use index of UNK_WORD\r\n","            s = [vocab[token] if token in vocab \r\n","                 else vocab['UNK']\r\n","                 for token in sentence.split(' ')]\r\n","            sentences.append(s)\r\n","\r\n","    with open(labels_file) as f:\r\n","        for sentence in f.read().splitlines():\r\n","            # replace each label by its index\r\n","            l = [tag_map[label] for label in sentence.split(' ')] # I added plus 1 here\r\n","            labels.append(l) \r\n","    return sentences, labels, len(sentences)\r\n"],"execution_count":8,"outputs":[]}]}