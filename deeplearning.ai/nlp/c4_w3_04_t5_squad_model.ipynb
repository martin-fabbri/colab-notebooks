{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"c4_w3_04_t5_squad_model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1_K3M9uSN-eCEbEVDlSnukDW-5SQJmMEU","authorship_tag":"ABX9TyP8zHuxpviW/uMzcG1RiSHf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-QzUSOn6m2OX"},"source":["# Assignment 3, Part 2: T5 SQuAD Model \r\n","\r\n","Welcome to the part 2 of testing the models for this week's assignment. This time we will perform decoding using the T5 SQuAD model. In this notebook we'll perform Question Answering by providing a \"Question\", its \"Context\" and see how well we get the \"Target\" answer. \r\n","\r\n","## IMPORTANT\r\n","\r\n","- As you cannot save the changes you make to this colab, you have to make a copy of this notebook in your own drive and run that. You can do so by going to `File -> Save a copy in Drive`. Close this colab and open the copy which you have made in your own drive.\r\n","\r\n","- Go to this [google drive folder](https://drive.google.com/drive/folders/1rOZsbEzcpMRVvgrRULRh1JPFpkIG_JOz?usp=sharing) named `NLP C4 W3 Data`. In the folder, next to its name use the drop down menu to select `\"Add shortcut to Drive\" -> \"My Drive\" and then press ADD SHORTCUT`. This should add a shortcut to the folder `NLP C4 W3 Data` within your own google drive. Please make sure this happens, as you'll be reading the data for this notebook from this folder.\r\n","\r\n","- Make sure your runtime is GPU (_not_ CPU or TPU). And if it is an option, make sure you are using _Python 3_. You can select these settings by going to `Runtime -> Change runtime type -> Select the above mentioned settings and then press SAVE`"]},{"cell_type":"markdown","metadata":{"id":"HsbTPw1CnUAB"},"source":["**Note: Restarting the runtime maybe required**.\r\n","\r\n","Colab will tell you if the restarting is necessary -- you can do this from the:\r\n","\r\n","Runtime > Restart Runtime\r\n","\r\n","option in the dropdown."]},{"cell_type":"markdown","metadata":{"id":"LurN1kjlnWBe"},"source":["## Outline\r\n","\r\n","- [Part 0: Downloading and loading dependencies](#0)\r\n","- [Part 1: Mounting your drive for data accessibility](#1)\r\n","- [Part 2: Getting things ready](#2)\r\n","- [Part 3: Fine-tuning on SQuAD](#3)\r\n","    - [3.1 Loading in the data and preprocessing](#3.1)\r\n","    - [3.2 Decoding from a fine-tuned model](#3.2)"]},{"cell_type":"markdown","metadata":{"id":"OXKHFGd0sZ6s"},"source":["<a name='0'></a>\r\n","# Part 0: Downloading and loading dependencies\r\n","\r\n","Uncomment the code cell below and run it to download some dependencies that you will need. You need to download them once every time you open the colab. You can ignore the `kfac` error."]},{"cell_type":"code","metadata":{"id":"1cfrPQuMmoXS","executionInfo":{"status":"ok","timestamp":1613359148261,"user_tz":480,"elapsed":15064,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["%%capture\r\n","!pip install trax"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4MuzqhEmsqEz","executionInfo":{"status":"ok","timestamp":1613359358017,"user_tz":480,"elapsed":955,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"32028fcb-c62e-4d55-f18e-359be80d334f"},"source":["!pip list | grep 'trax\\|t5'"],"execution_count":6,"outputs":[{"output_type":"stream","text":["t5                            0.8.1                \n","trax                          1.3.7                \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pe8uAsllst6M","executionInfo":{"status":"ok","timestamp":1613359328485,"user_tz":480,"elapsed":37452,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["import string\r\n","import t5\r\n","import numpy as np\r\n","import trax \r\n","from trax.supervised import decoding\r\n","import textwrap \r\n","# Will come handy later.\r\n","wrapper = textwrap.TextWrapper(width=70)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Urvp25ftrf4"},"source":["<a name='2'></a>\r\n","# Part 2: Getting things ready \r\n","\r\n","Run the code cell below to ready some functions which will later help us in decoding. The code and the functions are the same as the ones you previsouly ran on the coursera version of the assignment."]},{"cell_type":"code","metadata":{"id":"PVru-Bz0tkcU","executionInfo":{"status":"ok","timestamp":1613360512069,"user_tz":480,"elapsed":3626,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["PAD, EOS, UNK = 0, 1, 2\r\n","\r\n","t5_data_path = \"/content/drive/MyDrive/NLP C4 W3 Data/\"\r\n","\r\n","def detokenize(np_array):\r\n","    return trax.data.detokenize(\r\n","        np_array,\r\n","        vocab_type=\"sentencepiece\",\r\n","        vocab_file=\"sentencepiece.model\",\r\n","        vocab_dir=t5_data_path\r\n","    )\r\n","\r\n","def tokenize(s):\r\n","  # The trax.data.tokenize function operates on streams,\r\n","  # that's why we have to create 1-element stream with iter\r\n","  # and later retrieve the result with next.\r\n","  return next(trax.data.tokenize(\r\n","      iter([s]),\r\n","      vocab_type='sentencepiece',\r\n","      vocab_file='sentencepiece.model',\r\n","      vocab_dir=t5_data_path))\r\n","  \r\n","vocab_size = trax.data.vocab_size(\r\n","    vocab_type='sentencepiece',\r\n","    vocab_file='sentencepiece.model',\r\n","    vocab_dir=t5_data_path)\r\n","\r\n","def get_sentinels(vocab_size):\r\n","    sentinels = {}\r\n","\r\n","    for i, char in enumerate(reversed(string.ascii_letters), 1):\r\n","\r\n","        decoded_text = detokenize([vocab_size - i]) \r\n","        \r\n","        # Sentinels, ex: <Z> - <a>\r\n","        sentinels[decoded_text] = f'<{char}>'\r\n","        \r\n","    return sentinels\r\n","\r\n","sentinels = get_sentinels(vocab_size)    \r\n","\r\n","\r\n","def pretty_decode(encoded_str_list, sentinels=sentinels):\r\n","    # If already a string, just do the replacements.\r\n","    if isinstance(encoded_str_list, (str, bytes)):\r\n","        for token, char in sentinels.items():\r\n","            encoded_str_list = encoded_str_list.replace(token, char)\r\n","        return encoded_str_list\r\n","  \r\n","    # We need to decode and then prettyfy it.\r\n","    return pretty_decode(detokenize(encoded_str_list))  "],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"58b8yJegyAXv"},"source":["<a name='3'></a>\r\n","# Part 3: Fine-tuning on SQuAD\r\n","\r\n","Now let's try to fine tune on SQuAD and see what becomes of the model. For this, we need to write a function that will create and process the SQuAD `tf.data.Dataset`. Below is how T5 pre-processes SQuAD dataset as a text2text example. Before we jump in, we will have to first load in the data. \r\n","\r\n","<a name='3.1'></a>\r\n","### 3.1 Loading in the data and preprocessing\r\n","\r\n","You first start by loading in the dataset. The text2text example for a SQuAD example looks like:\r\n","\r\n","```\r\n","{\r\n","  'inputs': 'question: <question> context: <article>',\r\n","  'targets': '<answer_0>',\r\n","}\r\n","```\r\n","\r\n","The squad pre-processing function takes in the dataset and processes it using the sentencePiece vocabulary you have seen above. It generates the features from the vocab and encodes the string features. It takes on question, context, and answer, and returns \"question: Q context: C\" as input and \"A\" as target."]},{"cell_type":"code","metadata":{"id":"xg9qioJCtkZa","executionInfo":{"status":"ok","timestamp":1613362284611,"user_tz":480,"elapsed":271,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["# Retrieve Question, C, A and return \"question: Q context: C\" as input \r\n","# and \"A\" as target.\r\n","def squad_preprocess_fn(dataset, mode=\"train\"):\r\n","    return t5.data.preprocessors.squad(dataset)\r\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IlnD-zvvtkWT","executionInfo":{"status":"ok","timestamp":1613362547353,"user_tz":480,"elapsed":17415,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"9b6e969b-f3cf-4df7-89b5-c43c6173b141"},"source":["# train generator, this takes about 1 minute\r\n","train_generator_fn, eval_generator_fn = trax.data.tf_inputs.data_streams(\r\n","    \"squad/v1.1:2.0.0\",\r\n","    data_dir=f\"{t5_data_path}data/\",\r\n","    bare_preprocess_fn=squad_preprocess_fn,\r\n","    input_name=\"inputs\",\r\n","    target_name=\"targets\"\r\n",")\r\n","train_generator = train_generator_fn()\r\n","next(train_generator)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(b'question: When was the USB Battery Charging Specification Revision 1 . 1 released ? context: The USB Battery Charging Specification Revision 1 . 1 ( released in 2007 ) defines a new type of USB port , called the charging port . Contrary to the standard downstream port , for which current draw by a connected portable device can exceed 100 mA only after digital negotiation with the host or hub , a charging port can supply currents between 500 mA and 1 . 5 A without the digital negotiation . A charging port supplies up to 500 mA at 5 V , up to the rated current at 3 . 6 V or more , and drops its output voltage if the portable device attempts to draw more than the rated current . The charger port may shut down if the load is too high . ',\n"," b'in 2007')"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"-_mOGaqKtkSx"},"source":[""],"execution_count":null,"outputs":[]}]}