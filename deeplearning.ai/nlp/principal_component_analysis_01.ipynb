{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "principal-component-analysis-01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPymfYxH0DsrpTWpK9mInYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/nlp/principal_component_analysis_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnUodS3x1czV"
      },
      "source": [
        "# Principal Component Analysis (PCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-9rcV-l2KHe"
      },
      "source": [
        "PCA is based on the `Singular Value Decomposition(SVD)` of the `Covariance Matrix` of the original dataset. The `Eigenvectors` of such decomposition are used as a **rotation matrix**. The Eigenvectors are arranged in the rotation matrix in decreasing order according to its **explained variance**. This last term is related to `EigenValues` of the SVD.\n",
        "\n",
        "PCA is a potent technique with applications ranging from simple space transformation, dimensionality reduction, and mixture separation from spectral information.\n",
        "\n",
        "<img src=\"https://dbjxwcks.labs.coursera.org/notebooks/GaussianScatterPCA.svg\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QyU4AJ31aK2"
      },
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp9zfPlw6ocw"
      },
      "source": [
        "To start, let us consider a pair of random variables $x$, $y$. Consider the base case $y=n*x$. The $x$ and $y$ variables will be perfectly correlated to each other since $y$ is just a scaling of $x$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImCyJcnb6ly-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}