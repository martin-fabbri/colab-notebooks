{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"c3_w1_01_trax_intro.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMhsu1MXR+RKpfwd/STUtaC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zSC4IYh3010_"},"source":["# Trax Intro\n","\n","[Trax](https://trax-ml.readthedocs.io/en/latest/) is an end-to-end library for deep learning that focuses on clear code and speed.\n","\n","  1. **[Run a pre-trained Transformer](#1)**: create a translator in a few lines of code\n","  1. **[Walkthrough](#2)**: how Trax works, how to make new models and train on your own data\n"]},{"cell_type":"code","metadata":{"id":"q9Q2zWTIzV7z","executionInfo":{"status":"ok","timestamp":1611361788741,"user_tz":480,"elapsed":3675,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["#@title Install dependencies\n","#@markdown - Trax\n","%%capture\n","!pip install -Uqq trax"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bel6sAVg2Kuo","executionInfo":{"status":"ok","timestamp":1611361813517,"user_tz":480,"elapsed":28441,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"aabf68b8-ec06-4e44-bd12-5db358649754"},"source":["#@title Import packages\n","import os\n","\n","import numpy as np\n","import trax\n","\n","from trax import layers as tl\n","\n","print(\"numpy\", np.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["numpy 1.19.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w-KemeiA1c1p"},"source":["<a name='1'></a>\n","## Run a pre-trained Transformer\n","\n","\n","Here is how you create an Engligh-German translator in a few lines of code:\n","\n","* create a Transformer model in Trax with [trax.models.Transformer](https://trax-ml.readthedocs.io/en/latest/trax.models.html#trax.models.transformer.Transformer)\n","* initialize it from a file with pre-trained weights with [model.init_from_file](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Layer.init_from_file)\n","* tokenize your input sentence to input into the model with [trax.data.tokenize](https://trax-ml.readthedocs.io/en/latest/trax.data.html#trax.data.tf_inputs.tokenize)\n","* decode from the Transformer with [trax.supervised.decoding.autoregressive_sample](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.decoding.autoregressive_sample)\n","* de-tokenize the decoded result to get the translation with [trax.data.detokenize](https://trax-ml.readthedocs.io/en/latest/trax.data.html#trax.data.tf_inputs.detokenize)"]},{"cell_type":"code","metadata":{"id":"CMObhWjw2gCk","executionInfo":{"status":"ok","timestamp":1611361845344,"user_tz":480,"elapsed":60260,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["# create a transformer model\n","model = trax.models.Transformer(\n","    input_vocab_size=33300,\n","    d_model=512,\n","    d_ff=2048,\n","    n_heads=8,\n","    n_encoder_layers=6,\n","    max_len=2048,\n","    mode=\"predict\",\n",")\n","\n","# initialize using pre-trained weights\n","model.init_from_file(\n","    \"gs://trax-ml/models/translation/ende_wmt32k.pkl.gz\", \n","    weights_only=True\n",")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNKC16CM21JF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611361862721,"user_tz":480,"elapsed":77630,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"af574e12-11e1-4b00-f7d6-70314b51d7ce"},"source":["%%time\n","# tokenize a sentence\n","sentence = \"It is nice to learn new things today!\"\n","tokenized = list(\n","    trax.data.tokenize(\n","        iter([sentence]),\n","        vocab_dir=\"gs://trax-ml/vocabs/\",\n","        vocab_file=\"ende_32k.subword\",\n","    )\n",")[0]\n","\n","# decode from the transformer\n","tokenized = tokenized[None, :]\n","tokenized_translation = trax.supervised.decoding.autoregressive_sample(\n","    model, tokenized, temperature=0.0\n",")  # Higher temperature: more diverse results.\n","\n","# de-tokenize\n","tokenized_translation = tokenized_translation[0][:-1]  # remove batch and EOS\n","translation = trax.data.detokenize(\n","    tokenized_translation,\n","    vocab_dir=\"gs://trax-ml/vocabs/\",\n","    vocab_file=\"ende_32k.subword\",\n",")\n","print(translation)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Es ist schön, heute neue Dinge zu lernen!\n","CPU times: user 12.5 s, sys: 939 ms, total: 13.5 s\n","Wall time: 17.4 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kQEFBUT6A6YT"},"source":["Expected result:\n","\n","```\n","Es ist schön, heute neue Dinge zu lernen!\n","[GPU time] \n","1 loop, best of 3: 4.22 s per loop\n","CPU times: user 12.7 s, sys: 227 ms, total: 12.9 s\n","Wall time: 13.3 s\n","\n","[TPU time] \n","1 loop, best of 3: 13.8 s per loop ???\n","CPU times: user 49.5 s, sys: 234 ms, total: 49.7 s\n","Wall time: 49.7 s\n","\n","[CPU time] \n","1 loop, best of 3: 14.4 s per loop\n","CPU times: user 57.5 s, sys: 250 ms, total: 57.7 s\n","Wall time: 57.8 s\n","```"]},{"cell_type":"markdown","metadata":{"id":"-h49ifhZOGtd"},"source":["<a name='2'></a>\n","## Walkthrough"]},{"cell_type":"markdown","metadata":{"id":"rUHY8z01Ppqc"},"source":["### Tensors and Fast Math\n","\n","The basic units flowing through Trax models are *tensors* - multi-dimensional arrays, sometimes also known as numpy arrays, due to the most widely used package for tensor operations -- `numpy`.  Trax also uses the numpy API.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tABdyLCR-b9u","executionInfo":{"status":"ok","timestamp":1611361863477,"user_tz":480,"elapsed":78378,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"de4e70a2-a198-4f32-f8f2-4659ceac58b1"},"source":["from trax.fastmath import numpy as fastnp\n","trax.fastmath.use_backend(\"jax\")\n","\n","matrix = fastnp.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","print(f\"matrix =\\n{matrix}\")\n","vector = fastnp.ones(3)\n","print(f\"vector = {vector}\")\n","product = fastnp.dot(vector, matrix)\n","print(f\"product = {product}\")\n","tanh = fastnp.tanh(product)\n","print(f\"tanh(product) = {tanh}\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["matrix =\n","[[1 2 3]\n"," [4 5 6]\n"," [7 8 9]]\n","vector = [1. 1. 1.]\n","product = [12. 15. 18.]\n","tanh(product) = [0.99999994 0.99999994 0.99999994]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TOFqy2xyRKAG"},"source":["Gradients can be calculated using trax.fastmath.grad."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTON1P5NQMjm","executionInfo":{"status":"ok","timestamp":1611361863853,"user_tz":480,"elapsed":78747,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"2be4938c-f9d9-42ef-e200-2ba21377eaff"},"source":["def f(x):\n","    return 2.0 * x * x\n","\n","grad_f = trax.fastmath.grad(f)\n","\n","print(f\"grad(2x^2) at  1 = {grad_f(1.0)}\")\n","print(f\"grad(2x^2) at -2 = {grad_f(-2.0)}\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["grad(2x^2) at  1 = 4.0\n","grad(2x^2) at -2 = -8.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aWCmFD1fSiHU"},"source":["## Layers\n","\n","Layers with trainable weights like `Embedding` need to be initialized with the signature (shape and dtype) of the input, and then can be run by calling them."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dAAb0slPRTyw","executionInfo":{"status":"ok","timestamp":1611361863854,"user_tz":480,"elapsed":78741,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"2585a9ce-819c-4ff9-a603-812482e31419"},"source":["x = np.arange(15)\n","print(f\"x = {x}\")\n","\n","embedding = tl.Embedding(vocab_size=20, d_feature=32)\n","embedding.init(trax.shapes.signature(x))\n","\n","y = embedding(x)\n","print(f\"shape of y= {y.shape}\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["x = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n","shape of y= (15, 32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0CB5tSOlT9dP"},"source":["### Models\n","\n","Models in Trax are built from layers most often using the `Serial` and `Branch` combinators. You can read more about those combinators in the [layers intro](https://trax-ml.readthedocs.io/en/latest/notebooks/layers_intro.html) and\n","see the code for many models in `trax/models/`, e.g., this is how the [Transformer Language Model](https://github.com/google/trax/blob/master/trax/models/transformer.py#L167) is implemented. Below is an example of how to build a sentiment classification model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvHCxLlwTr__","executionInfo":{"status":"ok","timestamp":1611361863855,"user_tz":480,"elapsed":78734,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"642112c3-4d9d-4dc6-a5ea-b9c3930ff906"},"source":["model = tl.Serial(\n","    tl.Embedding(vocab_size=8192, d_feature=256),\n","    tl.Mean(axis=1),\n","    tl.Dense(2),\n",")\n","\n","print(model)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Serial[\n","  Embedding_8192_256\n","  Mean\n","  Dense_2\n","]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"atPI77rJU5pz"},"source":["### Data\n","\n","To train your model, you need data. In Trax, data streams are represented as python iterators, so you can call `next(data_stream)` and get a tuple, e.g., `(inputs, targets)`. Trax allows you to use [TensorFlow Datasets](https://www.tensorflow.org/datasets) easily and you can also get an iterator from your own text file using the standard `open('my_file.txt')`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQBipu-1UtQK","executionInfo":{"status":"ok","timestamp":1611361863856,"user_tz":480,"elapsed":78727,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"84812a4a-3156-42de-bc4b-136bc76ae2f4"},"source":["train_stream = trax.data.TFDS(\n","    \"imdb_reviews\", keys=(\"text\", \"label\"), train=True\n",")()\n","eval_stream = trax.data.TFDS(\n","    \"imdb_reviews\", keys=(\"text\", \"label\"), train=False\n",")()\n","print(next(train_stream))\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", 0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WixOVxIrXsV6"},"source":["Using the `trax.data` module you can create input processing pipelines, e.g., to tokenize and shuffle your data. You create data pipelines using `trax.data.Serial` and they are functions that you apply to streams to create processed streams."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Riup8uKBXDpE","executionInfo":{"status":"ok","timestamp":1611361865528,"user_tz":480,"elapsed":80390,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"c72a0a58-8316-497b-80b9-d7bedce8cbb5"},"source":["data_pipeline = trax.data.Serial(\n","    trax.data.Tokenize(vocab_file=\"en_8k.subword\", keys=[0]),\n","    trax.data.Shuffle(),\n","    trax.data.FilterByLength(max_length=2048, length_keys=[0]),\n","    trax.data.BucketByLength(\n","        boundaries=[32, 128, 512, 2048],\n","        batch_sizes=[512, 128, 32, 8, 1],\n","        length_keys=[0],\n","    ),\n","    trax.data.AddLossWeights(),\n",")\n","train_batches_stream = data_pipeline(train_stream)\n","eval_batches_stream = data_pipeline(eval_stream)\n","example_batch = next(train_batches_stream)\n","print(f\"shapes = {[x.shape for x in example_batch]}\")\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["shapes = [(8, 2048), (8,), (8,)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HHiWgRQLbcjA"},"source":["### Supervised training\n","\n","When you have the model and the data, use `trax.supervised.training` to define training and eval tasks and create a training loop. The Trax training loop optimizes training and will create TensorBoard logs and model checkpoints for you."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjenbPq1Xgue","executionInfo":{"status":"ok","timestamp":1611363291032,"user_tz":480,"elapsed":62440,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"4545fc32-a8c4-4c8d-e55d-d3b3a8c979b3"},"source":["from trax.supervised import training\n","\n","train_task = training.TrainTask(\n","    labeled_data=train_batches_stream,\n","    loss_layer=tl.WeightedCategoryCrossEntropy(),\n","    optimizer=trax.optimizers.Adam(0.01),\n","    n_steps_per_checkpoint=500,\n",")\n","\n","eval_task = training.EvalTask(\n","    labeled_data=eval_batches_stream,\n","    metrics=[tl.WeightedCategoryCrossEntropy(), tl.WeightedCategoryAccuracy()],\n","    n_eval_batches=20\n",")\n","\n","output_dir = os.path.expanduser(\"~/output_dir/\")\n","!rm -rf {output_dir}\n","training_loop = training.Loop(\n","    model,\n","    train_task,\n","    eval_tasks=[eval_task],\n","    output_dir=output_dir\n",")\n","\n","training_loop.run(2000)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\n","Step      1: Total number of trainable weights: 2097666\n","Step      1: Ran 1 train steps in 1.60 secs\n","Step      1: train WeightedCategoryCrossEntropy |  0.69452739\n","Step      1: eval  WeightedCategoryCrossEntropy |  0.70902301\n","Step      1: eval      WeightedCategoryAccuracy |  0.47500000\n","\n","Step    500: Ran 499 train steps in 15.23 secs\n","Step    500: train WeightedCategoryCrossEntropy |  0.50166368\n","Step    500: eval  WeightedCategoryCrossEntropy |  0.42592406\n","Step    500: eval      WeightedCategoryAccuracy |  0.80000000\n","\n","Step   1000: Ran 500 train steps in 13.28 secs\n","Step   1000: train WeightedCategoryCrossEntropy |  0.37094992\n","Step   1000: eval  WeightedCategoryCrossEntropy |  0.33120547\n","Step   1000: eval      WeightedCategoryAccuracy |  0.84375000\n","\n","Step   1500: Ran 500 train steps in 13.04 secs\n","Step   1500: train WeightedCategoryCrossEntropy |  0.34561551\n","Step   1500: eval  WeightedCategoryCrossEntropy |  0.48605159\n","Step   1500: eval      WeightedCategoryAccuracy |  0.78437500\n","\n","Step   2000: Ran 500 train steps in 12.08 secs\n","Step   2000: train WeightedCategoryCrossEntropy |  0.28374630\n","Step   2000: eval  WeightedCategoryCrossEntropy |  0.41163191\n","Step   2000: eval      WeightedCategoryAccuracy |  0.85351562\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CQGSpKtTvQJw"},"source":["After training the model, run it like any layer to get results."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aV6FUjzMa32S","executionInfo":{"status":"ok","timestamp":1611364072553,"user_tz":480,"elapsed":1049,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"f5b4246e-0a4c-42df-f898-750e1fe8f160"},"source":["example_input = next(eval_batches_stream)[0][0]\n","example_input_str = trax.data.detokenize(\n","    example_input, vocab_file=\"en_8k.subword\"\n",")\n","print(f\"sample review: {example_input_str}\")\n","sentiment_log_probs = model(example_input[None, :])\n","print(f\"probabilities: {np.exp(sentiment_log_probs)}\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["sample review: I was a schoolboy when I watched this film for the first time. The next day I knew that all pupils of our form watched it and all were fascinated by the film as I was. I think the same situation was in all forms of our school and in the whole Soviet Union. Later I watched it every time it was shown on TV and want to watch more. I think that comparison with \"Back to the Future\" or other Sci-Fi films is not appropriate. \"Gost'ya iz budushchego\" is unique in many ways, once you have watched it, you never forget it.<br /><br />This film is full of belief in peaceful science achievements, full of belief in the beautiful future of our world. It's not only the film, but also a forecast of many scientific inventions and achievements. The time shown in the film is the year 1984 (the year of its creation) and the year 2084 (where a schoolboy Kolya Gerasimov has traveled for some time and where his friend Alisa Seleznyova was from). The year now is 2005, many inventions and achievements predicted in the film are not realized yet. Such as \"Mielophone\" (a device, which can read thoughts of any animal and human), expeditions to Venus and Mars (as easy as going for a picnic in the weekend), creating and launching of the satellites as a homework for pupils, easy to drive flying machines (which completely replaced automobiles), biorobots, \"historical identification\" of any kind of material or creature performed in a couple of minutes, and many others. Meanwhile, some of them nowadays became much more realistic than they seemed in 1984! Just wait for 2084 :-)<br /><br />The film also depicts typical Russian schoolboys and schoolgirls (and does it so naturally!). With their inventiveness, curiosity, humour, dreaminess. Look for example at Fima Korolyov, you could find such character in nearly all forms of every school of the Soviet Union, similar character was in my form too! Alisa Seleznyova... I myself, as well as many my classmates fell in love at first sight with her! By the way, later an actress who played Alisa became a scientist - I think she was as much influenced by the film as people who watched it on TV.<br /><br />Beautiful idea, beautiful realization, beautiful actors, beautiful music, beautiful song \"Prekrasnoye Daleko\" (\"The Wonderful Far-Away\")... Beautiful, beautiful, beautiful...<br /><br />The last thing I want to say is that different remakes and \"new versions\" of the song from the film and even the film itself were made later and spread on TV and in the Internet. All they are not even comparable with the original. I should not even comment them, my comment is only about the original. So, request the original and enjoy it!<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","probabilities: [[0.17556243 5.566917  ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XONGgxuayCnL","executionInfo":{"status":"ok","timestamp":1611364650510,"user_tz":480,"elapsed":1389,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"1357b5da-4550-49e6-9204-e098ef263f49"},"source":["example_input_str = \"It is a moving film, I got touched for the story.\"\n","example_input_tokenized = list(\n","    trax.data.tokenize(\n","        iter([example_input_str]),\n","        vocab_dir=\"gs://trax-ml/vocabs/\",\n","        vocab_file=\"ende_32k.subword\",\n","    )\n",")[0]\n","print(f\"sample review: {example_input_str}\")\n","sentiment_log_probs = model(example_input_tokenized[None, :])\n","print(f\"probabilities: {np.exp(sentiment_log_probs)}\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["sample review: It is a moving film, I got touched for the story.\n","probabilities: [[17.71551     0.05883902]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_EvnqugRyu6r","executionInfo":{"status":"ok","timestamp":1611364698490,"user_tz":480,"elapsed":1413,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"01b7b52e-f7a5-478e-ce39-a9dbcd7cb3a9"},"source":["example_input_str = \"Completely dissapointing. I felt sleep. Simply awful.\"\n","example_input_tokenized = list(\n","    trax.data.tokenize(\n","        iter([example_input_str]),\n","        vocab_dir=\"gs://trax-ml/vocabs/\",\n","        vocab_file=\"ende_32k.subword\",\n","    )\n",")[0]\n","print(f\"sample review: {example_input_str}\")\n","sentiment_log_probs = model(example_input_tokenized[None, :])\n","print(f\"probabilities: {np.exp(sentiment_log_probs)}\")"],"execution_count":27,"outputs":[{"output_type":"stream","text":["sample review: Completely dissapointing. I felt sleep. Simply awful.\n","probabilities: [[1.9859998 0.520353 ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xAEZqAMEz6nC"},"source":[""],"execution_count":null,"outputs":[]}]}