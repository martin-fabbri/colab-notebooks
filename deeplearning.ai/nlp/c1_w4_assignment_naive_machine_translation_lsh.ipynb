{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c1-w4-assignment-naive-machine-translation-lsh.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNiEJQfT1QoLqjij3k10vpJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/nlp/c1_w4_assignment_naive_machine_translation_lsh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAmbNfhsYO0e"
      },
      "source": [
        "# Assignment 4 - Naive Machine Translation and LSH\n",
        "\n",
        "You will now implement your first machine translation system and then you\n",
        "will see how locality sensitive hashing works. Let's get started by importing\n",
        "the required functions!\n",
        "\n",
        "If you are running this notebook in your local computer, don't forget to\n",
        "download the twitter samples and stopwords from nltk.\n",
        "\n",
        "```\n",
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkjMjgsaYOtT"
      },
      "source": [
        "### This assignment covers the folowing topics:\n",
        "\n",
        "- [1. The word embeddings data for English and French words](#1)\n",
        "  - [1.1 Generate embedding and transform matrices](#1-1)\n",
        "      - [Exercise 1](#ex-01)\n",
        "- [2. Translations](#2)\n",
        "  - [2.1 Translation as linear transformation of embeddings](#2-1)\n",
        "      - [Exercise 2](#ex-02)  \n",
        "      - [Exercise 3](#ex-03)  \n",
        "      - [Exercise 4](#ex-04)        \n",
        "  - [2.2 Testing the translation](#2-2)\n",
        "      - [Exercise 5](#ex-05)\n",
        "      - [Exercise 6](#ex-06)      \n",
        "- [3. LSH and document search](#3)\n",
        "  - [3.1 Getting the document embeddings](#3-1)\n",
        "      - [Exercise 7](#ex-07)\n",
        "      - [Exercise 8](#ex-08)      \n",
        "  - [3.2 Looking up the tweets](#3-2)\n",
        "  - [3.3 Finding the most similar tweets with LSH](#3-3)\n",
        "  - [3.4 Getting the hash number for a vector](#3-4)\n",
        "      - [Exercise 9](#ex-09)  \n",
        "  - [3.5 Creating a hash table](#3-5)\n",
        "      - [Exercise 10](#ex-10)  \n",
        "  - [3.6 Creating all hash tables](#3-6)\n",
        "      - [Exercise 11](#ex-11) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ0jAE2vVw1Z"
      },
      "source": [
        "import pdb\n",
        "import pickle\n",
        "import string\n",
        "import re\n",
        "import time\n",
        "import nltk\n",
        "import gensim\n",
        "import scipy\n",
        "import sklearn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import twitter_samples\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzEvWgmSZB3y",
        "outputId": "ed1e9a01-6e4f-475f-8a33-1b0d3ebe1944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l_3mA5lZPIB"
      },
      "source": [
        "def process_tweet(tweet):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "\n",
        "    '''\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "            word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean\n",
        "\n",
        "\n",
        "def get_dict(file_name):\n",
        "    \"\"\"\n",
        "    This function returns the english to french dictionary given a file where the each column corresponds to a word.\n",
        "    Check out the files this function takes in your workspace.\n",
        "    \"\"\"\n",
        "    my_file = pd.read_csv(file_name, delimiter=' ')\n",
        "    etof = {}  # the english to french dictionary to be returned\n",
        "    for i in range(len(my_file)):\n",
        "        # indexing into the rows.\n",
        "        en = my_file.loc[i][0]\n",
        "        fr = my_file.loc[i][1]\n",
        "        etof[en] = fr\n",
        "\n",
        "    return etof\n",
        "\n",
        "\n",
        "def cosine_similarity(A, B):\n",
        "    '''\n",
        "    Input:\n",
        "        A: a numpy array which corresponds to a word vector\n",
        "        B: A numpy array which corresponds to a word vector\n",
        "    Output:\n",
        "        cos: numerical number representing the cosine similarity between A and B.\n",
        "    '''\n",
        "    # you have to set this variable to the true label.\n",
        "    cos = -10\n",
        "    dot = np.dot(A, B)\n",
        "    norma = np.linalg.norm(A)\n",
        "    normb = np.linalg.norm(B)\n",
        "    cos = dot / (norma * normb)\n",
        "\n",
        "    return cos"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdVvY0TWZyLa"
      },
      "source": [
        "<a name=\"1\"></a>\n",
        "\n",
        "# 1. The word embeddings data for English and French words\n",
        "\n",
        "Write a program that translates English to French.\n",
        "\n",
        "## The data\n",
        "\n",
        "The full dataset for English embeddings is about 3.64 gigabytes, and the French\n",
        "embeddings are about 629 megabytes. To prevent the Coursera workspace from\n",
        "crashing, we've extracted a subset of the embeddings for the words that you'll\n",
        "use in this assignment.\n",
        "\n",
        "If you want to run this on your local computer and use the full dataset,\n",
        "you can download the\n",
        "* English embeddings from Google code archive word2vec\n",
        "[look for GoogleNews-vectors-negative300.bin.gz](https://code.google.com/archive/p/word2vec/)\n",
        "    * You'll need to unzip the file first.\n",
        "* and the French embeddings from\n",
        "[cross_lingual_text_classification](https://github.com/vjstark/crosslingual_text_classification).\n",
        "    * in the terminal, type (in one line)\n",
        "    `curl -o ./wiki.multi.fr.vec https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.fr.vec`\n",
        "\n",
        "Then copy-paste the code below and run it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BbiHl89aoJp"
      },
      "source": [
        "```python\n",
        "# Use this code to download and process the full dataset on your local computer\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "en_embeddings = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary = True)\n",
        "fr_embeddings = KeyedVectors.load_word2vec_format('./wiki.multi.fr.vec')\n",
        "\n",
        "\n",
        "# loading the english to french dictionaries\n",
        "en_fr_train = get_dict('en-fr.train.txt')\n",
        "print('The length of the english to french training dictionary is', len(en_fr_train))\n",
        "en_fr_test = get_dict('en-fr.test.txt')\n",
        "print('The length of the english to french test dictionary is', len(en_fr_train))\n",
        "\n",
        "english_set = set(en_embeddings.vocab)\n",
        "french_set = set(fr_embeddings.vocab)\n",
        "en_embeddings_subset = {}\n",
        "fr_embeddings_subset = {}\n",
        "french_words = set(en_fr_train.values())\n",
        "\n",
        "for en_word in en_fr_train.keys():\n",
        "    fr_word = en_fr_train[en_word]\n",
        "    if fr_word in french_set and en_word in english_set:\n",
        "        en_embeddings_subset[en_word] = en_embeddings[en_word]\n",
        "        fr_embeddings_subset[fr_word] = fr_embeddings[fr_word]\n",
        "\n",
        "\n",
        "for en_word in en_fr_test.keys():\n",
        "    fr_word = en_fr_test[en_word]\n",
        "    if fr_word in french_set and en_word in english_set:\n",
        "        en_embeddings_subset[en_word] = en_embeddings[en_word]\n",
        "        fr_embeddings_subset[fr_word] = fr_embeddings[fr_word]\n",
        "\n",
        "\n",
        "pickle.dump( en_embeddings_subset, open( \"en_embeddings.p\", \"wb\" ) )\n",
        "pickle.dump( fr_embeddings_subset, open( \"fr_embeddings.p\", \"wb\" ) )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO6Xcu5Wc1R1"
      },
      "source": [
        "#### The subset of data\n",
        "\n",
        "To do the assignment on the Coursera workspace, we'll use the subset of word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm63Btt6dAEJ",
        "outputId": "9cc3df3e-025d-48d7-f8f3-01b2613e6bca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://github.com/martin-fabbri/colab-notebooks/raw/master/data/nlp/en_embeddings.p \n",
        "!wget https://github.com/martin-fabbri/colab-notebooks/raw/master/data/nlp/fr_embeddings.p\n",
        "!wget https://raw.githubusercontent.com/martin-fabbri/colab-notebooks/master/data/nlp/en-fr.train.txt\n",
        "!wget https://raw.githubusercontent.com/martin-fabbri/colab-notebooks/master/data/nlp/en-fr.test.txt"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-05 20:00:59--  https://github.com/martin-fabbri/colab-notebooks/raw/master/data/nlp/en_embeddings.p\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/martin-fabbri/colab-notebooks/master/data/nlp/en_embeddings.p [following]\n",
            "--2020-11-05 20:01:01--  https://raw.githubusercontent.com/martin-fabbri/colab-notebooks/master/data/nlp/en_embeddings.p\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8119809 (7.7M) [application/octet-stream]\n",
            "Saving to: ‘en_embeddings.p.3’\n",
            "\n",
            "en_embeddings.p.3   100%[===================>]   7.74M  41.7MB/s    in 0.2s    \n",
            "\n",
            "2020-11-05 20:01:01 (41.7 MB/s) - ‘en_embeddings.p.3’ saved [8119809/8119809]\n",
            "\n",
            "--2020-11-05 20:01:01--  https://github.com/martin-fabbri/colab-notebooks/raw/master/data/nlp/fr_embeddings.p\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/martin-fabbri/colab-notebooks/master/data/nlp/fr_embeddings.p [following]\n",
            "--2020-11-05 20:01:02--  https://raw.githubusercontent.com/martin-fabbri/colab-notebooks/master/data/nlp/fr_embeddings.p\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7355253 (7.0M) [application/octet-stream]\n",
            "Saving to: ‘fr_embeddings.p.3’\n",
            "\n",
            "fr_embeddings.p.3   100%[===================>]   7.01M  25.8MB/s    in 0.3s    \n",
            "\n",
            "2020-11-05 20:01:03 (25.8 MB/s) - ‘fr_embeddings.p.3’ saved [7355253/7355253]\n",
            "\n",
            "--2020-11-05 20:01:03--  https://raw.githubusercontent.com/martin-fabbri/colab-notebooks/master/data/nlp/en-fr.train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 178608 (174K) [text/plain]\n",
            "Saving to: ‘en-fr.train.txt.2’\n",
            "\n",
            "en-fr.train.txt.2   100%[===================>] 174.42K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-11-05 20:01:03 (6.76 MB/s) - ‘en-fr.train.txt.2’ saved [178608/178608]\n",
            "\n",
            "--2020-11-05 20:01:03--  https://raw.githubusercontent.com/martin-fabbri/colab-notebooks/master/data/nlp/en-fr.test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50509 (49K) [text/plain]\n",
            "Saving to: ‘en-fr.test.txt.2’\n",
            "\n",
            "en-fr.test.txt.2    100%[===================>]  49.33K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-11-05 20:01:03 (3.17 MB/s) - ‘en-fr.test.txt.2’ saved [50509/50509]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPcUCgcbZPNW"
      },
      "source": [
        "en_embeddings_subset = pickle.load(open('en_embeddings.p', 'rb'))\n",
        "fr_embeddings_subset = pickle.load(open('fr_embeddings.p', 'rb'))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaL8fBS6eCWv"
      },
      "source": [
        "#### Look at the data\n",
        "\n",
        "* en_embeddings_subset: the key is an English word, and the vaule is a\n",
        "300 dimensional array, which is the embedding for that word.\n",
        "```\n",
        "'the': array([ 0.08007812,  0.10498047,  0.04980469,  0.0534668 , -0.06738281, ....\n",
        "```\n",
        "\n",
        "* fr_embeddings_subset: the key is an French word, and the vaule is a 300\n",
        "dimensional array, which is the embedding for that word.\n",
        "```\n",
        "'la': array([-6.18250e-03, -9.43867e-04, -8.82648e-03,  3.24623e-02,...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhnjc-GLZPU0",
        "outputId": "89a50c92-69b0-4568-ea56-e8702ee415a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(en_embeddings_subset)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDNnMDZLZPas",
        "outputId": "a91c44be-17d6-4e54-dbcd-983618823e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(en_embeddings_subset)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6370"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNdUemYiZPX4",
        "outputId": "81c0f23d-1205-4ce3-d70a-5f79af203507",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(en_embeddings_subset['the'])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnddbZ1UgNAx"
      },
      "source": [
        "#### Load two dictionaries mapping the English to French words\n",
        "* A training dictionary\n",
        "* and a testing dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb7hIkSkZPRl",
        "outputId": "ad52f290-a9a6-45fc-8432-c85e328986d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# loading the english to french dictionaries\n",
        "en_fr_train = get_dict('en-fr.train.txt')\n",
        "print('The length of the English to French training dictionary is', len(en_fr_train))\n",
        "en_fr_test = get_dict('en-fr.test.txt')\n",
        "print('The length of the English to French test dictionary is', len(en_fr_train))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the English to French training dictionary is 5000\n",
            "The length of the English to French test dictionary is 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwirvY4DhdCf"
      },
      "source": [
        "#### Looking at the English French dictionary\n",
        "\n",
        "* `en_fr_train` is a dictionary where the key is the English word and the value\n",
        "is the French translation of that English word.\n",
        "```\n",
        "{'the': 'la',\n",
        " 'and': 'et',\n",
        " 'was': 'était',\n",
        " 'for': 'pour',\n",
        "```\n",
        "\n",
        "* `en_fr_test` is similar to `en_fr_train`, but is a test set.  We won't look at it\n",
        "until we get to testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrInXZXaZPKz",
        "outputId": "41d9f631-9429-40e5-91af-b9a70686642a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "en_fr_train['the']"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'la'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6d14JkiZO8S",
        "outputId": "7afd6023-9c54-429b-d82b-03ad4135ca93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "en_fr_train['people']"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'personnes'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcwwPDYahoGR"
      },
      "source": [
        "<a name=\"1-1\"></a>\n",
        "\n",
        "## 1.1 Generate embedding and transform matrices\n",
        "\n",
        "<a name=\"ex-01\"></a>\n",
        "#### Exercise 01: Translating English dictionary to French by using embeddings\n",
        "\n",
        "You will now implement a function `get_matrices`, which takes the loaded data\n",
        "and returns matrices `X` and `Y`.\n",
        "\n",
        "Inputs:\n",
        "- `en_fr` : English to French dictionary\n",
        "- `en_embeddings` : English to embeddings dictionary\n",
        "- `fr_embeddings` : French to embeddings dictionary\n",
        "\n",
        "Returns:\n",
        "- Matrix `X` and matrix `Y`, where each row in X is the word embedding for an\n",
        "english word, and the same row in Y is the word embedding for the French\n",
        "version of that English word.\n",
        "\n",
        "<div style=\"width:image width px; font-size:100%; text-align:center;\">\n",
        "<img src='https://github.com/martin-fabbri/colab-notebooks/raw/master/deeplearning.ai/nlp/images/X_to_Y.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:800px;height:200px;\" /> Figure 2 </div>\n",
        "\n",
        "Use the `en_fr` dictionary to ensure that the ith row in the `X` matrix\n",
        "corresponds to the ith row in the `Y` matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slIZj8GFimuB"
      },
      "source": [
        "**Instructions**: Complete the function `get_matrices()`:\n",
        "* Iterate over English words in `en_fr` dictionary.\n",
        "* Check if the word have both English and French embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb4vGXili6yj"
      },
      "source": [
        "<details>\n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "    <p>\n",
        "        <ul>\n",
        "            <li><a href=\"https://realpython.com/python-sets/#set-size-and-membership\" >Sets</a> are useful data structures that can be used to check if an item is a member of a group.</li>\n",
        "            <li>You can get words which are embedded into the language by using <a href=\"https://www.w3schools.com/python/ref_dictionary_keys.asp\"> keys</a> method.</li>\n",
        "            <li>Keep vectors in `X` and `Y` sorted in list. You can use <a href=\"https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ma.vstack.html\"> np.vstack()</a> to merge them into the numpy matrix. </li>\n",
        "            <li><a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html\">numpy.vstack</a> stacks the items in a list as rows in a matrix.</li>\n",
        "        </ul>\n",
        "    </p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6XtsL34j2Vt",
        "outputId": "5157baf5-1832-42ce-f4c3-c4607bc06ee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = np.array([1, 2, 4])\n",
        "b = np.array([5, 6, 7])\n",
        "c = np.vstack((a, b))\n",
        "d = np.array([8, 9, 10])\n",
        "e = np.vstack((c, d))\n",
        "e"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  4],\n",
              "       [ 5,  6,  7],\n",
              "       [ 8,  9, 10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SasZk6pOpgtE",
        "outputId": "6efe8e24-0c05-4f69-9cd0-a1ff6c18d442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "l = list()\n",
        "l.append([1, 2, 4])\n",
        "l.append([5, 6, 7])\n",
        "l.append([8, 9, 10])\n",
        "e = np.vstack(l)\n",
        "e"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  4],\n",
              "       [ 5,  6,  7],\n",
              "       [ 8,  9, 10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7Ca57Muk7c9",
        "outputId": "15fd4faf-9d9f-4b42-989f-37dcea67d074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "e = {k for k in en_embeddings_subset.keys()}\n",
        "type(e)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qe6b0AvmQf4",
        "outputId": "b1c706b4-8286-495f-c33c-2145cf862f30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "f = {k for k in fr_embeddings_subset.keys()}\n",
        "type(f)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wutz8GQDmpey",
        "outputId": "7638a942-63ba-4c8a-90da-b1b3947edd69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "en_fr_train.values()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values(['la', 'et', 'était', 'pour', 'cela', 'avec', 'depuis', 'ce', 'tuc', 'son', 'pas', 'sont', 'parlez', 'lequel', 'egalement', 'étaient', 'mais', 'ont', 'one', 'nouveautés', 'premiers', 'page', 'you', 'eux', 'avais', 'article', 'who', 'all', 'leurs', 'là', 'fabriqué', 'son', 'personnes', 'peut', 'aprés', 'autres', 'devrais', 'deux', 'partition', 'her', 'peut', 'ferait', 'plus', 'elle', 'quand', 'heure', 'equipe', 'américains', 'telles', 'débat', 'liens', 'seule', 'quelques', 'vois', 'unies', 'ans', 'école', 'mondiale', 'universitaire', 'lors', 'out', 'état', 'états', 'nationales', 'wikipedia', 'année', 'most', 'villes', 'utilisée', 'puis', 'comté', 'externes', 'où', 'sera', 'quelle', 'effacer', 'ces', 'janvier', 'mars', 'août', 'juillet', 'être', 'film', 'lui', 'plusieurs', 'sud', 'septembre', 'aimez', 'entre', 'octobre', 'three', 'juin', 'bah', 'utilisez', 'war', 'under', 'eux', 'avril', 'born', 'decembre', 'lien', 'ultérieur', 'partie', 'novembre', 'joueurs', 'listes', 'svp', 'suivant', 'février', 'connu', 'seconde', 'noms', 'groupe', 'historique', 'séries', 'juste', 'nord', 'travailler', 'avant', 'puisque', 'saisons', 'both', 'élevé', 'via', 'district', 'maintenant', 'observations', 'parceque', 'football', 'musique', 'cependant', 'diff', 'century', 'ligue', 'modifications', 'débat', 'titre', 'articles', 'john', 'même', 'comprenant', 'pourraient', 'anglais', 'album', 'numéro', 'against', 'familles', 'usager', 'basé', 'domaine', 'devint', 'york', 'vie', 'britannique', 'internationale', 'jeu', 'club', 'vos', 'tôt', 'meilleurs', 'west', 'maison', 'société', 'général', 'gauche', 'trés', 'voici', 'don', 'vivre', 'journee', 'plusieurs', 'lieu', 'fête', 'université', 'résultat', 'conserver', 'appropriée', 'quatre', 'même', 'classe', 'gouvernements', 'comment', 'appelés', 'did', 'chacun', 'trouvés', 'centre', 'per', 'style', 'com', 'long', 'pays', 'revenir', 'way', 'www', 'modifier', 'fin', 'faire', 'publique', 'joué', 'gagnés', 'another', 'libéré', 'ajoutée', 'appui', 'jeux', 'ancienne', 'ceux', 'films', 'eglise', 'orient', 'line', 'majeur', 'adhérents', 'bonnes', 'beaucoup', 'image', 'spectacle', 'toujours', 'réfléchir', 'dessous', 'ville', 'dernières', 'système', 'droit', 'chanson', 'remarquables', 'section', 'célibataires', 'compris', 'alignement', 'accueil', 'femme', 'télé', 'semence', 'membre', 'objectifs', 'sources', 'réserver', 'gare', 'commander', 'vieille', 'information', 'définir', 'posséder', 'texte', 'bande', 'point', 'locaux', 'alentour', 'rivière', 'haut', 'principaux', 'langues', 'françaises', 'https', 'nommés', 'hors', 'notez', 'carrière', 'originaux', 'âges', 'service', 'établis', 'situé', 'disait', 'site', 'population', 'air', 'allemande', 'droit', 'militaires', 'grand', 'clubs', 'publié', 'président', 'parc', 'officiel', 'affaire', 'londres', 'fois', 'quoique', 'petite', 'troisièmement', 'différent', 'dû', 'obtenir', 'village', 'clos', 'artistique', 'lecteur', 'définitive', 'collectivité', 'tenu', 'encore', 'commencé', 'armée', 'récompense', 'sans', 'mort', 'construits', 'homme', 'grand', 'site', 'utilisant', 'suppression', 'blanc', 'cinq', 'centrale', 'chemin', 'enfant', 'libre', 'prit', 'angleterre', 'inclut', 'association', 'descendre', 'donnés', 'sources', 'californienne', 'homme', 'version', 'écrits', 'créés', 'médias', 'noirs', 'php', 'rapport', 'bâtiment', 'prends', 'circonscription', 'commenter', 'avoir', 'king', 'éditer', 'stadium', 'mort', 'vaisseau', 'recherche', 'enregistrer', 'archives', 'lieux', 'défaire', 'coupe', 'records', 'souvent', 'peu', 'reçue', 'latéral', 'pouvoir', 'éducation', 'savoir', 'catégories', 'eau', 'espèce', 'domaine', 'près', 'australie', 'video', 'besoin', 'île', 'formulaire', 'trouvez', 'desservis', 'jouez', 'projet', 'radio', 'oeuvres', 'proposés', 'chaque', 'développement', 'exemple', 'vivre', 'syndicat', 'indes', 'next', 'spéciale', 'cour', 'région', 'petite', 'courtes', 'william', 'province', 'western', 'fiston', 'france', 'conseil', 'autres', 'royaux', 'actuelle', 'rue', 'complet', 'rouge', 'too', 'département', 'san', 'aide', 'parmi', 'préservées', 'james', 'ouvrir', 'forcer', 'position', 'têtes', 'réalisateur', 'père', 'morceau', 'http', 'canada', 'never', 'australie', 'george', 'jpg', 'niveau', 'tard', 'été', 'société', 'déplacée', 'bureau', 'période', 'championnat', 'ronds', 'récit', 'chansons', 'diverses', 'fichier', 'journées', 'terres', 'entreprises', 'raison', 'amérique', 'millions', 'européen', 'terme', 'six', 'publication', 'why', 'produites', 'sujet', 'jeune', 'totaux', 'david', 'sciences', 'liés', 'rock', 'archivés', 'ferroviaire', 'devenir', 'led', 'élèves', 'commencée', 'actualités', 'décrite', 'rôle', 'élections', 'albums', 'présenter', 'indien', 'royaume', 'livres', 'importants', 'nord', 'love', 'exécuter', 'canadien', 'presse', 'plutôt', 'tapez', 'act', 'editeur', 'vint', 'écoles', 'programme', 'once', 'social', 'allemagne', 'production', 'homme', 'pourrait', 'récompenses', 'points', 'semblable', 'professionnelles', 'dis', 'contexte', 'assez', 'plomb', 'soit', 'commun', 'chevauchements', 'données', 'couleurs', 'meilleur', 'personne', 'services', 'bgcolor', 'musée', 'combat', 'allé', 'sports', 'dejà', 'présentement', 'hall', 'édifices', 'historiques', 'date', 'supprimées', 'considérés', 'changement', 'lieu', 'semble', 'devez', 'yes', 'nos', 'méridionale', 'perdus', 'quelquechose', 'révision', 'together', 'thierry', 'moins', 'japonaises', 'groupes', 'contenus', 'impliquée', 'isbn', 'planche', 'japon', 'contrôle', 'politique', 'modernes', 'humain', 'demi', 'conception', 'evénement', 'événements', 'disponibles', 'faite', 'washington', 'vraie', 'début', 'personnels', 'action', 'espace', 'zones', 'étoiles', 'réellement', 'chine', 'possibles', 'paul', 'travailler', 'prise', 'loin', 'aller', 'ministre', 'lac', 'signalée', 'populaire', 'marié', 'fondée', 'europe', 'auteur', 'loin', 'indépendants', 'procédé', 'equipes', 'personnage', 'bas', 'michel', 'pages', 'léger', 'grand', 'vus', 'libèrent', 'voulez', 'episode', 'écrit', 'république', 'thomas', 'sociétés', 'via', 'russe', 'remerciements', 'mettre', 'race', 'travaillé', 'parcours', 'enregistré', 'someone', 'civiles', 'policier', 'charles', 'répertoriés', 'utilisateurs', 'modèle', 'oriental', 'corps', 'question', 'italiens', 'vedettes', 'semaines', 'éditeurs', 'texas', 'chef', 'proche', 'match', 'romains', 'venir', 'ouvert', 'tournée', 'mer', 'croisé', 'jouant', 'santé', 'institut', 'bouchons', 'forces', 'vertes', 'droits', 'preuves', 'initialement', 'avions', 'arts', 'portée', 'sûrement', 'consensus', 'barre', 'problématique', 'regardes', 'problèmes', 'anciens', 'moyenne', 'réseau', 'gagnant', 'spectacles', 'femme', 'retournée', 'soir', 'magasine', 'centre', 'rejoint', 'généralement', 'milieu', 'terminé', 'élus', 'significatifs', 'africaines', 'capable', 'google', 'scène', 'ajout', 'irlande', 'aujourdhui', 'academy', 'saint', 'self', 'soi', 'continué', 'stations', 'maman', 'semblait', 'afrique', 'culture', 'espagnols', 'grand', 'comité', 'choses', 'incendies', 'changée', 'gold', 'femme', 'cours', 'orienté', 'mois', 'chinoise', 'précédents', 'développé', 'tailles', 'mentionnés', 'ajoutez', 'fête', 'pierre', 'basketball', 'déplacer', 'rendement', 'standard', 'signifie', 'donnez', 'entraînement', 'artistes', 'mot', 'bleues', 'primaires', 'annoncée', 'valeur', 'chrétien', 'privés', 'catholiques', 'artistes', 'comprend', 'visualiser', 'ainsi', 'quasiment', 'baseball', 'sept', 'apparait', 'ever', 'fournissent', 'technologie', 'olympiques', 'avenir', 'formée', 'recensement', 'images', 'los', 'résultats', 'revenir', 'qualité', 'construction', 'zélande', 'devant', 'housse', 'maquette', 'malgré', 'lis', 'matériau', 'fort', 'entraîneur', 'henry', 'footballeurs', 'mark', 'rev', 'organisation', 'études', 'fédérales', 'richard', 'html', 'virginia', 'voiture', 'attaquer', 'conférence', 'exterieur', 'étude', 'frere', 'noms', 'scénariste', 'caractères', 'musical', 'rien', 'bordure', 'médical', 'pays', 'passés', 'écrire', 'rend', 'intérêt', 'fournis', 'tués', 'médailles', 'signés', 'étiquettes', 'équitables', 'recherchez', 'bay', 'référence', 'spécialement', 'supprimé', 'librairie', 'finalement', 'gestion', 'références', 'fonctionnalités', 'marine', 'guitares', 'colline', 'sûr', 'historiques', 'inférieure', 'fille', 'nommés', 'lire', 'pourtant', 'systèmes', 'débuts', 'mouvement', 'spécifique', 'toujours', 'acteur', 'naturelle', 'effacer', 'côte', 'let', 'got', 'chicago', 'championnats', 'pennsylvanie', 'ten', 'effectué', 'individuel', 'conçus', 'règle', 'etc', 'listes', 'paris', 'pensée', 'brune', 'hand', 'besoins', 'fiables', 'forgeron', 'généralement', 'base', 'parfois', 'floride', 'capital', 'vallée', 'banque', 'moulu', 'atteint', 'italie', 'energie', 'crois', 'leader', 'actifs', 'online', 'blocage', 'passerelle', 'familles', 'changements', 'suivies', 'industrie', 'collecte', 'demandez', 'bientot', 'olympiques', 'vendu', 'écrivains', 'professeure', 'studio', 'mexique', 'concours', 'campagne', 'org', 'théâtres', 'particulier', 'empire', 'longueurs', 'iles', 'chanteuse', 'créent', 'réorienter', 'additionnel', 'soviétiques', 'marché', 'mots', 'producteurs', 'notes', 'hockey', 'code', 'arbitre', 'quatrièmement', 'sport', 'van', 'myriam', 'aéroport', 'son', 'statut', 'irlandais', 'placé', 'enfant', 'idée', 'étrangères', 'municipalité', 'registre', 'eight', 'problèmes', 'autochtone', 'couverture', 'channel', 'parlement', 'pseudo', 'édition', 'mineur', 'dit', 'fondations', 'unités', 'film', 'glace', 'simplement', 'limités', 'unit', 'etudiant', 'précédemment', 'déclaré', 'gouverneur', 'complet', 'tester', 'désignés', 'facturer', 'parties', 'voix', 'théorie', 'régional', 'compte', 'voter', 'ordinateur', 'aucune', 'carolina', 'tournoi', 'pologne', 'derrière', 'galles', 'gagnant', 'lot', 'hôpitaux', 'mid', 'prenant', 'montagnes', 'supérieur', 'cas', 'angeles', 'édition', 'remplacés', 'alimentation', 'plusieurs', 'probablement', 'termes', 'monsieur', 'chose', 'carrées', 'essaye', 'sujet', 'femme', 'officier', 'catégories', 'grec', 'récente', 'envoyé', 'copyright', 'vitesse', 'gabarits', 'argent', 'scie', 'senior', 'sélectionné', 'introduites', 'politicien', 'véritable', 'requis', 'régulier', 'décernés', 'commerciale', 'villes', 'contient', 'échanges', 'degré', 'anti', 'naissance', 'soleil', 'terminé', 'rugby', 'terre', 'accéder', 'prieur', 'saisons', 'journal', 'début', 'logiciels', 'célèbres', 'religieuse', 'apparaissent', 'martin', 'dieu', 'bits', 'heures', 'courir', 'amenés', 'disparu', 'economique', 'structure', 'rural', 'restait', 'décision', 'certaines', 'frapper', 'minutes', 'espagne', 'joue', 'entier', 'joseph', 'seigneur', 'enchaînement', 'décidé', 'opérations', 'fonction', 'louis', 'assemblage', 'queen', 'sécurité', 'utilisations', 'ohio', 'possédés', 'yann', 'opération', 'appelle', 'réussie', 'légale', 'russie', 'prince', 'juive', 'personnel', 'établissements', 'but', 'vers', 'acceptez', 'mauvais', 'participation', 'peuplées', 'nature', 'autorisées', 'capitaine', 'monture', 'calculée', 'structures', 'dure', 'dicton', 'gérant', 'elections', 'rencontrer', 'boite', 'lignes', 'démocratiques', 'réussite', 'associées', 'célibataires', 'traditionnels', 'repose', 'autoroutes', 'particulièrement', 'vaste', 'mois', 'soin', 'administrateur', 'culturel', 'commission', 'plan', 'pratiques', 'commande', 'nomination', 'jersey', 'parties', 'michigan', 'quiconque', 'chevauchements', 'environ', 'maître', 'noté', 'usa', 'arrêtez', 'caractéristique', 'moteur', 'réaction', 'requis', 'illinois', 'afd', 'expérience', 'génie', 'argenté', 'séparer', 'prend', 'secrétaire', 'hollandais', 'lee', 'enregistrement', 'prime', 'regles', 'téléchargée', 'essayer', 'jeunes', 'ecosse', 'iii', 'maisons', 'coeur', 'chambres', 'pierres', 'montré', 'aubaine', 'dramatique', 'scores', 'mort', 'clés', 'abattu', 'tournez', 'occupation', 'écossais', 'exécutif', 'plante', 'promues', 'villages', 'langues', 'internet', 'congé', 'ressentir', 'couverts', 'fusion', 'surtout', 'nombreuses', 'ancienne', 'tentative', 'propriété', 'programmes', 'image', 'finalement', 'vaisseaux', 'fiction', 'regardant', 'secondaire', 'nations', 'majoritaires', 'édouard', 'annuel', 'digital', 'mission', 'vécu', 'revendiquer', 'seat', 'bbc', 'profils', 'danser', 'faire', 'georgie', 'port', 'pacifique', 'chateau', 'pass', 'transport', 'organisations', 'ratio', 'récemment', 'fall', 'mondiaux', 'époque', 'ailes', 'avis', 'commandant', 'fort', 'effet', 'ouverture', 'amende', 'objectif', 'hivers', 'genre', 'congrès', 'globalement', 'activités', 'rencontrés', 'revenus', 'massachusetts', 'vient', 'aîné', 'crête', 'manque', 'bass', 'super', 'complexes', 'académique', 'étoiles', 'comptes', 'aspect', 'asiatique', 'demandé', 'amis', 'aimable', 'financier', 'entrée', 'asiatique', 'sens', 'signifiant', 'actrice', 'carte', 'destiné', 'bishop', 'boston', 'tarif', 'littérature', 'foret', 'voix', 'jack', 'pré', 'justice', 'champion', 'doubles', 'polonais', 'nombres', 'columbia', 'tempe', 'vaincue', 'administration', 'revendications', 'jones', 'paroisse', 'israel', 'comédiens', 'sœur', 'nine', 'marqué', 'tableau', 'participé', 'pop', 'journal', 'amis', 'inconnues', 'lauréat', 'diagramme', 'initialement', 'pertes', 'sites', 'démarrage', 'architecture', 'relations', 'supérieur', 'supporté', 'pistes', 'contrat', 'face', 'directement', 'dépensés', 'fillette', 'clairement', 'junior', 'francisco', 'politique', 'présenté', 'mar', 'cause', 'volume', 'causées', 'tom', 'vol', 'candidat', 'allumettes', 'revendiqué', 'excepté', 'pétrole', 'assistante', 'surface', 'victoires', 'régiment', 'histoires', 'représentés', 'obtient', 'speedy', 'semaines', 'permettre', 'embranchement', 'retraité', 'collectivités', 'train', 'papiers', 'ajoutant', 'fournit', 'demeure', 'victoria', 'métalliques', 'erroné', 'directs', 'frank', 'miles', 'bloqués', 'lancés', 'messe', 'président', 'comique', 'relation', 'connaissance', 'format', 'creek', 'réunion', 'échoué', 'officiers', 'brouillon', 'goes', 'bagarre', 'figure', 'faculté', 'camps', 'couru', 'variété', 'propriétaire', 'statistique', 'soulevées', 'lourds', 'alexander', 'seule', 'comprends', 'épisodes', 'éducatif', 'quotidienne', 'williams', 'latines', 'completement', 'produits', 'sombre', 'attention', 'religieux', 'von', 'mind', 'opposer', 'corps', 'administratifs', 'coupe', 'scott', 'devenir', 'footballeur', 'jean', 'maires', 'pro', 'plages', 'descente', 'presque', 'quittant', 'hautement', 'plâtre', 'territoire', 'rédiger', 'bourgs', 'formulaires', 'joe', 'intérieur', 'voulait', 'solide', 'individuels', 'autorité', 'mentionner', 'projets', 'del', 'poursuivre', 'coûts', 'vice', 'conduire', 'avis', 'johnson', 'forcée', 'fondement', 'looks', 'raisons', 'photo', 'espérance', 'bûche', 'parents', 'entrés', 'mike', 'basic', 'scientifique', 'montant', 'ressort', 'oxford', 'kong', 'opéra', 'tenté', 'critiques', 'simples', 'fondatrice', 'hong', 'raconté', 'mari', 'utiles', 'techniques', 'nécessaire', 'croyait', 'opéré', 'montagne', 'importance', 'musiciens', 'hôtel', 'filles', 'équipages', 'février', 'boy', 'ontario', 'nation', 'défense', 'wiki', 'champions', 'doré', 'quartiers', 'foi', 'courses', 'essentiellement', 'automatique', 'vies', 'suédois', 'sexy', 'divertissement', 'tournés', 'filet', 'soccer', 'création', 'produits', 'tower', 'augmentée', 'voix', 'escadrons', 'contemporaine', 'concentrer', 'mariage', 'questions', 'navales', 'détail', 'forward', 'mémorial', 'paix', 'gardé', 'iran', 'coréenne', 'analyse', 'vainqueurs', 'pauvres', 'grade', 'criquet', 'juge', 'electrique', 'exister', 'corporation', 'tenez', 'campus', 'brésil', 'christophe', 'beyond', 'cinquième', 'accroissement', 'résumé', 'restants', 'déclaration', 'diffuser', 'obtenir', 'piano', 'romans', 'servir', 'heure', 'déménager', 'résolution', 'concept', 'alternatif', 'brothers', 'attentats', 'encyclopédie', 'républicains', 'représentants', 'politiciens', 'difficile', 'aptitude', 'étudiés', 'hôte', 'mur', 'aussitôt', 'urbains', 'pakistan', 'devient', 'marine', 'physiques', 'déc', 'troupes', 'interview', 'venir', 'semi', 'suggérer', 'empereurs', 'lettre', 'couple', 'duc', 'galeries', 'suivi', 'fenêtres', 'arbres', 'hits', 'jazz', 'protection', 'pertinents', 'comte', 'situation', 'critiques', 'contenant', 'classiques', 'offert', 'dame', 'hollande', 'reportages', 'influencer', 'adresse', 'linéaire', 'considérons', 'machine', 'domaine', 'eléments', 'minnesota', 'types', 'nov', 'servez', 'sydney', 'ministère', 'blood', 'distances', 'fond', 'donnant', 'garçons', 'potentiel', 'montréal', 'édité', 'infanterie', 'jun', 'autrefois', 'oct', 'conflit', 'travailleurs', 'steve', 'philadelphia', 'aidés', 'der', 'nationalités', 'dispute', 'scène', 'méthode', 'titres', 'berlin', 'conditions', 'armes', 'courses', 'découvertes', 'fer', 'étendue', 'eglises', 'sinon', 'positifs', 'santa', 'imperial', 'composé', 'ballon', 'largeurs', 'vite', 'correcte', 'responsables', 'possiblement', 'indiana', 'soldats', 'exemples', 'coréenne', 'genres', 'poisson', 'sénat', 'effets', 'revolver', 'vérifier', 'apparences', 'plans', 'renommée', 'signez', 'signaler', 'suède', 'consiste', 'patrimoine', 'balise', 'principalement', 'docteur', 'dirigeants', 'mensonges', 'inc', 'rivières', 'crime', 'libérales', 'stand', 'bob', 'existants', 'publication', 'industriel', 'reponse', 'scission', 'avr', 'sexe', 'mixte', 'agir', 'personnel', 'rail', 'meurs', 'premier', 'démarche', 'wisconsin', 'peine', 'racine', 'normes', 'bd', 'gagnées', 'mlle', 'spécialement', 'jument', 'réelle', 'cotisations', 'lieutenant', 'bois', 'végétaux', 'initiales', 'origines', 'environnement', 'jolies', 'classer', 'autobus', 'gaz', 'direction', 'guide', 'ressources', 'accepté', 'animaux', 'nor', 'activité', 'niveaux', 'lois', 'jim', 'créer', 'cambridge', 'compositrice', 'supprimez', 'agence', 'réserver', 'atlantique', 'suprêmes', 'poids', 'demande', 'bagarre', 'jackson', 'largement', 'rosé', 'traitement', 'liés', 'andré', 'procès', 'agrandi', 'daniel', 'certainement', 'infos', 'sciences', 'fame', 'tout', 'avenue', 'voyages', 'échelle', 'briser', 'oregon', 'produisent', 'capacités', '#efefef', 'fictif', 'échanger', 'actions', 'citée', 'généralement', 'accord', 'traductions', 'hommes', 'kansas', 'géré', 'apporter', 'charge', 'échoue', 'dévouée', 'proche', 'résidents', 'morceau', 'croissance', 'confiance', 'appliqué', 'fûts', 'délivré', 'meurtres', 'normal', 'vingt', 'évitez', 'tony', 'norvégienne', 'critères', 'contexte', 'proposé', 'révolution', 'totalement', 'guerres', 'aug', 'feuilles', 'avancée', 'distribution', 'médicament', 'jardin', 'atteindre', 'dinde', 'femelles', 'publications', 'incidence', 'ménages', 'sondage', 'hauteur', 'matinale', 'honorer', 'profonde', 'arguments', 'publication', 'arthur', 'élisabeth', 'homonymie', 'worth', 'colorado', 'médian', 'maryland', 'falls', 'zone', 'soliste', 'apprentissage', 'paie', 'résout', 'choix', 'drapeaux', 'ingénieur', 'voitures', 'fermes', 'wilson', 'principal', 'acquis', 'construits', 'secrète', 'poètes', 'construire', 'rester', 'orchestre', 'versions', 'suit', 'réparé', 'efforts', 'documentaires', 'equipement', 'ray', 'jaune', 'gardien', 'pressions', 'grant', 'prison', 'liberté', 'norvège', 'magasin', 'taylor', 'trimestre', 'désignées', 'indépendance', 'plateformes', 'rome', 'institutrice', 'copie', 'effort', 'nucléaire', 'photos', 'modèles', 'sep', 'aisément', 'remercier', 'description', 'convenu', 'institutions', 'housses', 'installations', 'cibler', 'stack', 'justification', 'stat', 'combinés', 'bronze', 'trier', 'hébergés', 'programmation', 'sri', 'ferroviaire', 'unique', 'défini', 'océan', 'cellule', 'missouri', 'concert', 'améliorer', 'biographiques', 'prêt', 'contacte', 'saint', 'tennessee', 'sub', 'securite', 'étienne', 'politiques', 'peintures', 'tarif', 'entièrement', 'mexicain', 'leadership', 'voler', 'message', 'municipaux', 'sérieuse', 'siège', 'officiellement', 'cimetière', 'mémoire', 'champs', 'générations', 'rejoindre', 'copie', 'finales', 'renards', 'continue', 'représentante', 'détruites', 'pieds', 'gars', 'philippins', 'révélée', 'organisées', 'sert', 'conservateurs', 'partagez', 'maria', 'maladies', 'sections', 'philosophie', 'façons', 'arrivé', 'divisés', 'plancher', 'logos', 'cancer', 'offre', 'impôt', 'attendu', 'circulation', 'préoccupations', 'diplômé', 'invités', 'juifs', 'signifiait', 'economie', 'storm', 'raconte', 'mile', 'protégé', 'bol', 'lettres', 'fournissant', 'commence', 'classiques', 'dommage', 'harry', 'offre', 'davis', 'défi', 'vues', 'marqués', 'permet', 'densité', 'littéraires', 'htm', 'ben', 'transport', 'kentucky', 'vente', 'flotte', 'soutenir', 'capturés', 'extra', 'reconnus', 'arizona', 'comparé', 'thème', 'françois', 'moscou', 'intéressé', 'entendus', 'comportement', 'transféré', 'environnemental', 'blanc', 'musicien', 'assigné', 'sièges', 'tennis', 'pourcentage', 'grumes', 'affiche', 'convention', 'anneau', 'joint', 'brian', 'adjointe', 'prévue', 'universités', 'yards', 'communiste', 'agent', 'différence', 'animal', 'tchèques', 'positions', 'exactement', 'rester', 'titré', 'combat', 'palace', 'ordonnée', 'opposition', 'tentatives', 'compréhensive', 'lutter', 'critiques', 'croissante', 'établir', 'mains', 'participé', 'poésie', 'materiaux', 'turcs', 'payés', 'promotion', 'apparement', 'bataillon', 'portable', 'additions', 'rangée', 'fusionné', 'metropolitan', 'chiffres', 'existence', 'œil', 'louisiane', 'lewis', 'melbourne', 'autriche', 'brigade', 'écran', 'risque', 'mené', 'lats', 'interdire', 'législatif', 'définitions', 'effectivement', 'dessiner', 'candidature', 'acier', 'présence', 'expansion', 'comte', 'maximum', 'sauvages', 'planification', 'comique', 'adoptés', 'facilité', 'plus', 'joyeuse', 'actes', 'classes', 'iowa', 'sauver', 'victoires', 'théâtre', 'existe', 'rôles', 'chance', 'prévenir', 'linecolor', 'candidats', 'objet', 'ressenti', 'powers', 'oiseaux', 'répandre', 'vaincre', 'cap', 'identifiés', 'régions', 'mien', 'côtés', 'jul', 'montrant', 'enseignement', 'directives', 'simon', 'profondeurs', 'lyrique', 'noel', 'refusé', 'grèce', 'expresse', 'fédération', 'journaliste', 'intelligence', 'connexion', 'affichés', 'portugais', 'déclarés', 'constitution', 'présidentiel', 'standing', 'sons', 'parcelle', 'dates', 'extrémités', 'pilotes', 'relativement', 'recevoir', 'éduqué', 'opposés', 'manchester', 'queensland', 'américains', 'introduction', 'directeurs', 'véhicule', 'stock', 'véhicules', 'israéliennes', 'fréquemment', 'collines', 'exécutant', 'northwest', 'médicament', 'visiter', 'portion', 'résidence', 'walter', 'pov', 'intéressants', 'moon', 'limiter', 'minute', 'bell', 'athlétisme', 'réduites', 'vents', 'oklahoma', 'architectes', 'idées', 'électronique', 'couronne', 'anderson', 'étape', 'armement', 'incapable', 'neutralité', 'connecté', 'suisse', 'expatriés', 'armé', 'hebdomadaires', 'cote', 'programme', 'brigade', 'multi', 'dynastie', 'froids', 'accordée', 'socorro', 'alliances', 'méthodes', 'sam', 'alabama', 'albert', 'tropicales', 'viêtnam', 'dvd', 'chauffer', 'adeptes', 'entourant', 'crédit', 'commons', 'canot', 'coffrets', 'ethniques', 'parlant', 'tomba', 'arène', 'chemins', 'noyau', 'chienne', 'tue', 'athlétisme', 'aîné', 'négatifs', 'confirmée', 'sixième', 'edge', 'jesus', 'outils', 'colonel', 'faibles', 'choisie', 'marque', 'résultant', 'nfl', 'rise', 'approvisionnement', 'traditions', 'élémentaires', 'ménage', 'spirit', 'tâche', 'légèrement', 'howard', 'incidents', 'développer', 'dimanche', 'discutez', 'statistiques', 'climat', 'thèmes', 'achetés', 'communications', 'chapitre', 'cassée', 'singapour', 'situé', 'licence', 'haven', 'décès', 'passant', 'citoyens', 'canons', 'arbres', 'gone', 'amélioré', 'visuelles', 'papes', 'officiels', 'sat', 'verres', 'meunier', 'publié', 'estimation', 'contenir', 'brésiliennes', 'sexuelle', 'défense', 'respectivement', 'concernant', 'riche', 'rapides', 'propriétés', 'appris', 'extensive', 'exposition', 'allocution', 'proposition', 'hétéro', 'interne', 'efficaces', 'solution', 'mode', 'pieds', 'oranges', 'argentine', 'brève', 'représentations', 'adultes', 'nouvellement', 'identité', 'chanteuses', 'inspirée', 'discuté', 'requièrent', 'facilité', 'transfert', 'egypte', 'cellules', 'patrick', 'quebec', 'connecticut', 'notation', 'antoine', 'permanents', 'phase', 'auditoire', 'mouvement', 'bleues', 'hongrois', 'arabes', 'trains', 'ensembles', 'classé', 'contrairement', 'commencer', 'réglage', 'yeux', 'studios', 'gmina', 'criminelle', 'commonwealth', 'termine', 'communication', 'portée', 'accusée', 'divisions', 'acceptez', 'avertissements', 'alan', 'objets', 'diego', 'concours', 'boxeur', 'trouvailles', 'coachs', 'battement', 'extrêmement', 'ford', 'suisse', 'pardon', 'houston', 'mondial', 'montré', 'cales', 'cathédrales', 'perdre', 'avance', 'réalités', 'diffusion', 'adam', 'vandalisme', 'ennemi', 'youtube', 'évalués', 'milliards', 'enterrée', 'belgique', 'respecte', 'rares', 'detroit', 'diplômé', 'collèges', 'explique', 'autorités', 'tuer', 'maximum', 'ni', 'adepte', 'notifier', 'peintre', 'hamilton', 'revenant', 'tentative', 'univers', 'passes', 'évidente', 'souffert', 'morceaux', 'appliquez', 'actrices', 'compétitions', 'aide', 'conducteur', 'folk', 'dan', 'khan', 'baby', 'danemark', 'tokyo', 'panneau', 'appelant', 'anne', 'danoise', 'veut', 'formules', 'intérieurs', 'kevin', 'intempéries', 'puissantes', 'musulman', 'inscrit', 'editeur', 'précédant', 'bruits', 'eric', 'agréé', 'atteint', 'douglas', 'provinciale', 'fonds', 'portugal', 'sportifs', 'bird', 'groupes', 'audio', 'cat', 'siècles', 'valides', 'chimiques', 'lane', 'holding', 'comtés', 'actualiser', 'ncaa', 'parle', 'trouver', 'domestique', 'ali', 'fausses', 'équivalent', 'capturés', 'christ', 'finissant', 'puerto', 'effectuer', 'partenaires', 'roumanie', 'aéronautique', 'défaillance', 'pupille', 'force', 'chevaliers', 'candidatures', 'hongrie', 'inquiétude', 'enregistrements', 'juan', 'fonctions', 'mississippi', 'appels', 'critiques', 'impliquant', 'magique', 'gordon', 'traité', 'antonio', 'sélection', 'arrières', 'coloniale', 'moteur', 'obtenu', 'circuit', 'souhaiter', 'recueil', 'harvard', 'islamique', 'déterminé', 'géographie', 'arkansas', 'carburant', 'artillerie', 'médiévaux', 'lieux', 'inclusion', 'reconnaissance', 'instant', 'motifs', 'réussi', 'historien', 'condition', 'physique', 'quotidiens', 'représentent', 'allen', 'regarde', 'kitt', 'protègent', 'grise', 'lancez', 'dave', 'philip', 'iraq', 'changer', 'ukraine', 'municipalités', 'mixage', 'tamouls', 'maj', 'partagé', 'autrichienne', 'porte', 'enquête', 'institution', 'princesses', 'piste', 'parcs', 'demandes', 'cent', 'prescriptions', 'parlant', 'kim', 'ltd', 'mètres', 'grise', 'sectoriel', 'doyenne', 'agricoles', 'incorporée', 'escape', 'ordres', 'coin', 'commandées', 'fondatrice', 'laminoir', 'mrs', 'sujets', 'températures', 'réglé', 'spacewatch', 'souviens', 'miami', 'promouvoir', 'valeurs', 'spot', 'avancement', 'apprends', 'planète', 'occupée', 'usage', 'refusée', 'borough', 'vérité', 'clark', 'suffisante', 'égale', 'administrateur', 'personnes', 'usine', 'combattu', 'dérivées', 'remarquable', 'magazines', 'écoulement', 'pairs', 'attaquée', 'générer', 'forme', 'créateur', 'nécessite', 'option', 'lincoln', 'commence', 'gradins', 'établissement', 'vendre', 'causes', 'budget', 'batailles', 'ciel', 'légende', 'arrêtée', 'forum', 'metro', 'cassée', 'frapper', 'blessures', 'ryan', 'zéro', 'converti', 'violence', 'sensiblement', 'déclarations', 'contrôlé', 'welsh', 'chuté', 'roger', 'pdf', 'distingué', 'samuel', 'traduit', 'papiers', 'détail', 'chapel', 'frederick', 'milliers', 'banques', 'offensant', 'kings', 'factor', 'renommer', 'remplace', 'musées', 'résistances', 'jonction', 'tim', 'moteurs', 'contribué', 'milieu', 'périphérique', 'bénéfices', 'rêve', 'saisissez', 'douze', 'universel', 'typique', 'compétences', 'acheté', 'voyageur', 'cleveland', 'financement', 'agriculture', 'parent', 'décennies', 'recevoir', 'signal', 'réformes', 'organisation', 'colonnes', 'défunt', 'utah', 'dirigeants', 'qualifié', 'indiquer', 'ukrainiens', 'homosexuel', 'amateur', 'évidemment', 'flore', 'gene', 'âme', 'alat', 'discussions', 'montreal', 'virages', 'rôdeur', 'entrée', 'sillon', 'nice', 'cordes', 'influencés', 'survenir', 'développer', 'abandonnée', 'humains', 'paires', 'plat', 'échantillons', 'contenaient', 'bannie', 'moore', 'fortement', 'visité', 'croissante', 'avocate', 'arm', 'mathématiques', 'canal', 'diagrammes', 'penser', 'dublin', 'suggère', 'patronyme', 'cervelle', 'pittsburgh', 'blogue', 'economie', 'seventh', 'alex', 'lourdement', 'auteurs', 'tableaux', 'concernés', 'récipiendaires', 'controversé', 'controverses', 'exprimés', 'josé', 'carrosseries', 'conservation', 'cartes', 'marie', 'arguments', 'chaine', 'concentrée', 'lecteurs', 'carl', 'infraction', 'bureaux', 'onde', 'cercle', 'invasions', 'jimmy', 'opportunité', 'détermine', 'colspan', 'orthodoxes', 'voté', 'formelle', 'décrit', 'seconds', 'cycle', 'doutez', 'golf', 'murs', 'productions', 'circonscription', 'étroitement', 'survient', 'enorme', 'andy', 'représentant', 'indonésie', 'vendre', 'lun', 'dessiné', 'diocèse', 'cuve', 'conseils', 'sénatrice', 'généré', 'malaisie', 'demandant', 'finlande', 'causant', 'prospects', 'avocate', 'seattle', 'gain', 'indice', 'saints', 'coureur', 'crise', 'ciné', 'mat', 'hollywood', 'réaction', 'médailles', 'documents', 'lecteur', 'lawrence', 'schéma', 'archives', 'atlanta', 'votants', 'examiné', 'bear', 'parfaite', 'restauré', 'bruce', 'baltimore', 'baron', 'casserole', 'commune', 'fantaisie', 'devoir', 'fauteuil', 'scènes', 'large', 'opposés', 'trucs', 'vieilli', 'rues', 'nick', 'anna', 'billy', 'vulgarisation', 'kent', 'parlementaire', 'kelly', 'tirer', 'prêts', 'pick', 'compositrice', 'conscients', 'jordan', 'dictionnaires', 'composition', 'sel', 'bangladesh', 'bot', 'prestation', 'terres', 'intérêts', 'programmé', 'enseignant', 'fermeture', 'publicités', 'cotisation', 'maine', 'retraite', 'scientifiques', 'digue', 'blocs', 'las', 'imprimer', 'techniques', 'participer', 'anniversaire', 'demandés', 'discovery', 'expliquée', 'expedition', 'citation', 'und', 'entretemps', 'hampshire', 'créatif', 'maintenir', 'pierre', 'détaillé', 'faits', 'cadre', 'finance', 'socialiste', 'script', 'caméra', 'retourne', 'engagé', 'assistance', 'expérimentés', 'souterrains', 'vente', 'belle', 'jeanne', 'abc', 'supposé', 'successeurs', 'classification', 'outil', 'minière', 'cabinet', 'octets', 'ross', 'russell', 'citations', 'maintenue', 'soir', 'chanter', 'fifa', 'genre', 'lieux', 'laques', 'mail', 'jeff', 'électorale', 'urgences', 'mode', 'christophe', 'têtes', 'prouvés', 'curé', 'fonds', 'investissements', 'roumain', 'séance', 'capter', 'aspects', 'réduire', 'trophées', 'maltraitance', 'préfecture', 'marcher', 'normalement', 'snow', 'magasin', 'dakota', 'buisson', 'charbon', 'habitants', 'gary', 'salariés', 'erreurs', 'invitées', 'câble', 'protéine', 'accident', 'décennie', 'mesure', 'regardées', 'patientes', 'downtown', 'animée', 'satellite', 'johnny', 'combinaison', 'juridictions', 'séquence', 'crochet', 'nettoyer', 'propriétaires', 'jumelles', 'distribuées', 'décrire', 'défensif', 'islam', 'photographies', 'ottomane', 'formé', 'touché', 'itinéraires', 'ministres', 'vin', 'ailleurs', 'lanka', 'carlos', 'atterrir', 'recueilli', 'renouveau', 'río', 'communes', 'saturday', 'députés', 'devine', 'drop', 'sarah', 'pondu', 'baignade', 'adhésion', 'édimbourg', 'ajuster', 'harris', 'dallas', 'degré', 'baccalauréat', 'personnellement', 'brièvement', 'dossiers', 'extreme', 'cours', 'atteindre', 'recherché', 'vision', 'exiger', 'verticale', 'actualisé', 'commercialisation', 'jason', 'consistait', 'appel', 'avion', 'rapides', 'victor', 'dyk', 'solaire', 'âges', 'quartier', 'équitablement', 'ailes', 'acides', 'rfc', 'constants', 'hanche', 'administrateurs', 'nova', 'cérémonie', 'chili', 'compositeurs', 'nazis', 'érudit', 'liverpool', 'hero', 'créateur', 'apprises', 'instruments', 'bienvenu', 'coiffure', 'consécutive', 'ciné', 'adjacent', 'pool', 'aut', 'normande', 'collections', 'belges', 'austin', 'assurez', 'conduite', 'téléphone', 'mouche', 'ian', 'fenêtres', 'document', 'adams', 'collaboratif', 'marguerite', 'kennedy', 'jambe', 'vidéos', 'supposez', 'attachés', 'sécher', 'élargir', 'bible', 'matthieu', 'serbes', 'instrument', 'couvrant', 'aléatoires', 'représente', 'participants', 'minutieuse', 'mentions', 'portrait', 'conducteur', 'airlines', 'franklin', 'spectateurs', 'finlandaise', 'différences', 'lieu', 'vocal', 'élément', 'régulièrement', 'rejeté', 'parent', 'illicite', 'stewart', 'toiture', 'lieues', 'couleurs', 'morgan', 'détenus', 'facebook', 'assister', 'nelson', 'survécu', 'assurance', 'expert', 'vapeurs', 'cartes', 'fabrication', 'tester', 'côtière', 'yorkshire', 'sauveteurs', 'territoires', 'thu', 'thailande', 'frappé', 'choisis', 'vienne', 'parcours', 'rangement', 'coûts', 'singh', 'distincts', 'notamment', 'soldat', 'colonie', 'évolution', 'taïwan', 'ouragan', 'juges', 'jardins', 'poèmes', 'conduit', 'responsabilité', 'phrases', 'birmingham', 'ingénieurs', 'visibles', 'substantiel', 'gulf', 'installée', 'révolutionnaire', 'trip', 'gastronomie', 'graham', 'magasins', 'riz', 'prouve', 'raisonnables', 'peau', 'engagé', 'volleyball', 'choisi', 'facteurs', 'centaine', 'lésée', 'périphériques', 'phrase', 'stanley', 'lemmon', 'thompson', 'suicides', 'avantage', 'automatiquement', 'disque', 'minimums', 'biens', 'charges', 'alfred', 'opérateur', 'terminer', 'fred', 'identifier', 'producteurs', 'anne', 'campbell', 'portland', 'dernière', 'rejets', 'victimes', 'explications', 'opérer', 'menace', 'traversée', 'lente', 'poètes', 'stoppé', 'stratégie', 'wayne', 'classement', 'disney', 'wright', 'résidentiels', 'associer', 'importance', 'statué', 'excellent', 'observé', 'menacées', 'amical', 'redirections', 'temporaire', 'maîtres', 'péninsule', 'réseaux', 'passagers', 'présumé', 'artistique', 'coffre', 'fêtes', 'concourir', 'png', 'hunter', 'alaska', 'partenariat', 'maintenance', 'suivi', 'diabolique', 'secours', 'charlie', 'pauvreté', 'hop', 'fri', 'soupçonné', 'rempli', 'nba', 'décidez', 'briser', 'argentine', 'démission', 'oblast', 'drew', 'hawaii', 'brooklyn', 'historiens', 'conférencier', 'papillon', 'permission', 'blessés', 'raciale', 'marshall', 'porte', 'springs', 'roy', 'photographique', 'aider', 'chevaliers', 'rouleau', 'progressive', 'contraste', 'continue', 'procédés', 'terminaux', 'exécutée', 'svg', 'épouse', 'infrastructure', 'principe', 'peintres', 'peints', 'correctement', 'fréquences', 'façonnée', 'rejoindre', 'robinson', 'waters', 'crête', 'ponts', 'pdg', 'monument', 'mental', 'carter', 'karl', 'rowspan', 'mac', 'orléans', 'portail', 'parallèle', 'thirty', 'géante', 'qualifier', 'murray', 'afghanistan', 'appréciation', 'comptoir', 'oursons', 'achetez', 'expression', 'uefa', 'améliorations', 'madrid', 'fermeture', 'roues', 'ambassadrice', 'désertique', 'apportant', 'iranien', 'régner', 'oncle', 'sévère', 'pluie', 'amiral', 'pêche', 'existaient', 'élever', 'broadway', 'principes', 'pousser', 'épreuves', 'grossièrement', 'tech', 'perturbation', 'rico', 'alinéa', 'batte', 'préparé', 'mesures', 'robin', 'engagé', 'craintes', 'mérite', 'participation', 'massives', 'dessins', 'agences', 'technique', 'alberta', 'égyptien', 'commis', 'savaient', 'étroit', 'adapté', 'commissaire', 'rapides', 'crédité', 'rencontres', 'entreprises', 'bombes', 'capable', 'poème', 'étapes', 'honorifiques', 'dragon', 'chargé', 'proposer', 'modifiés', 'virés', 'mlb', 'envoyer', 'preuves', 'pratiques', 'arabes', 'attractions', 'embouchure', 'réparer', 'agréé', 'symbole', 'organe', 'endommagée', 'warren', 'exception', 'costa', 'malheureusement', 'jérusalem', 'remplaçant', 'indiens', 'soundtrack', 'puceau', 'milliers', 'vancouver', 'législations', 'beauté', 'crédits', 'achetez', 'organisations', 'serbie', 'christianisme', 'opinions', 'cavalerie', 'tribu', 'richmond', 'echec', 'canaux', 'revendiquer', 'exactes', 'baker', 'alliée', 'implication', 'anime', 'donald', 'sœurs', 'requêtes', 'insolite', 'impossibles', 'couleurs', 'cuisinière', 'dessiner', 'wikimedia', 'jonathan', 'suppression', 'indique', 'admises', 'propriété', 'rivage', 'surveillé', 'nebraska', 'règlement', 'krach', 'guitariste', 'supports', 'abbaye', 'suppression', 'nevada', 'barry', 'tonus', 'opère', 'autochtone', 'personnalité', 'réception', 'transit', 'bison', 'fleurs', 'bond', 'jay', 'aventure', 'définitivement', 'guinéenne', 'horreur', 'rangers', 'pointu', 'pomme', 'popularité', 'parfois', 'coalition', 'franchisés', 'étoilé', 'critique', 'revues', 'roulement', 'pourcentage', 'silencieuses', 'laboratoires', 'microsoft', 'mouvements', 'chartes', 'convenable', 'alterner', 'offrande', 'missions', 'expérimentale', 'chambres', 'conclus', 'réputation', 'précis', 'versus', 'sites', 'interprétation', 'identifiés', 'endémiques', 'chimie', 'réaliser', 'connait', 'mangas', 'journalistes', 'forêt', 'cbs', 'symphonie', 'promotionnels', 'electrique', 'tags', 'mètres', 'jerry', 'tigres', 'commerce', 'remix', 'adressée', 'phil', 'automatique', 'bande', 'imprimés', 'chêne', 'warner', 'tendent', 'cite', 'séparé', 'évêques', 'glasgow', 'fondamentalement', 'attendez', 'accumulateur', 'faveur', 'benjamin', 'apparente', 'shopping', 'patrouille', 'aigle', 'anges', 'martiaux', 'restauration', 'delhi', 'hans', 'indiqué', 'morris', 'centres', 'broyeurs', 'utiles', 'livré', 'composantes', 'victorienne', 'législature', 'tourisme', 'traitées', 'étendue', 'enfants', 'barbara', 'essai', 'circonstances', 'répétées', 'plaine', 'superieur', 'stratégiques', 'pareillement', 'devoirs', 'efficacement', 'blp', 'considérant', 'arrangés', 'ken', 'grammaire', 'modification', 'prétendu', 'relation', 'habitat', 'parlée', 'shell', 'monté', 'entrées', 'conflit', 'philippines', 'montana', 'apparaissant', 'triple', 'caraïbe', 'hôtes', 'panneaux', 'serieux', 'bristol', 'belligérantes', 'mitchell', 'industries', 'colombie', 'comparaisons', 'bassin', 'eleven', 'malades', 'pradesh', 'charité', 'sortie', 'adn', 'carbone', 'bateaux', 'desc', 'architectural', 'représentation', 'commentaire', 'montante', 'visiteurs', 'marchés', 'plaque', 'giants', 'traitement', 'paysages', 'dick', 'chasse', 'sommet', 'psychologie', 'balade', 'grandement', 'gardien', 'terminus', 'pertes', 'équilibre', 'démocratie', 'nicholas', 'habituelle', 'pérou', 'huitième', 'instrumentale', 'hindoue', 'défenseur', 'équitation', 'arrivées', 'evans', 'tournant', 'insinuer', 'prose', 'fret', 'masqués', 'bénévoles', 'biographie', 'détenteur', 'sucres', 'filles', 'faune', 'amusant', 'intégrés', 'partenaires', 'taux', 'grace', 'fil', 'enfance', 'accompagnés', 'milan', 'photographies', 'honneur', 'sol', 'serveur', 'manuelle', 'béton', 'possibilité', 'fantômes', 'troublé', 'tunnel', 'larry', 'styles', 'élévation', 'mahomet', 'considérables', 'inter', 'perd', 'phoenix', 'sweet', 'déchet', 'opérationnelle', 'tall', 'qualifier', 'constitutionnels', 'peuples', 'acceptable', 'fruits', 'décisions', 'dépression', 'perspective', 'milieu', 'crystal', 'monastères', 'résidents', 'cincinnati', 'liées', 'chirurgie', 'étapes', 'transporteur', 'ruisseau', 'alice', 'botter', 'etrange', 'prédécesseur', 'bernard', 'nigéria', 'douleurs', 'influent', 'voyou', 'suggestion', 'interactions', 'retenu', 'accomplissement', 'mécaniques', 'drogue', 'manqués', 'trinité', 'classé', 'minoritaire', 'manteau', 'propulsé', 'alive', 'nbc', 'lnh', 'keith', 'bobby', 'harbor', 'comportement', 'croate', 'maritime', 'terry', 'virtuelles', 'intérieur', 'périodes', 'spirituelles', 'croatie', 'lions', 'archevêque', 'luis', 'négociant', 'azerbaïdjan', 'lots', 'contestée', 'rédaction', 'initiative', 'charlotte', 'pure', 'frontières', 'persan', 'marques', 'arméniens', 'romantique', 'remplaçant', 'talent', 'improbables', 'panel', 'saut', 'animations', 'mandataires', 'emplois', 'négociation', 'parker', 'statue', 'daté', 'wonder', 'classé', 'provinces', 'vendredi', 'emplois', 'cuba', 'sao', 'scientifique', 'calendrier', 'attendant', 'familiers', 'suspectes', 'désaccord', 'suggestions', 'turner', 'formage', 'formellement', 'locomotives', 'barcelona', 'cohérent', 'recommandées', 'désirer', 'patient', 'bulgarie', 'vincent', 'entendre', 'textes', 'croyance', 'visiteur', 'vaisseaux', 'fondamentalement', 'continentaux', 'trou', 'échouer', 'passage', 'voit', 'mariages', 'archéologiques', 'calque', 'appellation', 'clan', 'recettes', 'couples', 'costume', 'soft', 'weekend', 'homologation', 'démocrate', 'crimes', 'collins', 'expatriés', 'cheval', 'usure', 'soutiens', 'liquidités', 'denis', 'ressource', 'sculptures', 'pratique', 'harrison', 'rosé', 'olivier', 'limites', 'cooper', 'illustrés', 'enfer', 'statistique', 'référencé', 'arbcom', 'louve', 'guerriers', 'incidents', 'fraîcheur', 'éditions', 'racine', 'signature', 'cliniques', 'volumes', 'pires', 'adulte', 'contribuer', 'nécessairement', 'immédiatement', 'sentiment', 'théories', 'essentiels', 'achèvement', 'conclusion', 'technologies', 'strip', 'lié', 'loué', 'séjourné', 'coques', 'diamants', 'origines', 'vide', 'éliminé', 'précieuse', 'cite', 'doubles', 'succursales', 'honneurs', 'brique', 'expériences', 'beijing', 'cravates', 'homosexualité', 'liberté', 'siège', 'baptiste', 'ron', 'hébraïque', 'affectent', 'baisse', 'entraîneurs', 'alpha', 'équipé', 'identiques', 'soumis', 'entreprise', 'touche', 'transmissions', 'plateformes', 'cave', 'filmée', 'centimètre', 'cool', 'bulgares', 'liga', 'manhattan', 'destruction', 'activiste', 'arme', 'clay', 'claviers', 'dangereuses', 'visionné', 'courriel', 'biologie', 'gras', 'bowling', 'comparaison', 'traités', 'affiliés', 'chaussette', 'agressions', 'mensuelle', 'foster', 'cousine', 'url', 'hispanique', 'logiques', 'craig', 'trivial', 'pionnière', 'musulman', 'lay', 'noté', 'absence', 'amsterdam', 'éditeurs', 'tribus', 'percussion', 'coureurs', 'thèmes', '#les', 'prestations', 'gardiens', 'flux', 'attribuée', 'athènes', 'herbert', 'fêté', 'sponsorisée', 'raf', 'delaware', 'neil', 'polonais', 'arbitre', 'historiquement', 'tail', 'visites', 'stable', 'décide', 'vaisseau', 'identification', 'delta', 'écrit', 'méditerranée', 'bénévoles', 'reponse', 'stuart', 'marvel', 'luc', 'grave', 'odd', 'entendre', 'uss', 'mall', 'sanction', 'solutions', 'sécurisé', 'hugh', 'steven', 'semelle', 'architectes', 'caractéristiques', 'tombant', 'tourne', 'clinton', 'villa', 'sélectionner', 'métriques', 'critiqués', 'survivre', 'roberts', 'classements', 'biologique', 'lloyd', 'munich', 'appartient', 'adelaide', 'appartenir', 'harold', 'norfolk', 'majordome', 'coi', 'rivaux', 'acoustique', 'publications', 'adaptation', 'greg', 'reporter', 'url', 'absolument', 'personne', 'bourse', 'vaste', 'sortie', 'enquête', 'dual', 'belt', 'remarqué', 'brevet', 'mathématiques', 'rarement', 'soumission', 'démographie', 'foule', 'rick', 'gouvernements', 'bonification', 'touriste', 'mystères', 'cliquant', 'marcher', 'néanmoins', 'votants', 'carabine', 'composant', 'civiles', 'partielle', 'encouragé', 'anniversaires', 'eddy', 'chrétiens', 'denver', 'petersbourg', 'chercheurs', 'partiellement', 'photographe', 'exécutable', 'jon', 'obama', 'semblait', 'horloges', 'violon', 'autoroutes', 'vacances', 'distinctions', 'artwork', 'maquiller', 'catherine', 'fontes', 'agriculteurs', 'occasions', 'photographier', 'lutte', 'timestamp', 'yale', 'options', 'stylos', 'procédure', 'jacob', 'condamnés', 'tournée', 'transition', 'anglo', 'legs', 'refusée', 'relations', 'ottawa', 'derby', 'entouré', 'bibliothèques', 'rivaliser', 'intervenants', 'grades', 'hudson', 'administrateurs', 'sacrés', 'signature', 'braquer', 'citoyen', 'chien', 'argumenter', 'croit', 'annuellement', 'cardinal', 'népal', 'carrefour', 'révèle', 'différends', 'faisceau', 'outremer', 'perry', 'pseudonyme', 'syrie', 'wells', 'contribuer', 'ultime', 'rangs', 'dany', 'détail', 'préférés', 'vermont', 'commencée', 'téléchargement', 'confiance', 'nomination', 'ballet', 'jefferson', 'partout', 'sable', 'angle', 'sessions', 'récréation', 'portant', 'kenya', 'accessibles', 'ralph', 'fil', 'perturbateurs', 'dépenser', 'neuvième', 'arrestations', 'choeur', 'mines', 'lésions', 'ronds', 'compétitifs', 'opportunités', 'réunions', 'commentés', 'wang', 'woods', 'exercice', 'jacques', 'objectif', 'démolie', 'préférés', 'pedro', 'robotique', 'venezuela', 'segment', 'étudier', 'edwards', 'viser', 'dansant', 'aigles', 'montré', 'hommages', 'continus', 'encourager', 'araignée', 'agi', 'convaincus', 'heroes', 'décrivant', 'pierres', 'lit', 'gap', 'refléter', 'mars', 'participant', 'coopérations', 'obtenir', 'gothiques', 'manifestation', 'chasse', 'rfa', 'fréquente', 'reconversion', 'stressé', 'fabricants', 'checkuser', 'exprimé', 'traditionnellement', 'josé', 'aventures', 'tigre', 'totalement', 'concentration', 'chante', 'roquette', 'électricité', 'ombres', 'boxe', 'sénateurs', 'toubib', 'stanford', 'machines', 'vegas', 'enregistrés', 'jurys', 'calendrier', 'noblesse', 'tommy', 'coupables', 'leo', 'poignée', 'éteints', 'répondu', 'partages', 'scotia', 'fabricant', 'récits', 'implémentation', 'camion', 'orthographe', 'élément', 'charge', 'clientèle', 'ajoute', 'espaces', 'capuchon', 'orphelins', 'traversiers', 'préfèrent', 'pousse', 'mensonges', 'berkeley', 'liban', 'madison', 'trône', 'attirées', 'lionne', 'récupérée', 'manor', 'promouvoir', 'saoudien', 'série', 'etranger', 'rogers', 'luminaires', 'écartement', 'concerts', 'aîné', 'renaissance', 'uniformes', 'chase', 'aka', 'ordinateurs', 'brisbane', 'sylvie', 'raymond', 'fleur', 'col', 'thaïlandais', 'catastrophes', 'survivre', 'vêtement', 'murphy', 'sharp', 'explique', 'yougoslavie', 'bouddhistes', 'publiquement', 'viandes', 'littéralement', 'spams', 'téléphone', 'moralité', 'chantée', 'partiellement', 'juristes', 'citant', 'interviews', 'brunswick', 'radars', 'dépense', 'bosquet', 'thé', 'elite', 'lumineux', 'améliorer', 'sierra', 'ciel', 'athlète', 'aspect', 'réponses', 'ted', 'consommateur', 'financés', 'exclusif', 'ibn', 'manuel', 'alliés', 'examinateur', 'missile', 'mécanisme', 'helen', 'retiré', 'intention', 'mini', 'victimes', 'maladies', 'rythme', 'pat', 'attraper', 'scrutin', 'pont', 'newcastle', 'antarctique', 'leeds', 'duré', 'gammes', 'ordinaires', 'insecte', 'souffrances', 'flashs', 'culte', 'limites', 'aveugles', 'pakistanais', 'supposant', 'interstate', 'arrangement', 'globe', 'honneurs', 'brute', 'gilbert', 'applique', 'graduellement', 'gérer', 'expérimentation', 'radicale', 'gov', 'pattes', 'adversaire', 'diamètres', 'fournitures', 'pitch', 'utilité', 'nettoyage', 'opposants', 'régime', 'révisé', 'genres', 'diplomatiques', 'allemands', 'phoques', 'grégory', 'correspondant', 'concepts', 'sabre', 'violet', 'virus', 'populations', 'taureaux', 'batteur', 'présente', 'hollande', 'préjugé', 'fusion', 'distante', 'sean', 'messages', 'rébellion', 'premiere', 'physicien', 'victime', 'con', 'nuages', 'angels', 'bruit', 'rubrique', 'duo', 'bière', 'palestiniens', '$us', 'cuivre', 'juridiction', 'améliorations', 'skier', 'culminé', 'hms', 'boucle', 'renommer', 'fût', 'dramatiques', 'saskatchewan', 'pourparlers', 'séisme', 'rhode', 'chapeau', 'exigence', 'den', 'cuves', 'présidents', 'min', 'défendre', 'alcool', 'dominées', 'chantait', 'mange', 'graphisme', 'circonscriptions', 'asp', 'café', 'chancelière', 'détruire', 'tonnes', 'cruz', 'varsovie', 'exclusivement', 'connexions', 'rush', 'hauteurs', 'playstation', 'aboutissement', 'appartement', 'cardinaux', 'remplir', 'bénéficiaire', 'correctement', 'traditions', 'fondamentaux', 'minces', 'chan', 'résolue', 'mario', 'départements', 'dame', 'shield', 'combattants', 'ivan', 'écrits', 'bosnie', 'condamnés', 'violente', 'légende', 'harbour', 'marges', 'auckland', 'postale', 'pirates', 'collectif', 'diesel', 'libération', 'confédéré', 'diable', 'activistes', 'sultan', 'cavalier', 'amazone', 'florence', 'marc', 'arnold', 'shah', 'blogspot', 'réduction', 'contenu', 'génétiques', 'somerset', 'localement', 'lait', 'romantique', 'intellectuels', 'latinos', 'échouer', 'mason', 'pete', 'consultatif', 'arbitrages', 'interface', 'hitler', 'défaut', 'consulté', 'sheffield', 'départs', 'hindi', 'anglicane', 'suggérant', 'erreur', 'résidant', 'ambassades', 'assassinée', 'sox', 'dors', 'suspendus', 'sum', 'mythologie', 'bengale', 'désarroi', 'oscar', 'thérapies', 'occasion', 'exposé', 'assisté', 'possession', 'défendez', 'consacré', 'graphique', 'milwaukee', 'informés', 'anonyme', 'inversé', 'savons', 'territorial', 'lisa', 'paulo', 'northwestern', 'éliminatoires', 'patronne', 'nasa', 'cotés', 'byzantine', 'idaho', 'affiche', 'géographiques', 'rebonds', 'congo', 'venture', 'pire', 'canular', 'restreint', 'portes', 'nommer', 'situations', 'instructions', 'sullivan', 'tableaux', 'feuilles', 'tirez', 'remplaçants', 'gastronomie', 'contributeurs', 'erreurs', 'apprécié', 'cadre', 'rocky', 'kerala', 'shakespeare', 'quantique', 'immigration', 'miroirs', 'certifiés', 'actifs', 'npov', 'potentiellement', 'présentation', 'coton', 'assis', 'tournois', 'syndrome', 'coché', 'quarante', 'approvisionnement', 'journalistique', 'infructueuses', 'tours', 'conducteur', 'hôpitaux', 'bone', 'essex', 'reconstruit', 'wellington', 'idéal', 'crus', 'partager', 'libellés', 'leonard', 'watson', 'gouverneurs', 'poster', 'harvey', 'fondements', 'bjr', 'rabin', 'matériels', 'ensemble', 'monstre', 'pichet', 'emphase', 'guérison', 'répondez', 'aaron', 'moindre', 'qualification', 'organique', 'exposition', 'palestinien', 'pensées', 'rédigé', 'maurice', 'immigrés', 'variante', 'giron', 'légitime', 'autonome', 'wallace', 'succession', 'jeter', 'lundi', 'réserves', 'donnés', 'augmente', 'gamin', 'accouchement', 'joan', 'fifty', 'esclaves', 'rétroaction', 'columbus', 'pierres', 'gérer', 'cgi', 'initié', 'faveur', 'imprimerie', 'variables', 'théologie', 'todd', 'paramètres', 'voyagé', 'canton', 'han', 'reed', 'celtic', 'caractéristique', 'commandée', 'recherchant', 'inadéquat', 'commutateur', 'cravates', 'tube', 'otto', 'dettes', 'extérieure', 'navigation', 'admissibles', 'experts', 'chères', 'tier', 'evangile', 'newton', 'essais', 'shanghai', 'conventionnels', 'campagnes', 'sentiments', 'bath', 'venise', '#aaa', 'chats', 'variantes', 'émergé', 'chaussette', 'connexion', 'crue', 'documentée', 'coutume', 'touché', 'profession', 'agencement', 'universitaires', 'colons', 'fusionner', 'sony', 'compétiteurs', 'phillips', 'herbe', 'réservoir', 'artificielles', 'romancier', 'astuce', 'prague', 'abou', 'visages', 'guitares', 'aspx', 'laure', 'boursiers', 'internationalement', 'attaquer', 'johann', 'rêves', 'hugues', 'banlieue', 'compris', 'spécialisés', 'averti', 'perles', 'chœur', 'dépendants', 'restriction', 'meurtrier', 'oakland', 'trio', 'influences', 'blocage', 'mtv', 'bétail', 'engins', 'gabriel', 'échangé', 'patinage', 'quinzaine', 'palmier', 'wikis', 'conte', 'démontrer', 'varie', 'liquides', 'cyclisme', 'princeton', 'respectifs', 'voix', 'frédéric', 'jet', 'horn', 'érigé', 'brûler', 'ouvrier', 'ambiance', 'caractérisés', 'syriens', 'java', 'moniteur', 'diplômé', 'colonnes', 'réparations', 'poubelle', 'bâton', 'dollars', 'organisées', 'paramètre', 'véritablement', 'détermination', 'buenos', 'parade', 'adossés', 'notoriété', 'dépendra', 'définis', 'spencer', 'républicains', 'conspiration', 'meurent', 'clarke', 'bruts', 'engagez', 'pin', 'équation', 'ressent', 'démocrate', 'coupe', 'bouton', 'marques', 'queens', 'abraham', 'encolure', 'forever', 'boissons', 'shérif', 'miguel', 'aires', 'montgomery', 'vanité', 'cadeaux', 'cavaliers', 'fonctionnel', 'traversé', 'diverses', 'numérotés', 'soumissions', 'doucement', 'attitude', 'souris', 'justin', 'protestations', 'dieux', 'montants', 'variation', 'futé', 'prix', 'prier', 'terrorisme', 'béta', 'durham', 'comtes', 'irakienne', 'détective', 'josh', 'reliant', 'compositions', 'ovale', 'filmer', 'parfaitement', 'indianapolis', 'enterrement', 'récupérés', 'fermier', 'protestante', 'cameron', 'imprécis', 'indonésienne', 'mixage', 'mumbai', 'nashville', 'danger', 'rallye', 'récit', 'campements', 'surprises', 'fabriqué', 'déployée', 'kate', 'moléculaires', 'inutiles', 'isle', 'théorème', 'colonies', 'chypre', 'sillage', 'apporte', 'vents', 'magnétisme', 'conversation', 'sussex', 'portes', 'bélier', 'plastiques', 'électronique', 'rétablir', 'stockholm', 'inn', 'autocars', 'connectez', 'wmflabs', 'hôtes', 'rayonnements', 'reçoit', 'lancashire', 'éliminatoires', 'cork', 'généraux', 'intermédiaires', 'vérifiables', 'acclamations', 'philippine', 'orientée', 'hamburg', 'crée', 'orbites', 'massacres', 'dialoguer', 'maladie', 'robe', 'codes', 'aurore', 'isolé', 'nancy', 'violations', 'perth', 'titularisation', 'dames', 'automne', 'évaluations', 'erroné', 'éclaireur', 'difficultés', 'élèves', 'richesse', 'hart', 'allégations', 'règlementation', 'regarder', 'lodge', 'oeufs', 'contestée', 'citoyenneté', 'spécialiste', 'tâches', 'intentions', 'instruction', 'cessé', 'fierté', 'bannière', 'amitiés', 'panamá', 'corruption', 'coulé', 'harm', 'ernest', 'pilotes', 'poursuivre', 'bande', 'émigrés', 'annulés', 'venger', 'révision', 'dominant', 'redevance', 'informatique', 'examen', 'chen', 'matrix', 'das', 'biographique', 'bisou', 'valign', 'nationalistes', 'chance', 'croix', 'lourd', 'enchère', 'apprécie', 'ennemis', 'mercure', 'interactifs', 'mathématiques', 'préserver', 'nobel', 'grande', 'structurels', 'épouser', 'aéroports', 'vétérans', 'axe', 'exécution', 'cultes', 'réducteurs', 'colin', 'chester', 'ticket', 'appartenant', 'entité', 'judiciaire', 'expressément', 'attentat', 'reconnus', 'applicables', 'fondateurs', 'équipé', 'wilhelm', 'soudain', 'parking', 'absolu', 'françois', 'locomotives', 'préparation', 'nintendo', 'déclaration', 'vraisemblablement', 'enterrement', 'gouverner', 'jamaïque', 'connaissant', 'vladimir', 'battre', 'avg', 'méthodiste', 'utf', 'défis', 'kenneth', 'évolué', 'célébration', 'discipliné', 'roulements', 'appartenu', 'faune', 'manuscrits', 'expérimentations', 'chefs', 'composé', 'tampa', 'saoudite', 'associations', 'cibles', 'extraterrestre', 'représenté', 'adjudant', 'diffs', 'subsidiaires', 'thirteen', 'épaisses', 'prolonger', 'rejeté', 'néo', 'fil', 'doctorants', 'mesurées', 'graisse', 'visites', 'linux', 'enseigner', 'vols', 'couplet', 'bennet', 'chaude', 'dynamique', 'shaw', 'pauses', 'monuments', 'menteur', 'seigneurs', 'michel', 'traiter', 'raids', 'congrégation', 'température', 'testament', 'potable', 'compagne', 'manille', 'km²', 'pendjab', 'imagine', 'considération', 'vétéran', 'médecins', 'aîné', 'souverain', 'wise', 'envoi', 'afc', 'digne', 'immatriculation', 'répertoire', 'wyoming', 'manitoba', 'vietnamiennes', 'ronald', 'cubaines', 'brûlés', 'justifient', 'divins', 'supposons', 'destin', 'rovers', 'cole', 'oraux', 'trans', 'planches', 'bryan', 'santiago', 'épiscopale', 'terroristes', 'ok', 'vagues', 'inventé', 'débarqués', 'sandy', 'acres', 'peindre', 'activement', 'indication', 'arrêts', 'excellence', 'intégration', 'bibliographie', 'sottises', 'marathon', 'croyance', 'superflu', 'acrobatique', 'aérienne', 'conservation', 'altitude', 'librement', 'simultané', 'psychologique', 'fernando', 'cultures', 'fiscalité', 'marcus', 'piquets', 'dominicain', 'franz', 'monnaies', 'oxygène', 'civiques', 'isaac', 'orthographe', 'inspiration', 'paires', 'vecteur', 'arc', 'professionnels', 'vii', 'contraire', 'accusations', 'approches', 'esclaves', 'folle', 'spectre', 'client', 'douzaine', 'voyages', 'symboles', 'plaza', 'bancaire', 'héritées', 'légion', 'symptôme', 'mosquée', 'gars', 'lab', 'voile', 'orientation', 'pratiquement', 'générique', 'raisonnements', 'avc', 'syndicats', 'efficaces', 'ouvre', 'impression', 'découvrir', 'réinstallés', 'roosevelt', 'dancer', 'phénomène', 'préliminaire', 'reconnais', 'ancrer', 'argumenter', 'aptitudes', 'procédures', 'émotionnel', 'bois', 'pêcheur', 'prod', 'cartoon', 'trouble', 'fui', 'exigences', 'lituanie', 'continent', 'camaraderie', 'verrou', 'relégués', 'mandat', 'imaginais', 'récurrent', 'aperçu', 'riche', 'acquisition', 'eve', 'filtrant', 'allocutions', 'indépendamment', 'slovénie', 'observation', 'contestée', 'menace', 'tombé', 'protocol', 'jugement', 'grammy', 'teintes', 'distinctif', 'opposés', 'repère', 'colis', 'commandes', 'achèvement', 'sabha', 'détenu', 'signaux', 'fabien', 'inaugurale', 'intervention', 'arrivant', 'vérin', 'tenth', 'liu', 'testées', 'renommé', 'boutiques', 'dome', 'philosophe', 'épopée', 'potence', 'spécifié', 'davies', 'effondrement', 'allan', 'albanais', 'canyon', 'échantillons', 'perçues', 'célébrité', 'prêtres', 'louise', 'ateliers', 'claude', 'fortune', 'barres', 'cornwall', 'palmer', 'présidence', 'tiny', 'appels', 'istanbul', 'rookie', 'expansion', 'calgary', 'choquer', 'stevens', 'employé', 'yang', 'logés', 'caveau', 'gagner', 'innovation', 'ruisseaux', 'unity', 'lucas', 'croît', 'arménie', 'échangeur', 'protéines', 'propositions', 'nageurs', 'continentale', 'séminaire', 'hamlet', 'journal', 'réalise', 'newport', 'négociations', 'expositions', 'malte', 'haïr', 'westminster', 'installation', 'pénètre', 'gardien', 'julien', 'maroc', 'rendement', 'chapitres', 'hélicoptères', 'forteresse', 'ani', 'brûlé', 'affichages', 'compilées', 'ips', 'contributeurs'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRjXoAVOhT8A"
      },
      "source": [
        "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def get_matrices(en_fr, french_vecs, english_vecs):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        en_fr: English to French dictionary\n",
        "        french_vecs: French words to their corresponding word embeddings.\n",
        "        english_vecs: English words to their corresponding word embeddings.\n",
        "    Output: \n",
        "        X: a matrix where the columns are the English embeddings.\n",
        "        Y: a matrix where the columns correspong to the French embeddings.\n",
        "        R: the projection matrix that minimizes the F norm ||X R -Y||^2.\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "\n",
        "    # X_l and Y_l are lists of the english and french word embeddings\n",
        "    X_l = list()\n",
        "    Y_l = list()\n",
        "\n",
        "    # get the english words (the keys in the dictionary) and store in a set()\n",
        "    english_set = {k for k in en_embeddings_subset.keys()}\n",
        "\n",
        "    # get the french words (keys in the dictionary) and store in a set()\n",
        "    french_set = {k for k in fr_embeddings_subset.keys()}\n",
        "\n",
        "    # store the french words that are part of the english-french dictionary (these are the values of the dictionary)\n",
        "    french_words = set(en_fr.values())\n",
        "\n",
        "    # loop through all english, french word pairs in the english french dictionary\n",
        "    for en_word, fr_word in en_fr.items():\n",
        "\n",
        "        # check that the french word has an embedding and that the english word has an embedding\n",
        "        if fr_word in french_set and en_word in english_set:\n",
        "\n",
        "            # get the english embedding\n",
        "            en_vec = english_vecs[en_word]\n",
        "\n",
        "            # get the french embedding\n",
        "            fr_vec = french_vecs[fr_word]\n",
        "\n",
        "            # add the english embedding to the list\n",
        "            X_l.append(en_vec)\n",
        "\n",
        "            # add the french embedding to the list\n",
        "            Y_l.append(fr_vec)\n",
        "\n",
        "    # stack the vectors of X_l into a matrix X\n",
        "    X = np.vstack(X_l)\n",
        "\n",
        "    # stack the vectors of Y_l into a matrix Y\n",
        "    Y = np.vstack(Y_l)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvDN_dxPp8g8"
      },
      "source": [
        "Now we will use function `get_matrices()` to obtain sets `X_train` and `Y_train`\n",
        "of English and French word embeddings into the corresponding vector space models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-s3aYnCp89i",
        "outputId": "5ab87f32-f6c8-469b-b8a5-66efe6d221ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
        "\n",
        "# getting the training set:\n",
        "X_train, Y_train = get_matrices(\n",
        "    en_fr_train, fr_embeddings_subset, en_embeddings_subset)\n",
        "X_train, Y_train"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.08007812,  0.10498047,  0.04980469, ...,  0.00366211,\n",
              "          0.04760742, -0.06884766],\n",
              "        [ 0.02600098, -0.00189209,  0.18554688, ..., -0.12158203,\n",
              "          0.22167969, -0.02197266],\n",
              "        [-0.01177979, -0.04736328,  0.04467773, ...,  0.07128906,\n",
              "         -0.03491211,  0.02416992],\n",
              "        ...,\n",
              "        [-0.17089844,  0.17871094, -0.06494141, ..., -0.10644531,\n",
              "         -0.31640625, -0.09326172],\n",
              "        [-0.21875   ,  0.09179688,  0.03637695, ..., -0.015625  ,\n",
              "         -0.27148438,  0.14941406],\n",
              "        [-0.00418091,  0.0703125 , -0.04516602, ..., -0.16015625,\n",
              "          0.09326172, -0.15039062]], dtype=float32),\n",
              " array([[-0.0061825 , -0.00094387, -0.00882648, ...,  0.111644  ,\n",
              "         -0.0503964 , -0.0603421 ],\n",
              "        [-0.0341354 ,  0.042414  , -0.0656882 , ..., -0.0539992 ,\n",
              "          0.0371097 , -0.0433599 ],\n",
              "        [ 0.0426481 ,  0.0395683 , -0.00825683, ...,  0.0295259 ,\n",
              "          0.0713421 ,  0.0626402 ],\n",
              "        ...,\n",
              "        [ 0.0903279 , -0.108363  , -0.00956318, ..., -0.0337517 ,\n",
              "         -0.00909727, -0.0503935 ],\n",
              "        [-0.0753425 ,  0.0567269 ,  0.0230996 , ...,  0.0844913 ,\n",
              "          0.0782853 , -0.0151161 ],\n",
              "        [-0.0350154 , -0.0336099 , -0.0251155 , ...,  0.116152  ,\n",
              "          0.110519  ,  0.0197631 ]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiyB_6lV4hnE"
      },
      "source": [
        "<a name=\"2\"></a>\n",
        "\n",
        "# 2. Translations\n",
        "\n",
        "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https://github.com/martin-fabbri/colab-notebooks/raw/master/deeplearning.ai/nlp/images/e_to_f.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:700px;height:200px;\" /> Figure 1 </div>\n",
        "\n",
        "Write a program that translates English words to French words using word embeddings and vector space models. \n",
        "\n",
        "<a name=\"2-1\"></a>\n",
        "## 2.1 Translation as linear transformation of embeddings\n",
        "\n",
        "Given dictionaries of English and French word embeddings you will create a transformation matrix `R`\n",
        "* Given an English word embedding, $\\mathbf{e}$, you can multiply $\\mathbf{eR}$ to get a new word embedding $\\mathbf{f}$.\n",
        "    * Both $\\mathbf{e}$ and $\\mathbf{f}$ are [row vectors](https://en.wikipedia.org/wiki/Row_and_column_vectors).\n",
        "* You can then compute the nearest neighbors to `f` in the french embeddings and recommend the word that is most similar to the transformed word embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOvU9e9t5HvH"
      },
      "source": [
        "### Describing translation as the minimization problem\n",
        "\n",
        "Find a matrix `R` that minimizes the following equation. \n",
        "\n",
        "$$\\arg \\min _{\\mathbf{R}}\\| \\mathbf{X R} - \\mathbf{Y}\\|_{F}\\tag{1} $$\n",
        "\n",
        "### Frobenius norm\n",
        "\n",
        "The Frobenius norm of a matrix $A$ (assuming it is of dimension $m,n$) is defined as the square root of the sum of the absolute squares of its elements:\n",
        "\n",
        "$$\\|\\mathbf{A}\\|_{F} \\equiv \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left|a_{i j}\\right|^{2}}\\tag{2}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0o9v5ZS5Hlr"
      },
      "source": [
        "### Actual loss function\n",
        "In the real world applications, the Frobenius norm loss:\n",
        "\n",
        "$$\\| \\mathbf{XR} - \\mathbf{Y}\\|_{F}$$\n",
        "\n",
        "is often replaced by it's squared value divided by $m$:\n",
        "\n",
        "$$ \\frac{1}{m} \\|  \\mathbf{X R} - \\mathbf{Y} \\|_{F}^{2}$$\n",
        "\n",
        "where $m$ is the number of examples (rows in $\\mathbf{X}$).\n",
        "\n",
        "* The same R is found when using this loss function versus the original Frobenius norm.\n",
        "* The reason for taking the square is that it's easier to compute the gradient of the squared Frobenius.\n",
        "* The reason for dividing by $m$ is that we're more interested in the average loss per embedding than the  loss for the entire training set.\n",
        "    * The loss for all training set increases with more words (training examples),\n",
        "    so taking the average helps us to track the average loss regardless of the size of the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omPdMxHz5cG4"
      },
      "source": [
        "##### [Optional] Detailed explanation why we use norm squared instead of the norm:\n",
        "<details>\n",
        "<summary>\n",
        "    Click for optional details\n",
        "</summary>\n",
        "    <p>\n",
        "        <ul>\n",
        "            <li>The norm is always nonnegative (we're summing up absolute values), and so is the square. \n",
        "            <li> When we take the square of all non-negative (positive or zero) numbers, the order of the data is preserved.  \n",
        "            <li> For example, if 3 > 2, 3^2 > 2^2\n",
        "            <li> Using the norm or squared norm in gradient descent results in the same <i>location</i> of the minimum.\n",
        "            <li> Squaring cancels the square root in the Frobenius norm formula. Because of the <a href=\"https://en.wikipedia.org/wiki/Chain_rule\"> chain rule</a>, we would have to do more calculations if we had a square root in our expression for summation.\n",
        "            <li> Dividing the function value by the positive number doesn't change the optimum of the function, for the same reason as described above.\n",
        "            <li> We're interested in transforming English embedding into the French. Thus, it is more important to measure average loss per embedding than the loss for the entire dictionary (which increases as the number of words in the dictionary increases).\n",
        "        </ul>\n",
        "    </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLhJsXp-51km"
      },
      "source": [
        "<a name=\"ex-02\"></a>\n",
        "\n",
        "### Exercise 02: Implementing translation mechanism described in this section.\n",
        "\n",
        "#### Step 1: Computing the loss\n",
        "* The loss function will be squared Frobenoius norm of the difference between\n",
        "matrix and its approximation, divided by the number of training examples $m$.\n",
        "* Its formula is:\n",
        "$$ L(X, Y, R)=\\frac{1}{m}\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left( a_{i j} \\right)^{2}$$\n",
        "\n",
        "where $a_{i j}$ is value in $i$th row and $j$th column of the matrix $\\mathbf{XR}-\\mathbf{Y}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rEnX4476OnA"
      },
      "source": [
        "#### Instructions: complete the `compute_loss()` function\n",
        "\n",
        "* Compute the approximation of `Y` by matrix multiplying `X` and `R`\n",
        "* Compute difference `XR - Y`\n",
        "* Compute the squared Frobenius norm of the difference and divide it by $m$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqdq63aY69E2"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "   <li> Useful functions:\n",
        "       <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html\">Numpy dot </a>,\n",
        "       <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html\">Numpy sum</a>,\n",
        "       <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.square.html\">Numpy square</a>,\n",
        "       <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html\">Numpy norm</a>\n",
        "    </li>\n",
        "   <li> Be careful about which operation is elementwise and which operation is a matrix multiplication.</li>\n",
        "   <li> Try to use matrix operations instead of the numpy norm function.  If you choose to use norm function, take care of extra arguments and that it's returning loss squared, and not the loss itself.</li>\n",
        "\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_rEUGau6OO8"
      },
      "source": [
        "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def compute_loss(X, Y, R):\n",
        "    '''\n",
        "    Inputs: \n",
        "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
        "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
        "        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
        "    Outputs:\n",
        "        L: a matrix of dimension (m,n) - the value of the loss function for given X, Y and R.\n",
        "    '''\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    # m is the number of rows in X\n",
        "    m = len(X)\n",
        "    \n",
        "    # diff is XR - Y\n",
        "    diff = np.dot(X, R) - Y\n",
        "\n",
        "    # diff_squared is the element-wise square of the difference\n",
        "    diff_squared = np.square(diff)\n",
        "\n",
        "    # sum_diff_squared is the sum of the squared elements\n",
        "    sum_diff_squared = np.sum(diff_squared)\n",
        "\n",
        "    # loss i the sum_diff_squard divided by the number of examples (m)\n",
        "    loss = sum_diff_squared / m\n",
        "    ### END CODE HERE ###\n",
        "    return loss"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko8hfQnD8aPA"
      },
      "source": [
        "<a name=\"ex-03\"></a>\n",
        "\n",
        "### Exercise 03\n",
        "\n",
        "### Step 2: Computing the gradient of loss in respect to transform matrix R\n",
        "\n",
        "* Calculate the gradient of the loss with respect to transform matrix `R`.\n",
        "* The gradient is a matrix that encodes how much a small change in `R`\n",
        "affect the change in the loss function.\n",
        "* The gradient gives us the direction in which we should decrease `R`\n",
        "to minimize the loss.\n",
        "* $m$ is the number of training examples (number of rows in $X$).\n",
        "* The formula for the gradient of the loss function $𝐿(𝑋,𝑌,𝑅)$ is:\n",
        "\n",
        "$$\\frac{d}{dR}𝐿(𝑋,𝑌,𝑅)=\\frac{d}{dR}\\Big(\\frac{1}{m}\\| X R -Y\\|_{F}^{2}\\Big) = \\frac{2}{m}X^{T} (X R - Y)$$\n",
        "\n",
        "**Instructions**: Complete the `compute_gradient` function below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dtBxlcy8eUe"
      },
      "source": [
        "<details>\n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "    <ul>\n",
        "    <li><a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.T.html\" > Transposing in numpy </a></li>\n",
        "    <li><a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html\" > Finding out the dimensions</a> of matrices in numpy </li>\n",
        "    <li>Remember to use numpy.dot for matrix multiplication </li>\n",
        "    </ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4675_lca8aC-"
      },
      "source": [
        "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def compute_gradient(X, Y, R):\n",
        "    '''\n",
        "    Inputs: \n",
        "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
        "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
        "        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
        "    Outputs:\n",
        "        g: a matrix of dimension (n,n) - gradient of the loss function L for given X, Y and R.\n",
        "    '''\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    # m is the number of rows in X\n",
        "    m = len(X)\n",
        "\n",
        "    # gradient is X^T(XR - Y) * 2/m\n",
        "    gradient = 2/m * np.dot(X.T, np.dot(X, R) - Y)\n",
        "    ### END CODE HERE ###\n",
        "    return gradient"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjnUSVQu9gAp"
      },
      "source": [
        "### Step 3: Finding the optimal R with gradient descent algorithm\n",
        "\n",
        "#### Gradient descent\n",
        "\n",
        "[Gradient descent](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html) is an iterative algorithm which is used in searching for the optimum of the function. \n",
        "* Earlier, we've mentioned that the gradient of the loss with respect to the matrix encodes how much a tiny change in some coordinate of that matrix affect the change of loss function.\n",
        "* Gradient descent uses that information to iteratively change matrix `R` until we reach a point where the loss is minimized. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhs83hy89g1x"
      },
      "source": [
        "#### Training with a fixed number of iterations\n",
        "\n",
        "Most of the time we iterate for a fixed number of training steps rather than iterating until the loss falls below a threshold.\n",
        "\n",
        "##### OPTIONAL: explanation for fixed number of iterations\n",
        "<details>\n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>click here for detailed discussion</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li> You cannot rely on training loss getting low -- what you really want is the validation loss to go down, or validation accuracy to go up. And indeed - in some cases people train until validation accuracy reaches a threshold, or -- commonly known as \"early stopping\" -- until the validation accuracy starts to go down, which is a sign of over-fitting.\n",
        "    </li>\n",
        "    <li>\n",
        "    Why not always do \"early stopping\"? Well, mostly because well-regularized models on larger data-sets never stop improving. Especially in NLP, you can often continue training for months and the model will continue getting slightly and slightly better. This is also the reason why it's hard to just stop at a threshold -- unless there's an external customer setting the threshold, why stop, where do you put the threshold?\n",
        "    </li>\n",
        "    <li>Stopping after a certain number of steps has the advantage that you know how long your training will take - so you can keep some sanity and not train for months. You can then try to get the best performance within this time budget. Another advantage is that you can fix your learning rate schedule -- e.g., lower the learning rate at 10% before finish, and then again more at 1% before finishing. Such learning rate schedules help a lot, but are harder to do if you don't know how long you're training.\n",
        "    </li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFVMDqnn-QJt"
      },
      "source": [
        "Pseudocode:\n",
        "1. Calculate gradient $g$ of the loss with respect to the matrix $R$.\n",
        "2. Update $R$ with the formula:\n",
        "$$R_{\\text{new}}= R_{\\text{old}}-\\alpha g$$\n",
        "\n",
        "Where $\\alpha$ is the learning rate, which is a scalar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGd7q5pp-RNm"
      },
      "source": [
        "#### Learning rate\n",
        "\n",
        "* The learning rate or \"step size\" $\\alpha$ is a coefficient which decides how much we want to change $R$ in each step.\n",
        "* If we change $R$ too much, we could skip the optimum by taking too large of a step.\n",
        "* If we make only small changes to $R$, we will need many steps to reach the optimum.\n",
        "* Learning rate $\\alpha$ is used to control those changes.\n",
        "* Values of $\\alpha$ are chosen depending on the problem, and we'll use `learning_rate`$=0.0003$ as the default value for our algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqR4p5md-gtO"
      },
      "source": [
        "<a name=\"ex-04\"></a>\n",
        "\n",
        "### Exercise 04\n",
        "\n",
        "#### Instructions: Implement `align_embeddings()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFfjT5St-ghT"
      },
      "source": [
        "<details>\n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>Use the 'compute_gradient()' function to get the gradient in each step</li>\n",
        "\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfA8LEsv-lFS"
      },
      "source": [
        "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def align_embeddings(X, Y, train_steps=100, learning_rate=0.0003):\n",
        "    '''\n",
        "    Inputs:\n",
        "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
        "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
        "        train_steps: positive int - describes how many steps will gradient descent algorithm do.\n",
        "        learning_rate: positive float - describes how big steps will  gradient descent algorithm do.\n",
        "    Outputs:\n",
        "        R: a matrix of dimension (n,n) - the projection matrix that minimizes the F norm ||X R -Y||^2\n",
        "    '''\n",
        "    np.random.seed(129)\n",
        "\n",
        "    # the number of columns in X is the number of dimensions for a word vector (e.g. 300)\n",
        "    # R is a square matrix with length equal to the number of dimensions in th  word embedding\n",
        "    R = np.random.rand(X.shape[1], X.shape[1])\n",
        "\n",
        "    for i in range(train_steps):\n",
        "        if i % 25 == 0:\n",
        "            print(f\"loss at iteration {i} is: {compute_loss(X, Y, R):.4f}\")\n",
        "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "        # use the function that you defined to compute the gradient\n",
        "        gradient = compute_gradient(X, Y, R)\n",
        "\n",
        "        # update R by subtracting the learning rate times gradient\n",
        "        R = R - learning_rate * gradient \n",
        "        ### END CODE HERE ###\n",
        "    return R"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSBtjSZc_mtI",
        "outputId": "3b0cdb82-67cc-432e-ee1c-342aff8548eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
        "\n",
        "# Testing your implementation.\n",
        "np.random.seed(129)\n",
        "m = 10\n",
        "n = 5\n",
        "X = np.random.rand(m, n)\n",
        "Y = np.random.rand(m, n) * .1\n",
        "R = align_embeddings(X, Y)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss at iteration 0 is: 3.7242\n",
            "loss at iteration 25 is: 3.6283\n",
            "loss at iteration 50 is: 3.5350\n",
            "loss at iteration 75 is: 3.4442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SshRY46IAaJG"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "loss at iteration 0 is: 3.7242\n",
        "loss at iteration 25 is: 3.6283\n",
        "loss at iteration 50 is: 3.5350\n",
        "loss at iteration 75 is: 3.4442\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR5_lq_dAbvq"
      },
      "source": [
        "## Calculate transformation matrix R\n",
        "\n",
        "Using those the training set, find the transformation matrix $\\mathbf{R}$ by calling the function `align_embeddings()`.\n",
        "\n",
        "**NOTE:** The code cell below will take a few minutes to fully execute (~3 mins)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74hEk82GAdMP",
        "outputId": "89ba7acf-0e04-45a3-e03c-7c7406677298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# You do not have to input any code in this cell, but it is relevant to grading, so please do not change anything\n",
        "R_train = align_embeddings(X_train, Y_train, train_steps=400, learning_rate=0.8)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss at iteration 0 is: 963.0146\n",
            "loss at iteration 25 is: 97.8292\n",
            "loss at iteration 50 is: 26.8329\n",
            "loss at iteration 75 is: 9.7893\n",
            "loss at iteration 100 is: 4.3776\n",
            "loss at iteration 125 is: 2.3281\n",
            "loss at iteration 150 is: 1.4480\n",
            "loss at iteration 175 is: 1.0338\n",
            "loss at iteration 200 is: 0.8251\n",
            "loss at iteration 225 is: 0.7145\n",
            "loss at iteration 250 is: 0.6534\n",
            "loss at iteration 275 is: 0.6185\n",
            "loss at iteration 300 is: 0.5981\n",
            "loss at iteration 325 is: 0.5858\n",
            "loss at iteration 350 is: 0.5782\n",
            "loss at iteration 375 is: 0.5735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDyTrQXrA-Vy"
      },
      "source": [
        "##### Expected Output\n",
        "\n",
        "```\n",
        "loss at iteration 0 is: 963.0146\n",
        "loss at iteration 25 is: 97.8292\n",
        "loss at iteration 50 is: 26.8329\n",
        "loss at iteration 75 is: 9.7893\n",
        "loss at iteration 100 is: 4.3776\n",
        "loss at iteration 125 is: 2.3281\n",
        "loss at iteration 150 is: 1.4480\n",
        "loss at iteration 175 is: 1.0338\n",
        "loss at iteration 200 is: 0.8251\n",
        "loss at iteration 225 is: 0.7145\n",
        "loss at iteration 250 is: 0.6534\n",
        "loss at iteration 275 is: 0.6185\n",
        "loss at iteration 300 is: 0.5981\n",
        "loss at iteration 325 is: 0.5858\n",
        "loss at iteration 350 is: 0.5782\n",
        "loss at iteration 375 is: 0.5735"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i8ly79vA8ap"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5xh4_PrA9h7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksi1ujbcA9yZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPLgNGVwA9YP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}