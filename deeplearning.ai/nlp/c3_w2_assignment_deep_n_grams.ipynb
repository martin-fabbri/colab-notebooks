{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"c3_w2_assignment_deep_n_grams.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNz5i6GNGIFWCwVfpqdAwVf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IB8PnCix_w_G"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\r\n","  <td>\r\n","    <a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/nlp/c3_w2_assignment_deep_n_grams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>    \r\n","  </td>\r\n","  <td>\r\n","    <a href=\"https://github.com/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/nlp/c3_w2_assignment_deep_n_grams.ipynb\" target=\"_parent\"><img src=\"https://raw.githubusercontent.com/martin-fabbri/colab-notebooks/master/assets/github.svg\" alt=\"View On Github\"/></a>  </td>\r\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"Y1l8Kkll26e9"},"source":["# Assignment 2:  Deep N-grams\r\n","\r\n","Welcome to the second assignment of course 3. In this assignment you will explore Recurrent Neural Networks `RNN`.\r\n","- You will be using the fundamentals of google's [trax](https://github.com/google/trax) package to implement any kind of deeplearning model. \r\n","\r\n","By completing this assignment, you will learn how to implement models from scratch:\r\n","- How to convert a line of text into a tensor\r\n","- Create an iterator to feed data to the model\r\n","- Define a GRU model using `trax`\r\n","- Train the model using `trax`\r\n","- Compute the accuracy of your model using the perplexity\r\n","- Predict using your own model\r\n"]},{"cell_type":"markdown","metadata":{"id":"t3Ya-I29Amu0"},"source":["## Outline\r\n","\r\n","- [Overview](#0)\r\n","- [Part 1: Importing the Data](#1)\r\n","    - [1.1 Loading in the data](#1.1)\r\n","    - [1.2 Convert a line to tensor](#1.2)\r\n","        - [Exercise 01](#ex01)\r\n","    - [1.3 Batch generator](#1.3)\r\n","        - [Exercise 02](#ex02)\r\n","    - [1.4 Repeating Batch generator](#1.4)        \r\n","- [Part 2: Defining the GRU model](#2)\r\n","    - [Exercise 03](#ex03)\r\n","- [Part 3: Training](#3)\r\n","    - [3.1 Training the Model](#3.1)\r\n","        - [Exercise 04](#ex04)\r\n","- [Part 4:  Evaluation](#4)\r\n","    - [4.1 Evaluating using the deep nets](#4.1)\r\n","        - [Exercise 05](#ex05)\r\n","- [Part 5: Generating the language with your own model](#5)    \r\n","- [Summary](#6)"]},{"cell_type":"markdown","metadata":{"id":"ST5iX08_LEwu"},"source":["<a name='0'></a>\r\n","### Overview\r\n","\r\n","Your task will be to predict the next set of characters using the previous characters. \r\n","- Although this task sounds simple, it is pretty useful.\r\n","- You will start by converting a line of text into a tensor\r\n","- Then you will create a generator to feed data into the model\r\n","- You will train a neural network in order to predict the new set of characters of defined length. \r\n","- You will use embeddings for each character and feed them as inputs to your model. \r\n","    - Many natural language tasks rely on using embeddings for predictions. \r\n","- Your model will convert each character to its embedding, run the embeddings through a Gated Recurrent Unit `GRU`, and run it through a linear layer to predict the next set of characters.\r\n","\r\n","<img src = \"model.png\" style=\"width:600px;height:150px;\"/>\r\n","\r\n","The figure above gives you a summary of what you are about to implement. \r\n","- You will get the embeddings;\r\n","- Stack the embeddings on top of each other;\r\n","- Run them through two layers with a relu activation in the middle;\r\n","- Finally, you will compute the softmax. \r\n","\r\n","To predict the next character:\r\n","- Use the softmax output and identify the word with the highest probability.\r\n","- The word with the highest probability is the prediction for the next word."]},{"cell_type":"code","metadata":{"id":"HOkvO5g0A5gp"},"source":["%%capture\r\n","!pip install trax"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"thfg8l4g2nx4"},"source":["import trax\r\n","from trax import layers as tl\r\n","\r\n","import numpy as np\r\n","import torch \r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ldszNMGjBnQO","executionInfo":{"status":"ok","timestamp":1611720567301,"user_tz":480,"elapsed":1248,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}},"outputId":"df95bc6a-a07d-4441-c870-9ee6819c1d00"},"source":["!pip list | grep 'trax\\|jax'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["jax                           0.2.7                \n","jaxlib                        0.1.57+cuda101       \n","trax                          1.3.7                \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I8dhspA1Lk-b"},"source":["def get_batch(source, i):\r\n","    '''\r\n","        returns a batch\r\n","    '''\r\n","    bptt = 35\r\n","    seq_len = min(bptt, len(source) - 1 - i)\r\n","    data = source[i:i+seq_len]\r\n","    target = source[i+1:i+1+seq_len].view(-1)\r\n","    \r\n","    return data, target\r\n","\r\n","\r\n","def batchify(data, bsz):\r\n","    # Work out how cleanly we can divide the dataset into bsz parts.\r\n","    nbatch = data.size(0) // bsz\r\n","    # Trim off any extra elements that wouldn't cleanly fit (remainders).\r\n","    data = data.narrow(0, 0, nbatch * bsz)\r\n","    # Evenly divide the data across the bsz batches.\r\n","    data = data.view(bsz, -1).t().contiguous()\r\n","    return data\r\n","\r\n","\r\n","# to detach the hidden state from the graph.\r\n","def detach(hidden):\r\n","    \"\"\"\r\n","    This function detaches every single tensor. \r\n","    \"\"\"\r\n","    if isinstance(hidden, torch.Tensor):\r\n","        return hidden.detach()\r\n","    else:\r\n","        return tuple(detach(v) for v in hidden)"],"execution_count":null,"outputs":[]}]}