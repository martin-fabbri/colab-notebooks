{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"c4_w2_assignment_transformer_summarizer.ipynb","provenance":[],"authorship_tag":"ABX9TyM/+NfFonKuEl/ml9rkzk2M"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9XCeol40xzf1"},"source":["\r\n","# Assignment 2: Transformer Summarizer\r\n","\r\n","Welcome to the second assignment of course 4. In this assignment you will explore summarization using the transformer model. Yes, you will implement the transformer decoder from scratch, but we will slowly walk you through it. There are many hints in this notebook so feel free to use them as needed. \r\n","\r\n","<img src = \"transformerNews.png\">"]},{"cell_type":"markdown","metadata":{"id":"GUax1wvmDc7j"},"source":["## Outline\r\n","\r\n","- [Introduction](#0)\r\n","- [Part 1: Importing the dataset](#1)\r\n","    - [1.1 Encode & Decode helper functions](#1.1)\r\n","    - [1.2 Defining parameters](#1.2)\r\n","    - [1.3 Exploring the data](#1.3)\r\n","- [Part 2: Summarization with transformer](#2)\r\n","    - [2.1 Dot product attention](#2.1)\r\n","        - [Exercise 01](#ex01)\r\n","    - [2.2 Causal Attention](#2.2)\r\n","        - [Exercise 02](#ex02)\r\n","    - [2.3 Transformer decoder block](#2.3)\r\n","        - [Exercise 03](#ex03)\r\n","    - [2.4 Transformer Language model](#2.4)\r\n","        - [Exercise 04](#ex04)\r\n","- [Part 3: Training](#3)\r\n","    - [3.1 Training the model](#3.1)\r\n","        - [Exercise 05](#ex05)\r\n","- [Part 4: Evaluation](#4)\r\n","    - [4.1 Loading in a trained model](#4.1)\r\n","- [Part 5: Testing with your own input](#5) \r\n","    - [Exercise 6](#ex06)\r\n","    - [5.1 Greedy decoding](#5.1)\r\n","        - [Exercise 07](#ex07)"]},{"cell_type":"markdown","metadata":{"id":"PbZs68c3Dkt8"},"source":["<a name='0'></a>\r\n","### Introduction\r\n","\r\n","Summarization is an important task in natural language processing and could be useful for a consumer enterprise. For example, bots can be used to scrape articles, summarize them, and then you can use sentiment analysis to identify the sentiment about certain stocks. Anyways who wants to read an article or a long email today, when you can build a transformer to summarize text for you. Let's get started, by completing this assignment you will learn to:  \r\n","\r\n","- Use built-in functions to preprocess your data\r\n","- Implement DotProductAttention\r\n","- Implement Causal Attention\r\n","- Understand how attention works\r\n","- Build the transformer model\r\n","- Evaluate your model\r\n","- Summarize an article\r\n","\r\n","As you can tell, this model is slightly different than the ones you have already implemented. This is heavily based on attention and does not rely on sequences, which allows for parallel computing. "]},{"cell_type":"code","metadata":{"id":"hEiwSU8wEUqe","executionInfo":{"status":"ok","timestamp":1612895626366,"user_tz":480,"elapsed":15402,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["%%capture\r\n","!pip install trax"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-Bl4W37xJcW","executionInfo":{"status":"ok","timestamp":1612895750076,"user_tz":480,"elapsed":45802,"user":{"displayName":"Martin Fabbri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimIntWE1SvxJeoWOj0PwvUuB_-simILm2JI8het08=s64","userId":"04899005791450850059"}}},"source":["import sys\r\n","import os\r\n","\r\n","import numpy as np\r\n","\r\n","import textwrap\r\n","wrapper = textwrap.TextWrapper(width=70)\r\n","\r\n","import trax\r\n","from trax import layers as tl\r\n","from trax.fastmath import numpy as jnp\r\n","\r\n","# to print the entire np array\r\n","np.set_printoptions(threshold=sys.maxsize)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5RULauOHE6lR"},"source":["<a name='1'></a>\r\n","## Part 1: Importing the dataset"]},{"cell_type":"markdown","metadata":{"id":"KdGRNRh0FL6m"},"source":["Trax makes it easy to work with Tensorflow's datasets:"]},{"cell_type":"code","metadata":{"id":"nE-kXpBJE7t4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70J7LoSBE7kc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ux3XgKJKE7JO"},"source":[""],"execution_count":null,"outputs":[]}]}