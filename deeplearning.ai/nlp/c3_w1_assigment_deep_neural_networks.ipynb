{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c3_w1_assigment_deep_neural_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfPN963slKqcoN9g5DcHXn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/deeplearning.ai/nlp/c3_w1_assigment_deep_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPVkpoAe8BBC"
      },
      "source": [
        "# Assignment 1:  Sentiment with Deep Neural Networks\r\n",
        "\r\n",
        "Welcome to the first assignment of course 3. In this assignment, you will explore sentiment analysis using deep neural networks. \r\n",
        "## Outline\r\n",
        "- [Part 1:  Import libraries and try out Trax](#1)\r\n",
        "- [Part 2:  Importing the data](#2)\r\n",
        "    - [2.1  Loading in the data](#2.1)\r\n",
        "    - [2.2  Building the vocabulary](#2.2)\r\n",
        "    - [2.3  Converting a tweet to a tensor](#2.3)\r\n",
        "        - [Exercise 01](#ex01)\r\n",
        "    - [2.4  Creating a batch generator](#2.4)\r\n",
        "        - [Exercise 02](#ex02)\r\n",
        "- [Part 3:  Defining classes](#3)\r\n",
        "    - [3.1  ReLU class](#3.1)\r\n",
        "        - [Exercise 03](#ex03)\r\n",
        "    - [3.2  Dense class ](#3.2)\r\n",
        "        - [Exercise 04](#ex04)\r\n",
        "    - [3.3  Model](#3.3)\r\n",
        "        - [Exercise 05](#ex05)\r\n",
        "- [Part 4:  Training](#4)\r\n",
        "    - [4.1  Training the model](#4.1)\r\n",
        "        - [Exercise 06](#ex06)\r\n",
        "    - [4.2  Practice Making a prediction](#4.2)\r\n",
        "- [Part 5:  Evaluation  ](#5)\r\n",
        "    - [5.1  Computing the accuracy on a batch](#5.1)\r\n",
        "        - [Exercise 07](#ex07)\r\n",
        "    - [5.2  Testing your model on Validation Data](#5.2)\r\n",
        "        - [Exercise 08](#ex08)\r\n",
        "- [Part 6:  Testing with your own input](#6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r52dOO5s8FZp"
      },
      "source": [
        "In course 1, you implemented Logistic regression and Naive Bayes for sentiment analysis. However if you were to give your old models an example like:\r\n",
        "\r\n",
        "<center> <span style='color:blue'> <b>This movie was almost good.</b> </span> </center>\r\n",
        "\r\n",
        "Your model would have predicted a positive sentiment for that review. However, that sentence has a negative sentiment and indicates that the movie was not good. To solve those kinds of misclassifications, you will write a program that uses deep neural networks to identify sentiment in text. By completing this assignment, you will: \r\n",
        "\r\n",
        "- Understand how you can build/design a model using layers\r\n",
        "- Train a model using a training loop\r\n",
        "- Use a binary cross-entropy loss function\r\n",
        "- Compute the accuracy of your model\r\n",
        "- Predict using your own input\r\n",
        "\r\n",
        "As you can tell, this model follows a similar structure to the one you previously implemented in the second course of this specialization. \r\n",
        "- Indeed most of the deep nets you will be implementing will have a similar structure. The only thing that changes is the model architecture, the inputs, and the outputs. Before starting the assignment, we will introduce you to the Google library `trax` that we use for building and training models.\r\n",
        "\r\n",
        "\r\n",
        "Now we will show you how to compute the gradient of a certain function `f` by just using `  .grad(f)`. \r\n",
        "\r\n",
        "- Trax source code can be found on Github: [Trax](https://github.com/google/trax)\r\n",
        "- The Trax code also uses the JAX library: [JAX](https://jax.readthedocs.io/en/latest/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT988hwEHlo-"
      },
      "source": [
        "<a name=\"1\"></a>\r\n",
        "# Part 1:  Import libraries and try out Trax\r\n",
        "\r\n",
        "- Let's import libraries and look at an example of using the Trax library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIcgkqcEHroB"
      },
      "source": [
        "%%capture\r\n",
        "!pip install trax==1.3.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAJr628k7l-V",
        "outputId": "fe2805c5-772a-4b1d-9212-46227ed654c0"
      },
      "source": [
        "import random as rnd\r\n",
        "\r\n",
        "# import relevant libraries\r\n",
        "import trax\r\n",
        "\r\n",
        "# set random seeds to make this notebook easier to replicate\r\n",
        "trax.supervised.trainer_lib.init_random_number_generators(31)\r\n",
        "\r\n",
        "import os\r\n",
        "import re\r\n",
        "\r\n",
        "# import Layer from the utils.py file\r\n",
        "import string\r\n",
        "\r\n",
        "import nltk\r\n",
        "\r\n",
        "# import trax.fastmath.numpy\r\n",
        "import trax.fastmath.numpy as np\r\n",
        "\r\n",
        "# import trax.layers\r\n",
        "from trax import layers as tl\r\n",
        "\r\n",
        "nltk.download('twitter_samples')\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords, twitter_samples\r\n",
        "from nltk.tokenize import TweetTokenizer\r\n",
        "\r\n",
        "!pip list | grep 'trax\\|nltk\\|jax'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "jax                           0.2.7                \n",
            "jaxlib                        0.1.57+cuda101       \n",
            "nltk                          3.2.5                \n",
            "trax                          1.3.1                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1j5wBTIDYV"
      },
      "source": [
        "# Stop words are messy and not that compelling; \r\n",
        "# \"very\" and \"not\" are considered stop words, but they are obviously expressing sentiment\r\n",
        "\r\n",
        "# The porter stemmer lemmatizes \"was\" to \"wa\".  Seriously???\r\n",
        "\r\n",
        "# I'm not sure we want to get into stop words\r\n",
        "stopwords_english = stopwords.words('english')\r\n",
        "\r\n",
        "# Also have my doubts about stemming...\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "stemmer = PorterStemmer()\r\n",
        "\r\n",
        "def process_tweet(tweet):\r\n",
        "    '''\r\n",
        "    Input: \r\n",
        "        tweet: a string containing a tweet\r\n",
        "    Output:\r\n",
        "        tweets_clean: a list of words containing the processed tweet\r\n",
        "    \r\n",
        "    '''\r\n",
        "    # remove stock market tickers like $GE\r\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\r\n",
        "    # remove old style retweet text \"RT\"\r\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\r\n",
        "    # remove hyperlinks\r\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\r\n",
        "    # remove hashtags\r\n",
        "    # only removing the hash # sign from the word\r\n",
        "    tweet = re.sub(r'#', '', tweet)\r\n",
        "    # tokenize tweets\r\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\r\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\r\n",
        "    ### START CODE HERE ###\r\n",
        "    tweets_clean = []\r\n",
        "    for word in tweet_tokens:\r\n",
        "        if (word not in stopwords_english and # remove stopwords\r\n",
        "            word not in string.punctuation): # remove punctuation\r\n",
        "            #tweets_clean.append(word)\r\n",
        "            stem_word = stemmer.stem(word) # stemming word\r\n",
        "            tweets_clean.append(stem_word)\r\n",
        "    ### END CODE HERE ###\r\n",
        "    return tweets_clean\r\n",
        "\r\n",
        "\r\n",
        "# let's not reuse variables\r\n",
        "#all_positive_tweets = twitter_samples.strings('positive_tweets.json')\r\n",
        "#all_negative_tweets = twitter_samples.strings('negative_tweets.json')\r\n",
        "\r\n",
        "def load_tweets():\r\n",
        "    all_positive_tweets = twitter_samples.strings('positive_tweets.json')\r\n",
        "    all_negative_tweets = twitter_samples.strings('negative_tweets.json')  \r\n",
        "    return all_positive_tweets, all_negative_tweets\r\n",
        "    \r\n",
        "# Layers have weights and a foward function.\r\n",
        "# They create weights when layer.initialize is called and use them.\r\n",
        "# remove this or make it optional \r\n",
        "\r\n",
        "class Layer(object):\r\n",
        "    \"\"\"Base class for layers.\"\"\"\r\n",
        "    def __init__(self):\r\n",
        "        self.weights = None\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        raise NotImplementedError\r\n",
        "  \r\n",
        "    def init_weights_and_state(self, input_signature, random_key):\r\n",
        "        pass\r\n",
        "\r\n",
        "    def init(self, input_signature, random_key):\r\n",
        "        self.init_weights_and_state(input_signature, random_key)\r\n",
        "        return self.weights\r\n",
        "    \r\n",
        "    def __call__(self, x):\r\n",
        "        return self.forward(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "kehO6khUIKLF",
        "outputId": "054e197b-8522-48a6-d7cc-01b318a029de"
      },
      "source": [
        "# Create an array using trax.fastmath.numpy\r\n",
        "a = np.array(5.0)\r\n",
        "\r\n",
        "# View the returned array\r\n",
        "display(a)\r\n",
        "\r\n",
        "print(type(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DeviceArray(5., dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'jax.interpreters.xla._DeviceArray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cE5IP4aNZjv"
      },
      "source": [
        "Notice that trax.fastmath.numpy returns a DeviceArray from the jax library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RH0zy0UIKHp"
      },
      "source": [
        "# Define a function that will use the trax.fastmath.numpy array\r\n",
        "def f(x):\r\n",
        "    \r\n",
        "    # f = x^2\r\n",
        "    return (x**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt7r9-GlIKDl",
        "outputId": "c5388d5e-8499-4827-95de-ff8f3af4b08d"
      },
      "source": [
        "# Call the function\r\n",
        "print(f\"f(a) for a={a} is {f(a)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f(a) for a=5.0 is 25.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEURb2zqNxdk"
      },
      "source": [
        "The gradient (derivative) of function `f` with respect to its input `x` is the derivative of $x^2$.\r\n",
        "- The derivative of $x^2$ is $2x$.  \r\n",
        "- When x is 5, then $2x=10$.\r\n",
        "\r\n",
        "You can calculate the gradient of a function by using `trax.fastmath.grad(fun=)` and passing in the name of the function.\r\n",
        "- In this case the function you want to take the gradient of is `f`.\r\n",
        "- The object returned (saved in `grad_f` in this example) is a function that can calculate the gradient of f for a given trax.fastmath.numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL_Bk01zNyOT",
        "outputId": "51ccbd0d-9a87-41f6-95b6-100ab35861da"
      },
      "source": [
        "grad_f = trax.fastmath.grad(fun=f)\r\n",
        "type(grad_f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "function"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Mov9AurcNzGc",
        "outputId": "4e09e22b-4010-4370-96e0-d72228c36506"
      },
      "source": [
        "grad_calculation = grad_f(a)\r\n",
        "display(grad_calculation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DeviceArray(10., dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF3C87cSPGMa"
      },
      "source": [
        "The function returned by trax.fastmath.grad takes in x=5 and calculates the gradient of f, which is 2*x, which is 10. The value is also stored as a DeviceArray from the jax library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAzrSwK6NzDS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRdVxoIKNy_X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3RDjV1INy5i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYE7ebdDNyv-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}