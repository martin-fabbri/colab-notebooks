{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpytorch-regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/gpytorch_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UngR_0pwboG6",
        "colab_type": "text"
      },
      "source": [
        "# Gaussian Process Regression using GPyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y98arE-QbLCo",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxkbqvwIbKvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64c6ad1c-eadc-4ffa-f036-bcff834dfcb6"
      },
      "source": [
        "!pip install gpytorch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpytorch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybc6_AYVbKFq",
        "colab_type": "text"
      },
      "source": [
        "Function to model:\n",
        "\n",
        "\\begin{align}\n",
        "y &= \\sin(2\\pi x) + \\epsilon \\;\\; (1)\\\\\n",
        "  \\epsilon &\\sim \\mathcal{N}(0, 0.2) \\;\\; (2) \n",
        "\\end{align}\n",
        "\n",
        "with 100 training examples, and testing on 51 examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADTDpMf_bB7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from gpytorch.models import ExactGP\n",
        "from gpytorch.means import ConstantMean\n",
        "from gpytorch.kernels import ScaleKernel\n",
        "from gpytorch.kernels import RBFKernel\n",
        "from gpytorch.distributions import MultivariateNormal\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.settings import fast_pred_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1P2EiiDiUYb",
        "colab_type": "text"
      },
      "source": [
        "## Setup training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mTAMcLliUJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training data is 100 points in [0,1] regularly spaced\n",
        "train_x = torch.linspace(0, 1, 100)\n",
        "# True function is (1) with Gaussian noise (2)\n",
        "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ-cFO5EjbtW",
        "colab_type": "text"
      },
      "source": [
        "## Setting up the model\n",
        "\n",
        "For most GP regression models, you will need to construct the following GPyTorch objects:\n",
        "\n",
        "1. A **GP Model** (`gpytorch.models.ExactGP`) -  This handles most of the inference.\n",
        "1. A **Likelihood** (`gpytorch.likelihoods.GaussianLikelihood`) - This is the most common likelihood used for GP regression.\n",
        "1. A **Mean** - This defines the prior mean of the GP.(If you don't know which mean to use, a `gpytorch.means.ConstantMean()` is a good place to start.)\n",
        "1. A **Kernel** - This defines the prior covariance of the GP.(If you don't know which kernel to use, a `gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())` is a good place to start).\n",
        "1. A **MultivariateNormal** Distribution (`gpytorch.distributions.MultivariateNormal`) - This is the object used to represent multivariate normal distributions.\n",
        "\n",
        "### The GP Model\n",
        "  \n",
        "The components of a user built (Exact, i.e. non-variational) GP model in GPyTorch are, broadly speaking:\n",
        "\n",
        "1. An `__init__` method that takes the training data and a likelihood, and constructs whatever objects are necessary for the model's `forward` method. This will most commonly include things like a mean module and a kernel module.\n",
        "\n",
        "2. A `forward` method that takes in some $n \\times d$ data `x` and returns a `MultivariateNormal` with the *prior* mean and covariance evaluated at `x`. In other words, we return the vector $\\mu(x)$ and the $n \\times n$ matrix $K_{xx}$ representing the prior mean and covariance matrix of the GP. \n",
        "\n",
        "This specification leaves a large amount of flexibility when defining a model. For example, to compose two kernels via addition, you can either add the kernel modules directly:\n",
        "\n",
        "```python\n",
        "self.covar_module = ScaleKernel(RBFKernel() + WhiteNoiseKernel())\n",
        "```\n",
        "\n",
        "Or you can add the outputs of the kernel in the forward method:\n",
        "\n",
        "```python\n",
        "covar_x = self.rbf_kernel_module(x) + self.white_noise_module(x)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFqL4Z57iUG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ExactGPModel(ExactGP):\n",
        "  def __init__(self, train_x, train_y, likelihood):\n",
        "    super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
        "    self.mean_module = ConstantMean()\n",
        "    self.covar_module = ScaleKernel(RBFKernel())\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean_x = self.mean_module(x)\n",
        "    covar_x = self.covar_module(x)\n",
        "    return MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "# initialize likelyhood and model\n",
        "likelihood = GaussianLikelihood()\n",
        "model = ExactGPModel(train_x, train_y, likelihood)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cUYxqbkn9zQ",
        "colab_type": "text"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "The most obvious difference here compared to many other GP implementations is that, as in standard PyTorch, the core training loop is written by the user. In GPyTorch, we make use of the standard PyTorch optimizers as from `torch.optim`, and all trainable parameters of the model should be of type `torch.nn.Parameter`. Because GP models directly extend `torch.nn.Module`, calls to methods like `model.parameters()` or `model.named_parameters()` function as you might expect coming from PyTorch.\n",
        "\n",
        "In most cases, the boilerplate code below will work well. It has the same basic components as the standard PyTorch training loop:\n",
        "\n",
        "1. Zero all parameter gradients\n",
        "2. Call the model and compute the loss\n",
        "3. Call backward on the loss to fill in gradients\n",
        "4. Take a step on the optimizer\n",
        "\n",
        "However, defining custom training loops allows for greater flexibility. For example, it is easy to save the parameters at each step of training, or use different learning rates for different parameters (which may be useful in deep kernel learning for example).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtsOaxXYiUD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "fb19a31b-5b00-4429-d351-d0f0e49511b3"
      },
      "source": [
        "training_iter = 50\n",
        "# fin optimal model hyperparameters\n",
        "model.train()\n",
        "likelihood.train()\n",
        "\n",
        "optimizer = torch.optim.Adam([\n",
        "  {'params': model.parameters()}\n",
        "], lr=0.1)\n",
        "\n",
        "# loss for gps - the marginal log likelihood\n",
        "mll = ExactMarginalLogLikelihood(likelihood, model)\n",
        "\n",
        "for i in range(training_iter):\n",
        "  optimizer.zero_grad()\n",
        "  output = model(train_x)\n",
        "  loss = -mll(output, train_y)\n",
        "  loss.backward()\n",
        "  print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
        "        i + 1, training_iter, loss.item(),\n",
        "        model.covar_module.base_kernel.lengthscale.item(),\n",
        "        model.likelihood.noise.item()\n",
        "  ))\n",
        "  optimizer.step()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 1/50 - Loss: 1.570   lengthscale: 0.693   noise: 0.693\n",
            "Iter 2/50 - Loss: 1.549   lengthscale: 0.644   noise: 0.744\n",
            "Iter 3/50 - Loss: 1.531   lengthscale: 0.598   noise: 0.798\n",
            "Iter 4/50 - Loss: 1.518   lengthscale: 0.554   noise: 0.852\n",
            "Iter 5/50 - Loss: 1.508   lengthscale: 0.513   noise: 0.906\n",
            "Iter 6/50 - Loss: 1.501   lengthscale: 0.474   noise: 0.959\n",
            "Iter 7/50 - Loss: 1.495   lengthscale: 0.437   noise: 1.010\n",
            "Iter 8/50 - Loss: 1.492   lengthscale: 0.403   noise: 1.058\n",
            "Iter 9/50 - Loss: 1.489   lengthscale: 0.370   noise: 1.102\n",
            "Iter 10/50 - Loss: 1.488   lengthscale: 0.341   noise: 1.140\n",
            "Iter 11/50 - Loss: 1.487   lengthscale: 0.313   noise: 1.173\n",
            "Iter 12/50 - Loss: 1.487   lengthscale: 0.288   noise: 1.200\n",
            "Iter 13/50 - Loss: 1.486   lengthscale: 0.266   noise: 1.220\n",
            "Iter 14/50 - Loss: 1.486   lengthscale: 0.246   noise: 1.234\n",
            "Iter 15/50 - Loss: 1.486   lengthscale: 0.228   noise: 1.242\n",
            "Iter 16/50 - Loss: 1.486   lengthscale: 0.213   noise: 1.245\n",
            "Iter 17/50 - Loss: 1.485   lengthscale: 0.200   noise: 1.243\n",
            "Iter 18/50 - Loss: 1.485   lengthscale: 0.189   noise: 1.237\n",
            "Iter 19/50 - Loss: 1.484   lengthscale: 0.180   noise: 1.226\n",
            "Iter 20/50 - Loss: 1.484   lengthscale: 0.172   noise: 1.213\n",
            "Iter 21/50 - Loss: 1.483   lengthscale: 0.166   noise: 1.196\n",
            "Iter 22/50 - Loss: 1.482   lengthscale: 0.161   noise: 1.178\n",
            "Iter 23/50 - Loss: 1.482   lengthscale: 0.158   noise: 1.158\n",
            "Iter 24/50 - Loss: 1.481   lengthscale: 0.155   noise: 1.137\n",
            "Iter 25/50 - Loss: 1.481   lengthscale: 0.154   noise: 1.116\n",
            "Iter 26/50 - Loss: 1.480   lengthscale: 0.153   noise: 1.095\n",
            "Iter 27/50 - Loss: 1.480   lengthscale: 0.153   noise: 1.075\n",
            "Iter 28/50 - Loss: 1.480   lengthscale: 0.153   noise: 1.056\n",
            "Iter 29/50 - Loss: 1.479   lengthscale: 0.154   noise: 1.038\n",
            "Iter 30/50 - Loss: 1.479   lengthscale: 0.156   noise: 1.022\n",
            "Iter 31/50 - Loss: 1.479   lengthscale: 0.159   noise: 1.008\n",
            "Iter 32/50 - Loss: 1.479   lengthscale: 0.162   noise: 0.996\n",
            "Iter 33/50 - Loss: 1.479   lengthscale: 0.165   noise: 0.987\n",
            "Iter 34/50 - Loss: 1.479   lengthscale: 0.169   noise: 0.980\n",
            "Iter 35/50 - Loss: 1.479   lengthscale: 0.173   noise: 0.976\n",
            "Iter 36/50 - Loss: 1.479   lengthscale: 0.178   noise: 0.974\n",
            "Iter 37/50 - Loss: 1.479   lengthscale: 0.183   noise: 0.975\n",
            "Iter 38/50 - Loss: 1.479   lengthscale: 0.188   noise: 0.978\n",
            "Iter 39/50 - Loss: 1.479   lengthscale: 0.193   noise: 0.982\n",
            "Iter 40/50 - Loss: 1.479   lengthscale: 0.197   noise: 0.988\n",
            "Iter 41/50 - Loss: 1.478   lengthscale: 0.202   noise: 0.996\n",
            "Iter 42/50 - Loss: 1.478   lengthscale: 0.206   noise: 1.004\n",
            "Iter 43/50 - Loss: 1.478   lengthscale: 0.209   noise: 1.013\n",
            "Iter 44/50 - Loss: 1.478   lengthscale: 0.212   noise: 1.022\n",
            "Iter 45/50 - Loss: 1.478   lengthscale: 0.214   noise: 1.031\n",
            "Iter 46/50 - Loss: 1.478   lengthscale: 0.215   noise: 1.039\n",
            "Iter 47/50 - Loss: 1.478   lengthscale: 0.216   noise: 1.047\n",
            "Iter 48/50 - Loss: 1.478   lengthscale: 0.216   noise: 1.054\n",
            "Iter 49/50 - Loss: 1.478   lengthscale: 0.215   noise: 1.060\n",
            "Iter 50/50 - Loss: 1.478   lengthscale: 0.213   noise: 1.064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK75KtvVsdC9",
        "colab_type": "text"
      },
      "source": [
        "# Make predictions with the model\n",
        "\n",
        "Just as a user defined GP model returns a MultivariateNormal containing the prior mean and covariance from forward, a trained GP model in eval mode returns a MultivariateNormal containing the posterior mean and covariance. Thus, getting the predictive mean and variance, and then sampling functions from the GP at the given test points could be accomplished with calls like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihHxwoDPiUA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# f_preds = model(test_x)\n",
        "# y_preds = likelihood(model(test_x))\n",
        "\n",
        "# f_mean = f_preds.mean\n",
        "# f_var = f_preds.variance\n",
        "# f_covar = f_preds.covariance_matrix\n",
        "# f_sample = f_preds.sample(sample_shape=torch.Size(1000,))\n",
        "\n",
        "# get into evaluation (predictive posterior) mode\n",
        "model.eval()\n",
        "likelihood.eval()\n",
        "\n",
        "# test points are regularly spaces along [0,1]\n",
        "# make predictions by feeding model through likelihood\n",
        "with torch.no_grad(), fast_pred_var():\n",
        "  test_x = torch.linspace(0, 1, 51)\n",
        "  observed_pred = likelihood(model(test_x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn_B2h59u4AE",
        "colab_type": "text"
      },
      "source": [
        "### Plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WYYn6gFiT95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "b4776fef-6a76-4f2e-f925-1e311f02fac1"
      },
      "source": [
        "with torch.no_grad():\n",
        "  f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
        "  lower, upper = observed_pred.confidence_region()\n",
        "  ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
        "  ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
        "  ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
        "  ax.set_ylim([-3, 3])\n",
        "  ax.legend(['Observed Data', 'Mean', 'Confidence'])\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAADGCAYAAADWg+V4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 288x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}